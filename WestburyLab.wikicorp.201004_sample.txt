
Anarchism.
Anarchism is a political philosophy which considers the state undesirable, unnecessary and harmful, and instead promotes a stateless society, or anarchy. It seeks to diminish or even abolish authority in the conduct of human relations. Anarchists may widely disagree on what additional criteria are required in anarchism. "The Oxford Companion to Philosophy" says, "there is no single defining position that all anarchists hold, and those considered anarchists at best share a certain family resemblance."
There are many types and traditions of anarchism, not all of which are mutually exclusive. Strains of anarchism have been divided into the categories of social and individualist anarchism or similar dual classifications. Anarchism is often considered to be a radical left-wing ideology, and much of anarchist economics and anarchist legal philosophy reflect anti-statist interpretations of communism, collectivism, syndicalism or participatory economics. However, anarchism has always included an individualist strain supporting a market economy and private property, or unrestrained egoism that bases right on might.
Others, such as panarchists and anarchists without adjectives, neither advocate nor object to any particular form of organization as long as it is not compulsory. Differing fundamentally, some anarchist schools of thought support anything from extreme individualism to complete collectivism. The central tendency of anarchism as a social movement have been represented by communist anarchism, with individualist anarchism being primarily a philosophical or literary phenomenon. Some anarchists fundamentally oppose all forms of aggression, supporting self-defense or non-violence, while others have supported the use of some coercive measures, including violent revolution and terrorism, on the path to an anarchist society.
Etymology and terminology.
The term "anarchism" derives from the Greek ἄναρχος, "anarchos", meaning "without rulers", from the prefix ἀν- ("an-", "without") + ἀρχή ("archê", "sovereignty, realm, magistracy") + -ισμός ("-ismos", from the suffix -ιζειν, "-izein" "-izing"). There is some ambiguity with the use of the terms "libertarianism" and "libertarian" in writings about anarchism. Since the 1890s from France, the term "libertarianism" has often been used as a synonym for anarchism and was used almost exclusively in this sense until the 1950s in the United States; its use as a synonym is still common outside the United States. Accordingly, "libertarian socialism" is sometimes used as a synonym for socialist anarchism, to distinguish it from "individualist libertarianism" (individualist anarchism). On the other hand, some use "libertarianism" to refer to individualistic free-market philosophy only, referring to free-market anarchism as "libertarian anarchism."
Origins.
Some claim anarchist themes can be found in the works of Taoist sages Laozi and Zhuangzi. The latter has been translated, "There has been such a thing as letting mankind alone; there has never been such a thing as governing mankind [with success]," and "A petty thief is put in jail. A great brigand becomes a ruler of a Nation." Diogenes of Sinope and the Cynics, and their contemporary Zeno of Citium, the founder of Stoicism, also introduced similar topics.
Modern anarchism, however, sprang from the secular or religious thought of the Enlightenment, particularly Jean-Jacques Rousseau's arguments for the moral centrality of freedom. Although by the turn of the 19th century the term "anarchist" had lost its initial negative connotation, it first entered the English language in 1642 during the English Civil War as a term of abuse used by Royalists to damn those who were fomenting disorder. By the time of the French Revolution some, such as the "Enragés", began to use the term positively, in opposition to Jacobin centralisation of power, seeing "revolutionary government" as oxymoronic.
From this climate William Godwin developed what many consider the first expression of modern anarchist thought. Godwin was, according to Peter Kropotkin, "the first to formulate the political and economical conceptions of anarchism, even though he did not give that name to the ideas developed in his work", while Godwin attached his anarchist ideas to an early Edmund Burke. Benjamin Tucker instead credits Josiah Warren, an American who promoted stateless and voluntary communities where all goods and services were private, with being "the first man to expound and formulate the doctrine now known as Anarchism." The first to describe himself as an anarchist was Pierre-Joseph Proudhon, a French philosopher and politician, which led some to call him the founder of modern anarchist theory.
Social movement.
Anarchism as a social movement has regularly endured fluctuations in popularity. Its classical period, which scholars demarcate as from 1860 to 1939, is associated with the working-class movements of the nineteenth century and the Spanish Civil War-era struggles against fascism. Anarchists were heavilly involved in the abolition of slavery, and continue to be active in the labour movement, civil rights, women's liberation, both anti-capitalism and pro-capitalism (with varying definitions of capitalism), the anti-war movement, LGBT rights, both anti-globalization and pro-globalization (with varying definitions of globalization), tax resistance, and other areas.
The First International.
In Europe, harsh reaction followed the revolutions of 1848, during which ten countries had experienced brief or long-term social upheaval as groups carried out nationalist uprisings. After most of these attempts at systematic change ended in failure, conservative elements took advantage of the divided groups of socialists, anarchists, liberals, and nationalists, to prevent further revolt. In 1864 the International Workingmen's Association (sometimes called the "First International") united diverse revolutionary currents including French followers of Proudhon, Blanquists, Philadelphes, English trade unionists, socialists and social democrats.
Due to its links to active workers' movements, the International became a significant organization. Karl Marx became a leading figure in the International and a member of its General Council. Proudhon's followers, the mutualists, opposed Marx's state socialism, advocating political abstentionism and small property holdings.
In 1868, following their unsuccessful participation in the League of Peace and Freedom (LPF), Russian revolutionary Mikhail Bakunin and his collectivist anarchist associates and joined the First International (which had decided not to get involved with the LPF). They allied themselves with the federalist socialist sections of the International, who advocated the revolutionary overthrow of the state and the collectivization of property.
At first, the collectivists worked with the Marxists to push the First International in a more revolutionary socialist direction. Subsequently, the International became polarised into two camps, with Marx and Bakunin as their respective figureheads. Bakunin characterised Marx's ideas as centralist and predicted that, if a Marxist party came to power, its leaders would simply take the place of the ruling class they had fought against.
In 1872, the conflict climaxed with a final split between the two groups at the Hague Congress, where Bakunin and James Guillaume were expelled from the International and its headquarters were transferred to New York. In response, the federalist sections formed their own International at the St. Imier Congress, adopting a revolutionary anarchist program.
Organised labour.
The anti-authoritarian sections of the First International were the precursors of the anarcho-syndicalists, seeking to "replace the privilege and authority of the State" with the "free and spontaneous organization of labor." In 1886, the Federation of Organized Trades and Labor Unions (FOTLU) of the United States and Canada unanimously set 1 May 1886, as the date by which the eight-hour work day would become standard.
In response, unions across America prepared a general strike in support of the event. On 3 May, in Chicago, a fight broke out when strikebreakers attempted to cross the picket line, and two workers died when police opened fire upon the crowd. The next day, 4 May, anarchists staged a rally at Chicago's Haymarket Square. A bomb was thrown by an unknown party near the conclusion of the rally, killing an officer. In the ensuing panic, police opened fire on the crowd and each other. Seven police officers and at least four workers were killed. Eight anarchists directly and indirectly related to the organisers of the rally were arrested and charged with the murder of the deceased officer. The men became international political celebrities among the labour movement. Four of the men were executed and a fifth committed suicide prior to his own execution. The incident became known as the Haymarket affair, and was a setback for the labour movement and the struggle for the eight hour day. In 1890 a second attempt, this time international in scope, to organise for the eight hour day was made. The event also had the secondary purpose of memorializing workers killed as a result of the Haymarket affair. Although it had initially been conceived as a once-off event, by the following year the celebration of International Workers' Day on May Day had become firmly established as an international worker's holiday.
In 1907, the International Anarchist Congress of Amsterdam gathered delegates from 14 different countries, among which important figures of the anarchist movement, including Errico Malatesta, Pierre Monatte, Luigi Fabbri, Benoît Broutchoux, Emma Goldman, Rudolf Rocker, and Christiaan Cornelissen. Various themes were treated during the Congress, in particular concerning the organisation of the anarchist movement, popular education issues, the general strike or antimilitarism. A central debate concerned the relation between anarchism and syndicalism (or trade unionism). Malatesta and Monatte were in particular disagreement themselves on this issue, as the latter thought that syndicalism was revolutionary and would create the conditions of a social revolution, while Malatesta did not consider syndicalism by itself sufficient. He thought that the trade-union movement was reformist and even conservative, citing as essentially bourgeois and anti-worker the phenomenon of professional union officials. Malatesta warned that the syndicalists aims were in perpetuating syndicalism itself, whereas anarchists must always have anarchy as their end and consequently refrain from committing to any particular method of achieving it.
The Spanish Workers Federation in 1881 was the first major anarcho-syndicalist movement; anarchist trade union federations were of special importance in Spain. The most successful was the Confederación Nacional del Trabajo (National Confederation of Labour: CNT), founded in 1910. Before the 1940s, the CNT was the major force in Spanish working class politics, attracting 1.58 million members at one point and playing a major role in the Spanish Civil War. The CNT was affiliated with the International Workers Association, a federation of anarcho-syndicalist trade unions founded in 1922, with delegates representing two million workers from 15 countries in Europe and Latin America. The largest organised anarchist movement today is in Spain, in the form of the Confederación General del Trabajo (CGT) and the CNT. CGT membership was estimated to be around 100,000 for the year 2003. Other active syndicalist movements include the US Workers Solidarity Alliance and the UK Solidarity Federation. The revolutionary industrial unionist Industrial Workers of the World, claiming 2,000 paying members, and the International Workers Association, an anarcho-syndicalist successor to the First International, also remain active.
Russian Revolution.
Anarchists participated alongside the Bolsheviks in both February and October revolutions, and were initially enthusiastic about the Bolshevik coup. However, the Bolsheviks soon turned against the anarchists and other left-wing opposition, a conflict that culminated in the 1921 Kronstadt rebellion which the new government repressed. Anarchists in central Russia were either imprisoned, driven underground or joined the victorious Bolsheviks; the anarchists from Petrograd and Moscow fled to the Ukraine. There, in the Free Territory, they fought in the civil war against the Whites (a Western-backed grouping of monarchists and other opponents of the October Revolution) and then the Bolsheviks as part of the Revolutionary Insurrectionary Army of Ukraine led by Nestor Makhno, who established an anarchist society in the region for a number of months.
Expelled American anarchists Emma Goldman and Alexander Berkman were amongst those agitating in response to Bolshevik policy and the suppression of the Kronstadt uprising, before they left Russia. Both wrote accounts of their experiences in Russia, criticizing the amount of control the Bolsheviks exercised. For them, Bakunin's predictions about the consequences of Marxist rule that the rulers of the new "socialist” Marxist state would become a new elite had proved all too true.
The victory of the Bolsheviks in the October Revolution and the resulting Russian Civil War did serious damage to anarchist movements internationally. Many workers and activists saw Bolshevik success as setting an example; Communist parties grew at the expense of anarchism and other socialist movements. In France and the United States, for example, members of the major syndicalist movements of the CGT and IWW left the organizations and joined the Communist International.
In Paris, the Dielo Truda group of Russian anarchist exiles, which included Nestor Makhno, concluded that anarchists needed to develop new forms of organisation in response to the structures of Bolshevism. Their 1926 manifesto, called the "Organizational Platform of the General Union of Anarchists (Draft)", was supported. Platformist groups active today include the Workers Solidarity Movement in Ireland and the North Eastern Federation of Anarchist Communists of North America.
Fight against fascism.
In the 1920s and 1930s, the rise of fascism in Europe transformed anarchism's conflict with the state. Italy saw the first struggles between anarchists and fascists. Italian anarchists played a key role in the anti-fascist organisation "Arditi del Popolo", which was strongest in areas with anarchist traditions, and achieved some success in their activism, such as repelling Blackshirts in the anarchist stronghold of Parma in August 1922. In France, where the far right leagues came close to insurrection in the February 1934 riots, anarchists divided over a united front policy.
In Spain, the CNT initially refused to join a popular front electoral alliance, and abstention by CNT supporters led to a right wing election victory. But in 1936, the CNT changed its policy and anarchist votes helped bring the popular front back to power. Months later, the former ruling class responded with an attempted coup causing the Spanish Civil War (1936–1939). In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain where they collectivised the land. But even before the fascist victory in 1939, the anarchists were losing ground in a bitter struggle with the Stalinists, who controlled the distribution of military aid to the Republican cause from the Soviet Union. Stalinist-led troops suppressed the collectives and persecuted both dissident Marxists and anarchists.
Contemporary anarchism.
A surge of popular interest in anarchism occurred during the 1960s and 1970s. In the United Kingdom this was associated with the punk rock movement, as exemplified by bands such as Crass and the Sex Pistols. The housing and employment crisis in most of Western Europe led to the formation of communes and squatter movements like that of Barcelona, Spain. In Denmark, squatters occupied a disused military base and declared the Freetown Christiania, an autonomous haven in central Copenhagen.
Since the revival of anarchism in the mid 20th century, a number of new movements and schools of thought emerged. Although feminist tendencies have always been a part of the anarchist movement in the form of anarcha-feminism, they returned with vigour during the second wave of feminism in the 1960s. The American Civil Rights Movement and the movement against the war in Vietnam also contributed to the revival of North American anarchism. European anarchism of the late 20th century drew much of its strength from the labour movement, and both have incorporated animal rights activism. Anarchist anthropologist David Graeber has posited a rupture between generations of anarchism, with those "who often still have not shaken the sectarian habits" of the nineteenth century contrasted with the younger activists who are "much more informed, among other elements, by indigenous, feminist, ecological and cultural-critical ideas", and who by the turn of the 21st century formed "by far the majority" of anarchists.
Around the turn of the 21st century, anarchism grew in popularity and influence as part of the anti-war, anti-capitalist, and anti-globalisation movements. Anarchists became known for their involvement in protests against the meetings of the World Trade Organization (WTO), Group of Eight, and the World Economic Forum. Some anarchist factions at these protests engaged in rioting, property destruction, and violent confrontations with police, and the confrontations were selectively portrayed in mainstream media coverage as violent riots. These actions were precipitated by ad hoc, leaderless, anonymous cadres known as "black blocs"; other organisational tactics pioneered in this time include security culture, affinity groups and the use of decentralised technologies such as the internet. A landmark struggle of this period was the confrontations at WTO conference in Seattle in 1999.
Anarchist schools of thought.
Anarchist ideas have only occasionally inspired political movements of any size, and "the tradition is mainly one of individual thinkers, but they have produced an important body of theory." Anarchist schools of thought had been generally grouped in two main historical traditions, individualist anarchism and social anarchism, which have some different origins, values and evolution. The individualist wing of anarchism emphasises negative liberty, i.e. opposition to state or social control over the individual, while those in the social wing emphasise positive liberty to achieve one's potential and argue that humans have needs that society ought to fulfill, "recognizing equality of entitlement". In chronological and theoretical sense there are classical — those created throughout the 19th century — and post-classical anarchist schools — those created since the mid-20th century and after.
Beyond the specific factions of anarchist thought is philosophical anarchism, which embodies the theoretical stance that the State lacks moral legitimacy without accepting the imperative of revolution to eliminate it. A component especially of individualist anarchism philosophical anarchism may accept the existence of a minimal state as unfortunate, and usually temporary, "necessary evil" but argue that citizens do not have a moral obligation to obey the state when its laws conflict with individual autonomy. One reaction against sectarianism within the anarchist milieu was "anarchism without adjectives", a call for toleration first adopted by Fernando Tarrida del Mármol in 1889 in response to the "bitter debates" of anarchist theory at the time. In abandoning the hyphenated anarchisms (i.e. collectivist-, communist-, mutualist- and individualist-anarchism), it sought to emphasise the anti-authoritarian beliefs common to all anarchist schools of thought.
Mutualism.
Mutualism began in 18th century English and French labour movements before taking an anarchist form associated with Pierre-Joseph Proudhon in France and others in the United States. Proudhon proposed spontaneous order, whereby organization emerges without central authority, a "positive anarchy" where order arises when everybody does “what he wishes and only what he wishes" and where "business transactions alone produce the social order." Mutualist anarchism is concerned with reciprocity, free association, voluntary contract, federation, and credit and currency reform. According to William Batchelder Greene, each worker in the mutualist system would receive "just and exact pay for his work; services equivalent in cost being exchangeable for services equivalent in cost, without profit or discount." Mutualism has been retrospectively characterised as ideologically situated between individualist and collectivist forms of anarchism. Proudhon first characterised his goal as a "third form of society, the synthesis of communism and property."
Individualist anarchism.
Individualist anarchism refers to several traditions of thought within the anarchist movement that emphasise the individual and their will over any kinds of external determinants such as groups, society, traditions, and ideological systems. Individualist anarchism is not a single philosophy but refers to a group of individualistic philosophies that sometimes are in conflict.
In 1793, William Godwin, who has often been cited as the first anarchist, wrote "Political Justice", which some consider to be the first expression of anarchism. Godwin, a philosophical anarchist, from a rationalist and utilitarian basis opposed revolutionary action and saw a minimal state as a present "necessary evil" that would become increasingly irrelevant and powerless by the gradual spread of knowledge. Godwin advocated extreme individualism, proposing that all cooperation in labour be eliminated on the premise that this would be most conducive with the general good. Godwin was a utilitarian who believed that all individuals are not of equal value, with some of us "of more worth and importance" than others depending on our utility in bringing about social good. Therefore he does not believe in equal rights, but the person's life that should be favoured that is most conducive to the general good. Godwin opposed government because he saw it as infringing on the individual's right to "private judgement" to determine which actions most maximise utility, but also makes a critique of all authority over the individual's judgement. This aspect of Godwin's philosophy, stripped of utilitarian motivations, was developed into a more extreme form later by Stirner.
The most extreme form of individualist anarchism, called "egoism," or egoist anarchism, was expounded by one of the earliest and best-known proponents of individualist anarchism, Max Stirner. Stirner's "The Ego and Its Own", published in 1844, is a founding text of the philosophy. According to Stirner, the only limitation on the rights of the individual is their power to obtain what they desire, without regard for God, state, or morality. To Stirner, rights were "spooks" in the mind, and he held that society does not exist but "the individuals are its reality". Stirner advocated self-assertion and foresaw Unions of Egoists, non-systematic associations continually renewed by all parties' support through an act of will, which Stirner proposed as a form of organization in place of the state. Egoist anarchists claim that egoism will foster genuine and spontaneous union between individuals. "Egoism" has inspired many interpretations of Stirner's philosophy. It was re-discovered and promoted by German philosophical anarchist and LGBT activist John Henry Mackay. Individualist anarchism inspired by Stirner attracted a small following of European bohemian artists and intellectuals (see European individualist anarchism). Stirner's philosophy has been seen as a precedent of existentialism with other thinkers like Friedrich Nietzsche and Sören Kierkegaard.
Social anarchism.
Social anarchism calls for a system with public ownership of means of production and democratic control of all organizations, without any government authority or coercion. It is the largest school of anarchism. Social anarchism rejects private property, seeing it as a source of social inequality, and emphasises cooperation and mutual aid.
Collectivist anarchism, also referred to as "revolutionary socialism" or a form of such, is a revolutionary form of anarchism, commonly associated with Mikhail Bakunin and Johann Most. Collectivist anarchists oppose all private ownership of the means of production, instead advocating that ownership be collectivised. This was to be achieved through violent revolution, first starting with a small cohesive group through acts of violence, or "propaganda by the deed," which would inspire the workers as a whole to revolt and forcibly collectivise the means of production. However, collectivization was not to be extended to the distribution of income, as workers would be paid according to time worked, rather than receiving goods being distributed "according to need" as in anarcho-communism. This position was criticised by anarchist communists as effectively "uphold[ing] the wages system". Collectivist anarchism arose contemporaneously with Marxism but opposed the Marxist dictatorship of the proletariat, despite the stated Marxist goal of a collectivist stateless society. Anarchist communist and collectivist ideas are not mutually exclusive; although the collectivist anarchists advocated compensation for labour, some held out the possibility of a post-revolutionary transition to a communist system of distribution according to need.
Anarchist communism proposes that the freest form of social organisation would be a society composed of self-managing communes with collective use of the means of production, organised democratically, and related to other communes through federation. While some anarchist communists favour direct democracy, others feel that its majoritarianism can impede individual liberty and favour consensus democracy instead. In anarchist communism, as money would be abolished, individuals would not receive direct compensation for labour (through sharing of profits or payment) but would have free access to the resources and surplus of the commune. Anarchist communism does not always have a communitarian philosophy. Some forms of anarchist communism are egoist and strongly influenced by radical individualism, believing that anarchist communism does not require a communitarian nature at all.
In the early 20th century, anarcho-syndicalism arose as a distinct school of thought within anarchism. With greater focus on the labour movement than previous forms of anarchism, syndicalism posits radical trade unions as a potential force for revolutionary social change, replacing capitalism and the state with a new society, democratically self-managed by the workers. It is often combined with other branches of anarchism, and anarcho-syndicalists often subscribe to anarchist communist or collectivist anarchist economic systems. An early leading anarcho-syndicalist thinker was Rudolf Rocker, whose 1938 pamphlet "Anarchosyndicalism" outlined a view of the movement's origin, aims and importance to the future of labour.
Post-classical currents.
Anarchism continues to generate many philosophies and movements, at times eclectic, drawing upon various sources, and syncretic, combining disparate and contrary concepts to create new philosophical approaches. Since the revival of anarchism in the United States in the 1960s, a number of new movements and schools have emerged. Anarcho-capitalism developed from radical anti-state libertarianism and individualist anarchism, drawing from Austrian School economics, study of law and economics and public choice theory, while the burgeoning feminist and environmentalist movements also produced anarchist offshoots. Anarcha-feminism developed as a synthesis of radical feminism and anarchism that views patriarchy (male domination over women) as a fundamental manifestation of compulsory government. It was inspired by the late 19th century writings of early feminist anarchists such as Lucy Parsons, Emma Goldman, Voltairine de Cleyre, and Dora Marsden. Anarcha-feminists, like other radical feminists, criticise and advocate the abolition of traditional conceptions of family, education and gender roles. Green anarchism (or eco-anarchism) is a school of thought within anarchism which puts an emphasis on environmental issues, and whose main contemporary currents are anarcho-primitivism and social ecology. Post-left anarchy is a tendency which seeks to distance itself from traditional left-wing politics and to escape the confines of ideology in general. Post-anarchism is a theoretical move towards a synthesis of classical anarchist theory and poststructuralist thought drawing from diverse ideas including post-modernism, autonomist marxism, post-left anarchy, situationism and postcolonialism. Another recent form of anarchism critical of formal anarchist movements is insurrectionary anarchism, which advocates informal organization and active resistance to the state; its proponents include Wolfi Landstreicher and Alfredo M. Bonanno.
Topics of interest in anarchist theory.
Intersecting and overlapping between various schools of thought, certain topics of interest and internal disputes have proven perennial within anarchist theory.
Free love.
An important current within anarchism is Free love. Free love advocates sometimes traced their roots back to Josiah Warren and to experimental communities, viewed sexual freedom as a clear, direct expression of an individual's self-ownership. Free love particularly stressed women's rights since most sexual laws discriminated against women: for example, marriage laws and anti-birth control measures. The most important American free love journal was "Lucifer the Lightbearer" (1883–1907) edited by Moses Harman and Lois Waisbrooker, but also there existed Ezra Heywood and Angela Heywood's 'The Word' (1872–1890, 1892–1893). Also M. E. Lazarus was an important American individualist anarchist who promoted free love.
In New York's Greenwich Village, bohemian feminists and socialists advocated self-realisation and pleasure for women (and also men) in the here and now. They encouraged playing with sexual roles and sexuality, and the openly bisexual radical Edna St. Vincent Millay and the lesbian anarchist Margaret Anderson were prominent among them. Discussion groups organised by the Villagers were frequented by Emma Goldman, among others. Magnus Hirschfeld noted in 1923 that Goldman "has campaigned boldly and steadfastly for individual rights, and especially for those deprived of their rights. Thus it came about that she was the first and only woman, indeed the first and only American, to take up the defense of homosexual love before the general public." In fact, before Goldman, heterosexual anarchist Robert Reitzel (1849–98) spoke positively of homosexuality from the beginning of the 1890s in his Detroit-based German language journal "Der arme Teufel".
In Europe the main propagandist of free love within individualist anarchism was Emile Armand. He proposed the concept of "la camaraderie amoureuse" to speak of free love as the possibility of voluntary sexual encounter between consenting adults. He was also a consistent proponent of polyamory. In Germany the stirnerists Adolf Brand and John Henry Mackay were pioneering campaigners for the acceptance of male bisexuality and homosexuality.
More recently, the British anarcho-pacifist Alex Comfort gained notoriety during the sexual revolution for writing the bestseller sex manual "The Joy of Sex". The issue of free love has a dedicated treatment in the work of french anarcho-hedonist philosopher Michel Onfray in such works as "Théorie du corps amoureux: pour une érotique solaire" (2000) and "L'invention du plaisir: fragments cyréaniques" (2002).
Libertarian education.
In 1901, Spanish anarchist and free-thinker Francesc Ferrer i Guàrdia established "modern" or progressive schools in Barcelona in defiance of an educational system controlled by the Catholic Church. The schools' stated goal was to "educate the working class in a rational, secular and non-coercive setting". Fiercely anti-clerical, Ferrer believed in "freedom in education", education free from the authority of church and state. Murray Bookchin wrote: "This period [1890s] was the heyday of libertarian schools and pedagogical projects in all areas of the country where Anarchists exercised some degree of influence. Perhaps the best-known effort in this field was Francisco Ferrer's Modern School (Escuela Moderna), a project which exercised a considerable influence on Catalan education and on experimental techniques of teaching generally." La Escuela Moderna, and Ferrer's ideas generally, formed the inspiration for a series of "Modern Schools" in the United States, Cuba, South America and London. The first of these was started in New York City in 1911. It also inspired the Italian newspaper "Università popolare", founded in 1901.
Another libertarian tradition is that of unschooling and the free school in which child-led activity replaces pedagogic approaches. Experiments in Germany led to A. S. Neill founding what became Summerhill School in 1921. Summerhill is often cited as an example of anarchism in practice. However, although Summerhill and other free schools are radically libertarian, they differ in principle from those of Ferrer by not advocating an overtly-political class struggle-approach.
In addition to organizing schools according to libertarian principles, anarchists have also questioned the concept of schooling per se. The term deschooling was popularized by Ivan Illich, who argued that the school as an institution is dysfunctional for self-determined learning and serves the creation of a consumer society instead.
Internal issues and debates.
Anarchism is a philosophy which embodies many diverse attitudes, tendencies and schools of thought; as such, disagreement over questions of values, ideology and tactics is common. The compatibility of capitalism, nationalism and religion with anarchism is widely disputed. Similarly, anarchism enjoys complex relationships with ideologies such as Marxism, communism and capitalism. Anarchists may be motivated by humanism, divine authority, enlightened self-interest or any number of alternative ethical doctrines.
Phenomena such as civilization, technology (e.g. within anarcho-primitivism and insurrectionary anarchism), and the democratic process may be sharply criticised within some anarchist tendencies and simultaneously lauded in others. Anarchist attitudes towards race, gender and the environment have changed significantly since the modern origin of the philosophy in the 18th century.
On a tactical level, while propaganda of the deed was a tactic used by anarchists in the 19th century (e.g. the Nihilist movement), contemporary anarchists espouse alternative direct action methods such as nonviolence, counter-economics and anti-state cryptography to bring about an anarchist society. About the scope of an anarchist society, some anarchists advocate a global one, while others do so by local ones. The diversity in anarchism has led to widely different use of identical terms among different anarchist traditions, which has led to many definitional concerns in anarchist theory.
---END.OF.DOCUMENT---

Autism.
Autism is a disorder of neural development characterized by impaired social interaction and communication, and by restricted and repetitive behavior. These signs all begin before a child is three years old. Autism affects information processing in the brain by altering how nerve cells and their synapses connect and organize; how this occurs is not well understood. The two other autism spectrum disorders (ASD) are Asperger syndrome, which lacks delays in cognitive development and language, and PDD-NOS, diagnosed when full criteria for the other two disorders are not met.
Autism has a strong genetic basis, although the genetics of autism are complex and it is unclear whether ASD is explained more by rare mutations, or by rare combinations of common genetic variants. In rare cases, autism is strongly associated with agents that cause birth defects. Controversies surround other proposed environmental causes, such as heavy metals, pesticides or childhood vaccines; the vaccine hypotheses are biologically implausible and lack convincing scientific evidence. The prevalence of autism is about 1–2 per 1,000 people; the prevalence of ASD is about 6 per 1,000, with about four times as many males as females. The number of people diagnosed with autism has increased dramatically since the 1980s, partly due to changes in diagnostic practice; the question of whether actual prevalence has increased is unresolved.
Parents usually notice signs in the first two years of their child's life. The signs usually develop gradually, but some autistic children first develop more normally and then regress. Although early behavioral or cognitive intervention can help autistic children gain self-care, social, and communication skills, there is no known cure. Not many children with autism live independently after reaching adulthood, though some become successful. An autistic culture has developed, with some individuals seeking a cure and others believing autism should be tolerated as a difference and not treated as a disorder.
Characteristics.
Autism is a highly variable neurodevelopmental disorder that first appears during infancy or childhood, and generally follows a steady course without remission. Overt symptoms gradually begin after the age of six months, become established by age two or three years, and tend to continue through adulthood, although often in more muted form. It is distinguished not by a single symptom, but by a characteristic triad of symptoms: impairments in social interaction; impairments in communication; and restricted interests and repetitive behavior. Other aspects, such as atypical eating, are also common but are not essential for diagnosis. Autism's individual symptoms occur in the general population and appear not to associate highly, without a sharp line separating pathologically severe from common traits.
Social development.
Social deficits distinguish autism and the related autism spectrum disorders (ASD; see "Classification") from other developmental disorders. People with autism have social impairments and often lack the intuition about others that many people take for granted. Noted autistic Temple Grandin described her inability to understand the social communication of neurotypicals, or people with normal neural development, as leaving her feeling "like an anthropologist on Mars".
Unusual social development becomes apparent early in childhood. Autistic infants show less attention to social stimuli, smile and look at others less often, and respond less to their own name. Autistic toddlers differ more strikingly from social norms; for example, they have less eye contact and turn taking, and are more likely to communicate by manipulating another person's hand. Three- to five-year-old autistic children are less likely to exhibit social understanding, approach others spontaneously, imitate and respond to emotions, communicate nonverbally, and take turns with others. However, they do form attachments to their primary caregivers. Most autistic children display moderately less attachment security than non-autistic children, although this difference disappears in children with higher mental development or less severe ASD. Older children and adults with ASD perform worse on tests of face and emotion recognition.
Contrary to a common belief, autistic children do not prefer being alone. Making and maintaining friendships often proves to be difficult for those with autism. For them, the quality of friendships, not the number of friends, predicts how lonely they feel. Functional friendships, such as those resulting in invitations to parties, may affect the quality of life more deeply.
There are many anecdotal reports, but few systematic studies, of aggression and violence in individuals with ASD. The limited data suggest that, in children with mental retardation, autism is associated with aggression, destruction of property, and tantrums. A 2007 study interviewed parents of 67 children with ASD and reported that about two-thirds of the children had periods of severe tantrums and about one-third had a history of aggression, with tantrums significantly more common than in non-autistic children with language impairments. A 2008 Swedish study found that, of individuals aged 15 or older discharged from hospital with a diagnosis of ASD, those who committed violent crimes were significantly more likely to have other psychopathological conditions such as psychosis.
Communication.
About a third to a half of individuals with autism do not develop enough natural speech to meet their daily communication needs. Differences in communication may be present from the first year of life, and may include delayed onset of babbling, unusual gestures, diminished responsiveness, and vocal patterns that are not synchronized with the caregiver. In the second and third years, autistic children have less frequent and less diverse babbling, consonants, words, and word combinations; their gestures are less often integrated with words. Autistic children are less likely to make requests or share experiences, and are more likely to simply repeat others' words (echolalia) or reverse pronouns. Joint attention seems to be necessary for functional speech, and deficits in joint attention seem to distinguish infants with ASD: for example, they may look at a pointing hand instead of the pointed-at object, and they consistently fail to point at objects in order to comment on or share an experience. Autistic children may have difficulty with imaginative play and with developing symbols into language.
In a pair of studies, high-functioning autistic children aged 8–15 performed equally well as, and adults better than, individually matched controls at basic language tasks involving vocabulary and spelling. Both autistic groups performed worse than controls at complex language tasks such as figurative language, comprehension and inference. As people are often sized up initially from their basic language skills, these studies suggest that people speaking to autistic individuals are more likely to overestimate what their audience comprehends.
Repetitive behavior.
Autistic individuals display many forms of repetitive or restricted behavior, which the Repetitive Behavior Scale-Revised (RBS-R) categorizes as follows.
No single repetitive behavior seems to be specific to autism, but only autism appears to have an elevated pattern of occurrence and severity of these behaviors.
Other symptoms.
Autistic individuals may have symptoms that are independent of the diagnosis, but that can affect the individual or the family.
An estimated 0.5% to 10% of individuals with ASD show unusual abilities, ranging from splinter skills such as the memorization of trivia to the extraordinarily rare talents of prodigious autistic savants. Many individuals with ASD show superior skills in perception and attention, relative to the general population.
Sensory abnormalities are found in over 90% of those with autism, and are considered core features by some, although there is no good evidence that sensory symptoms differentiate autism from other developmental disorders. Differences are greater for under-responsivity (for example, walking into things) than for over-responsivity (for example, distress from loud noises) or for sensation seeking (for example, rhythmic movements).
An estimated 60%–80% of autistic people have motor signs that include poor muscle tone, poor motor planning, and toe walking;; deficits in motor coordination are pervasive across ASD and are greater in autism proper.
Unusual eating behavior occurs in about three-quarters of children with ASD, to the extent that it was formerly a diagnostic indicator. Selectivity is the most common problem, although eating rituals and food refusal also occur; this does not appear to result in malnutrition. Although some children with autism also have gastrointestinal (GI) symptoms, there is a lack of published rigorous data to support the theory that autistic children have more or different GI symptoms than usual; studies report conflicting results, and the relationship between GI problems and ASD is unclear.
Parents of children with ASD have higher levels of stress. Siblings of children with ASD report greater admiration of and less conflict with the affected sibling than siblings of unaffected children or those with Down syndrome; siblings of individuals with ASD have greater risk of negative well-being and poorer sibling relationships as adults.
Classification.
Autism is one of the five pervasive developmental disorders (PDD), which are characterized by widespread abnormalities of social interactions and communication, and severely restricted interests and highly repetitive behavior. These symptoms do not imply sickness, fragility, or emotional disturbance.
Of the five PDD forms, Asperger syndrome is closest to autism in signs and likely causes; Rett syndrome and childhood disintegrative disorder share several signs with autism, but may have unrelated causes; PDD not otherwise specified (PDD-NOS; also called "atypical autism") is diagnosed when the criteria are not met for a more specific disorder. Unlike with autism, people with Asperger syndrome have no substantial delay in language development. The terminology of autism can be bewildering, with autism, Asperger syndrome and PDD-NOS often called the "autism spectrum disorders" (ASD) or sometimes the "autistic disorders", whereas autism itself is often called "autistic disorder", "childhood autism", or "infantile autism". In this article, "autism" refers to the classic autistic disorder; in clinical practice, though, "autism", "ASD", and "PDD" are often used interchangeably. ASD, in turn, is a subset of the broader autism phenotype, which describes individuals who may not have ASD but do have autistic-like traits, such as avoiding eye contact.
The manifestations of autism cover a wide spectrum, ranging from individuals with severe impairments—who may be silent, mentally disabled, and locked into hand flapping and rocking—to high functioning individuals who may have active but distinctly odd social approaches, narrowly focused interests, and verbose, pedantic communication. Because the behavior spectrum is continuous, boundaries between diagnostic categories are necessarily somewhat arbitrary. Sometimes the syndrome is divided into low-, medium- or high-functioning autism (LFA, MFA, and HFA), based on IQ thresholds, or on how much support the individual requires in daily life; these subdivisions are not standardized and are controversial. Autism can also be divided into syndromal and non-syndromal autism; the syndromal autism is associated with severe or profound mental retardation or a congenital syndrome with physical symptoms, such as tuberous sclerosis. Although individuals with Asperger syndrome tend to perform better cognitively than those with autism, the extent of the overlap between Asperger syndrome, HFA, and non-syndromal autism is unclear.
Some studies have reported diagnoses of autism in children due to a loss of language or social skills, as opposed to a failure to make progress, typically from 15 to 30 months of age. The validity of this distinction remains controversial; it is possible that regressive autism is a specific subtype, or that there is a continuum of behaviors between autism with and without regression.
Research into causes has been hampered by the inability to identify biologically meaningful subpopulations and by the traditional boundaries between the disciplines of psychiatry, psychology, neurology and pediatrics. Newer technologies such as fMRI and diffusion tensor imaging can help identify biologically relevant phenotypes (observable traits) that can be viewed on brain scans, to help further neurogenetic studies of autism; one example is lowered activity in the fusiform face area of the brain, which is associated with impaired perception of people versus objects. It has been proposed to classify autism using genetics as well as behavior.
Causes.
It has long been presumed that there is a common cause at the genetic, cognitive, and neural levels for autism's characteristic triad of symptoms. However, there is increasing suspicion that autism is instead a complex disorder whose core aspects have distinct causes that often co-occur.
Autism has a strong genetic basis, although the genetics of autism are complex and it is unclear whether ASD is explained more by rare mutations with major effects, or by rare multigene interactions of common genetic variants. Complexity arises due to interactions among multiple genes, the environment, and epigenetic factors which do not change DNA but are heritable and influence gene expression. Studies of twins suggest that heritability is 0.7 for autism and as high as 0.9 for ASD, and siblings of those with autism are about 25 times more likely to be autistic than the general population. However, most of the mutations that increase autism risk have not been identified. Typically, autism cannot be traced to a Mendelian (single-gene) mutation or to a single chromosome abnormality like fragile X syndrome, and none of the genetic syndromes associated with ASDs has been shown to selectively cause ASD. Numerous candidate genes have been located, with only small effects attributable to any particular gene. The large number of autistic individuals with unaffected family members may result from copy number variations—spontaneous deletions or duplications in genetic material during meiosis. Hence, a substantial fraction of autism cases may be traceable to genetic causes that are highly heritable but not inherited: that is, the mutation that causes the autism is not present in the parental genome.
Several lines of evidence point to synaptic dysfunction as a cause of autism. Some rare mutations may lead to autism by disrupting some synaptic pathways, such as those involved with cell adhesion. Gene replacement studies in mice suggest that autistic symptoms are closely related to later developmental steps that depend on activity in synapses and on activity-dependent changes. All known teratogens (agents that cause birth defects) related to the risk of autism appear to act during the first eight weeks from conception, and though this does not exclude the possibility that autism can be initiated or affected later, it is strong evidence that autism arises very early in development. Although evidence for other environmental causes is anecdotal and has not been confirmed by reliable studies, extensive searches are underway. Environmental factors that have been claimed to contribute to or exacerbate autism, or may be important in future research, include certain foods, infectious disease, heavy metals, solvents, diesel exhaust, PCBs, phthalates and phenols used in plastic products, pesticides, brominated flame retardants, alcohol, smoking, illicit drugs, vaccines, and prenatal stress. Parents may first become aware of autistic symptoms in their child around the time of a routine vaccination, and this has given rise to theories that vaccines or their preservatives cause autism. Although these theories lack convincing scientific evidence and are biologically implausible, parental concern about autism has led to lower rates of childhood immunizations and higher likelihood of measles outbreaks.
Mechanism.
Autism's symptoms result from maturation-related changes in various systems of the brain. How autism occurs is not well understood. Its mechanism can be divided into two areas: the pathophysiology of brain structures and processes associated with autism, and the neuropsychological linkages between brain structures and behaviors. The behaviors appear to have multiple pathophysiologies.
Pathophysiology.
Interactions between the immune system and the nervous system begin early during the embryonic stage of life, and successful neurodevelopment depends on a balanced immune response. It is possible that aberrant immune activity during critical periods of neurodevelopment is part of the mechanism of some forms of ASD. Although some abnormalities in the immune system have been found in specific subgroups of autistic individuals, it is not known whether these abnormalities are relevant to or secondary to autism's disease processes. As autoantibodies are found in conditions other than ASD, and are not always present in ASD, the relationship between immune disturbances and autism remains unclear and controversial.
The relationship of neurochemicals to autism is not well understood; several have been investigated, with the most evidence for the role of serotonin and of genetic differences in its transport. Some data suggest an increase in several growth hormones; other data argue for diminished growth factors. Also, some inborn errors of metabolism are associated with autism but probably account for less than 5% of cases.
The mirror neuron system (MNS) theory of autism hypothesizes that distortion in the development of the MNS interferes with imitation and leads to autism's core features of social impairment and communication difficulties. The MNS operates when an animal performs an action or observes another animal perform the same action. The MNS may contribute to an individual's understanding of other people by enabling the modeling of their behavior via embodied simulation of their actions, intentions, and emotions. Several studies have tested this hypothesis by demonstrating structural abnormalities in MNS regions of individuals with ASD, delay in the activation in the core circuit for imitation in individuals with Asperger syndrome, and a correlation between reduced MNS activity and severity of the syndrome in children with ASD. However, individuals with autism also have abnormal brain activation in many circuits outside the MNS and the MNS theory does not explain the normal performance of autistic children on imitation tasks that involve a goal or object.
ASD-related patterns of low function and aberrant activation in the brain differ depending on whether the brain is doing social or nonsocial tasks.
In autism there is evidence for reduced functional connectivity of the default network, a large-scale brain network involved in social and emotional processing, with intact connectivity of the task-positive network, used in sustained attention and goal-directed thinking. In people with autism the two networks are not negatively correlated in time, suggesting an imbalance in toggling between the two networks, possibly reflecting a disturbance of self-referential thought. A 2008 brain-imaging study found a specific pattern of signals in the cingulate cortex which differs in individuals with ASD.
The underconnectivity theory of autism hypothesizes that autism is marked by underfunctioning high-level neural connections and synchronization, along with an excess of low-level processes. Evidence for this theory has been found in functional neuroimaging studies on autistic individuals and by a brain wave study that suggested that adults with ASD have local overconnectivity in the cortex and weak functional connections between the frontal lobe and the rest of the cortex. Other evidence suggests the underconnectivity is mainly within each hemisphere of the cortex and that autism is a disorder of the association cortex.
From studies based on event-related potentials, transient changes to the brain's electrical activity in response to stimuli, there is considerable evidence for differences in autistic individuals with respect to attention, orientiation to auditory and visual stimuli, novelty detection, language and face processing, and information storage; several studies have found a preference for non-social stimuli. For example, magnetoencephalography studies have found evidence in autistic children of delayed responses in the brain's processing of auditory signals.
Neuropsychology.
Two major categories of cognitive theories have been proposed about the links between autistic brains and behavior.
The first category focuses on deficits in social cognition. The empathizing–systemizing theory postulates that autistic individuals can systemize—that is, they can develop internal rules of operation to handle events inside the brain—but are less effective at empathizing by handling events generated by other agents. An extension, the extreme male brain theory, hypothesizes that autism is an extreme case of the male brain, defined psychometrically as individuals in whom systemizing is better than empathizing; this extension is controversial, as many studies contradict the idea that baby boys and girls respond differently to people and objects.
These theories are somewhat related to the earlier theory of mind approach, which hypothesizes that autistic behavior arises from an inability to ascribe mental states to oneself and others. The theory of mind hypothesis is supported by autistic children's atypical responses to the Sally–Anne test for reasoning about others' motivations, and the mirror neuron system theory of autism described in "Pathophysiology" maps well to the hypothesis. However, most studies have found no evidence of impairment in autistic individuals' ability to understand other people's basic intentions or goals; instead, data suggests that impairments are found in understanding more complex social emotions or in considering others' viewpoints.
The second category focuses on nonsocial or general processing. Executive dysfunction hypothesizes that autistic behavior results in part from deficits in working memory, planning, inhibition, and other forms of executive function. Tests of core executive processes such as eye movement tasks indicate improvement from late childhood to adolescence, but performance never reaches typical adult levels. A strength of the theory is predicting stereotyped behavior and narrow interests; two weaknesses are that executive function is hard to measure and that executive function deficits have not been found in young autistic children.
Weak central coherence theory hypothesizes that a limited ability to see the big picture underlies the central disturbance in autism. One strength of this theory is predicting special talents and peaks in performance in autistic people. A related theory—enhanced perceptual functioning—focuses more on the superiority of locally oriented and perceptual operations in autistic individuals. These theories map well from the underconnectivity theory of autism.
Neither category is satisfactory on its own; social cognition theories poorly address autism's rigid and repetitive behaviors, while the nonsocial theories have difficulty explaining social impairment and communication difficulties. A combined theory based on multiple deficits may prove to be more useful.
Screening.
U.S. and Japanese practice is to screen all children for ASD at 18 and 24 months, using autism-specific formal screening tests. In contrast, in the UK, screening targets children whose families or doctors recognize possible signs of autism. It is not known which approach is more effective. Screening tools include the Modified Checklist for Autism in Toddlers (M-CHAT), the Early Screening of Autistic Traits Questionnaire, and the First Year Inventory; initial data on M-CHAT and its predecessor CHAT on children aged 18–30 months suggests that it is best used in a clinical setting and that it has low sensitivity (many false-negatives) but good specificity (few false-positives). It may be more accurate to precede these tests with a broadband screener that does not distinguish ASD from other developmental disorders. Screening tools designed for one culture's norms for behaviors like eye contact may be inappropriate for a different culture. Although genetic screening for autism is generally still impractical, it can be considered in some cases, such as children with neurological symptoms and dysmorphic features.
Diagnosis.
Diagnosis is based on behavior, not cause or mechanism. Autism is defined in the DSM-IV-TR as exhibiting at least six symptoms total, including at least two symptoms of qualitative impairment in social interaction, at least one symptom of qualitative impairment in communication, and at least one symptom of restricted and repetitive behavior. Sample symptoms include lack of social or emotional reciprocity, stereotyped and repetitive use of language or idiosyncratic language, and persistent preoccupation with parts of objects. Onset must be prior to age three years, with delays or abnormal functioning in either social interaction, language as used in social communication, or symbolic or imaginative play. The disturbance must not be better accounted for by Rett syndrome or childhood disintegrative disorder. ICD-10 uses essentially the same definition.
Several diagnostic instruments are available. Two are commonly used in autism research: the Autism Diagnostic Interview-Revised (ADI-R) is a semistructured parent interview, and the Autism Diagnostic Observation Schedule (ADOS) uses observation and interaction with the child. The Childhood Autism Rating Scale (CARS) is used widely in clinical environments to assess severity of autism based on observation of children.
A pediatrician commonly performs a preliminary investigation by taking developmental history and physically examining the child. If warranted, diagnosis and evaluations are conducted with help from ASD specialists, observing and assessing cognitive, communication, family, and other factors using standardized tools, and taking into account any associated medical conditions. A pediatric neuropsychologist is often asked to assess behavior and cognitive skills, both to aid diagnosis and to help recommend educational interventions. A differential diagnosis for ASD at this stage might also consider mental retardation, hearing impairment, and a specific language impairment such as Landau–Kleffner syndrome. The presence of autism can make it harder to diagnose coexisting psychiatric disorders such as depression.
Clinical genetics evaluations are often done once ASD is diagnosed, particularly when other symptoms already suggest a genetic cause. Although genetic technology allows clinical geneticists to link an estimated 40% of cases to genetic causes, consensus guidelines in the U.S. and UK are limited to high-resolution chromosome and fragile X testing. A genotype-first model of diagnosis has been proposed, which would routinely assess the genome's copy number variations. As new genetic tests are developed several ethical, legal, and social issues will emerge. Commercial availability of tests may precede adequate understanding of how to use test results, given the complexity of autism's genetics. Metabolic and neuroimaging tests are sometimes helpful, but are not routine.
ASD can sometimes be diagnosed by age 14 months, although diagnosis becomes increasingly stable over the first three years of life: for example, a one-year-old who meets diagnostic criteria for ASD is less likely than a three-year-old to continue to do so a few years later. In the UK the National Autism Plan for Children recommends at most 30 weeks from first concern to completed diagnosis and assessment, though few cases are handled that quickly in practice. A 2009 U.S. study found the average age of formal ASD diagnosis was 5.7 years, far above recommendations, and that 27% of children remained undiagnosed at age 8 years. Although the symptoms of autism and ASD begin early in childhood, they are sometimes missed; years later, adults may seek diagnoses to help them or their friends and family understand themselves, to help their employers make adjustments, or in some locations to claim disability living allowances or other benefits.
Underdiagnosis and overdiagnosis are problems in marginal cases, and much of the recent increase in the number of reported ASD cases is likely due to changes in diagnostic practices. The increasing popularity of drug treatment options and the expansion of benefits has given providers incentives to diagnose ASD, resulting in some overdiagnosis of children with uncertain symptoms. Conversely, the cost of screening and diagnosis and the challenge of obtaining payment can inhibit or delay diagnosis. It is particularly hard to diagnose autism among the visually impaired, partly because some of its diagnostic criteria depend on vision, and partly because autistic symptoms overlap with those of common blindness syndromes.
Management.
The main goals of treatment are to lessen associated deficits and family distress, and to increase quality of life and functional independence. No single treatment is best and treatment is typically tailored to the child's needs. Families and the educational system are the main resources for treatment. Studies of interventions have methodological problems that prevent definitive conclusions about efficacy. Although many psychosocial interventions have some positive evidence, suggesting that some form of treatment is preferable to no treatment, the methodological quality of systematic reviews of these studies has generally been poor, their clinical results are mostly tentative, and there is little evidence for the relative effectiveness of treatment options. Intensive, sustained special education programs and behavior therapy early in life can help children acquire self-care, social, and job skills, and often improve functioning and decrease symptom severity and maladaptive behaviors; claims that intervention by around age three years is crucial are not substantiated. Available approaches include applied behavior analysis (ABA), developmental models, structured teaching, speech and language therapy, social skills therapy, and occupational therapy. Educational interventions have some effectiveness in children: intensive ABA treatment has demonstrated effectiveness in enhancing global functioning in preschool children and is well-established for improving intellectual performance of young children. Neuropsychological reports are often poorly communicated to educators, resulting in a gap between what a report recommends and what education is provided. It is not known whether treatment programs for children lead to significant improvements after the children grow up, and the limited research on the effectiveness of adult residential programs shows mixed results.
Many medications are used to treat ASD symptoms that interfere with integrating a child into home or school when behavioral treatment fails. More than half of U.S. children diagnosed with ASD are prescribed psychoactive drugs or anticonvulsants, with the most common drug classes being antidepressants, stimulants, and antipsychotics. Aside from antipsychotics, there is scant reliable research about the effectiveness or safety of drug treatments for adolescents and adults with ASD. A person with ASD may respond atypically to medications, the medications can have adverse effects, and no known medication relieves autism's core symptoms of social and communication impairments. Experiments in mice have reversed or reduced some symptoms related to autism by replacing or modulating gene function after birth, suggesting the possibility of targeting therapies to specific rare mutations known to cause autism.
Although many alternative therapies and interventions are available, few are supported by scientific studies. Treatment approaches have little empirical support in quality-of-life contexts, and many programs focus on success measures that lack predictive validity and real-world relevance. Scientific evidence appears to matter less to service providers than program marketing, training availability, and parent requests. Though most alternative treatments, such as melatonin, have only mild adverse effects some may place the child at risk. A 2008 study found that compared to their peers, autistic boys have significantly thinner bones if on casein-free diets; in 2005, botched chelation therapy killed a five-year-old child with autism.
Treatment is expensive; indirect costs are more so. For someone born in 2000, a U.S. study estimated an average lifetime cost of $ (net present value in dollars, inflation-adjusted from 2003 estimate), with about 10% medical care, 30% extra education and other care, and 60% lost economic productivity. Publicly supported programs are often inadequate or inappropriate for a given child, and unreimbursed out-of-pocket medical or therapy expenses are associated with likelihood of family financial problems; one 2008 U.S. study found a 14% average loss of annual income in families of children with ASD, and a related study found that ASD is associated with higher probability that child care problems will greatly affect parental employment. U.S. states increasingly require private health insurance to cover autism services, shifting costs from publicly funded education programs to privately funded health insurance. After childhood, key treatment issues include residential care, job training and placement, sexuality, social skills, and estate planning.
Prognosis.
No cure is known. Children recover occasionally, so that they lose their diagnosis of ASD; this occurs sometimes after intensive treatment and sometimes not. It is not known how often recovery happens; reported rates in unselected samples of children with ASD have ranged from 3% to 25%. A few autistic children have acquired speech at age 5 or older. Most children with autism lack social support, meaningful relationships, future employment opportunities or self-determination. Although core difficulties tend to persist, symptoms often become less severe with age. Few high-quality studies address long-term prognosis. Some adults show modest improvement in communication skills, but a few decline; no study has focused on autism after midlife. Acquiring language before age six, having an IQ above 50, and having a marketable skill all predict better outcomes; independent living is unlikely with severe autism. A 2004 British study of 68 adults who were diagnosed before 1980 as autistic children with IQ above 50 found that 12% achieved a high level of independence as adults, 10% had some friends and were generally in work but required some support, 19% had some independence but were generally living at home and needed considerable support and supervision in daily living, 46% needed specialist residential provision from facilities specializing in ASD with a high level of support and very limited autonomy, and 12% needed high-level hospital care. A 2005 Swedish study of 78 adults that did not exclude low IQ found worse prognosis; for example, only 4% achieved independence. A 2008 Canadian study of 48 young adults diagnosed with ASD as preschoolers found outcomes ranging through poor (46%), fair (32%), good (17%), and very good (4%); 56% of these young adults had been employed at some point during their lives, mostly in volunteer, sheltered or part-time work. Changes in diagnostic practice and increased availability of effective early intervention make it unclear whether these findings can be generalized to recently diagnosed children.
Epidemiology.
Most recent reviews tend to estimate a prevalence of 1–2 per 1,000 for autism and close to 6 per 1,000 for ASD; because of inadequate data, these numbers may underestimate ASD's true prevalence. PDD-NOS's prevalence has been estimated at 3.7 per 1,000, Asperger syndrome at roughly 0.6 per 1,000, and childhood disintegrative disorder at 0.02 per 1,000. The number of reported cases of autism increased dramatically in the 1990s and early 2000s. This increase is largely attributable to changes in diagnostic practices, referral patterns, availability of services, age at diagnosis, and public awareness, though unidentified environmental risk factors cannot be ruled out. The available evidence does not rule out the possibility that autism's true prevalence has increased; a real increase would suggest directing more attention and funding toward changing environmental factors instead of continuing to focus on genetics.
Boys are at higher risk for ASD than girls. The sex ratio averages 4.3:1 and is greatly modified by cognitive impairment: it may be close to 2:1 with mental retardation and more than 5.5:1 without. Although the evidence does not implicate any single pregnancy-related risk factor as a cause of autism, the risk of autism is associated with advanced age in either parent, and with diabetes, bleeding, and use of psychiatric drugs in the mother during pregnancy. The risk is greater with older fathers than with older mothers; two potential explanations are the known increase in mutation burden in older sperm, and the hypothesis that men marry later if they carry genetic liability and show some signs of autism. Most professionals believe that race, ethnicity, and socioeconomic background do not affect the occurrence of autism.
History.
A few examples of autistic symptoms and treatments were described long before autism was named. The "Table Talk" of Martin Luther contains the story of a 12-year-old boy who may have been severely autistic. According to Luther's notetaker Mathesius, Luther thought the boy was a soulless mass of flesh possessed by the devil, and suggested that he be suffocated. The earliest well-documented case of autism is that of Hugh Blair of Borgue, as detailed in a 1747 court case in which his brother successfully petitioned to annul Blair's marriage to gain Blair's inheritance. The Wild Boy of Aveyron, a feral child caught in 1798, showed several signs of autism; the medical student Jean Itard treated him with a behavioral program designed to help him form social attachments and to induce speech via imitation.
The New Latin word "autismus" (English translation "autism") was coined by the Swiss psychiatrist Eugen Bleuler in 1910 as he was defining symptoms of schizophrenia. He derived it from the Greek word "autós" (αὐτός, meaning "self"), and used it to mean morbid self-admiration, referring to "autistic withdrawal of the patient to his fantasies, against which any influence from outside becomes an intolerable disturbance".
The word "autism" first took its modern sense in 1938 when Hans Asperger of the Vienna University Hospital adopted Bleuler's terminology "autistic psychopaths" in a lecture in German about child psychology. Asperger was investigating an ASD now known as Asperger syndrome, though for various reasons it was not widely recognized as a separate diagnosis until 1981. Leo Kanner of the Johns Hopkins Hospital first used "autism" in its modern sense in English when he introduced the label "early infantile autism" in a 1943 report of 11 children with striking behavioral similarities. Almost all the characteristics described in Kanner's first paper on the subject, notably "autistic aloneness" and "insistence on sameness", are still regarded as typical of the autistic spectrum of disorders. It is not known whether Kanner derived the term independently of Asperger.
Kanner's reuse of "autism" led to decades of confused terminology like "infantile schizophrenia", and child psychiatry's focus on maternal deprivation led to misconceptions of autism as an infant's response to "refrigerator mothers". Starting in the late 1960s autism was established as a separate syndrome by demonstrating that it is lifelong, distinguishing it from mental retardation and schizophrenia and from other developmental disorders, and demonstrating the benefits of involving parents in active programs of therapy. As late as the mid-1970s there was little evidence of a genetic role in autism; now it is thought to be one of the most heritable of all psychiatric conditions. Although the rise of parent organizations and the destigmatization of childhood ASD have deeply affected how we view ASD, parents continue to feel social stigma in situations where their autistic children's behaviors are perceived negatively by others, and many primary care physicians and medical specialists still express some beliefs consistent with outdated autism research. The Internet has helped autistic individuals bypass nonverbal cues and emotional sharing that they find so hard to deal with, and has given them a way to form online communities and work remotely. Sociological and cultural aspects of autism have developed: some in the community seek a cure, while others believe that autism is simply another way of being.
---END.OF.DOCUMENT---

Albedo.
The albedo of an object is a measure of how strongly it reflects light from light sources such as the Sun. It is therefore a more specific form of the term reflectivity. Albedo is defined as the ratio of total-reflected to incident electromagnetic radiation. It is a unitless measure indicative of a surface's or body's diffuse reflectivity. The word is derived from Latin "albedo" "whiteness", in turn from "albus" "white", and was introduced into optics by Johann Heinrich Lambert in his 1760 work "Photometria". The range of possible values is from 0 (dark) to 1 (bright).
The albedo is an important concept in climatology and astronomy, as well as in computer graphics and computer vision. In climatology it is sometimes expressed as a percentage. Its value depends on the frequency of radiation considered: unqualified, it usually refers to some appropriate average across the spectrum of visible light. In general, the albedo depends on the direction and directional distribution of incoming radiation. Exceptions are Lambertian surfaces, which scatter radiation in all directions in a cosine function, so their albedo does not depend on the incoming distribution. In realistic cases, a bidirectional reflectance distribution function (BRDF) is required to characterize the scattering properties of a surface accurately, although albedos are a very useful first approximation.
Terrestrial albedo.
Albedos of typical materials in visible light range from up to 0.9 for fresh snow, to about 0.04 for charcoal, one of the darkest substances. Deeply shadowed cavities can achieve an effective albedo approaching the zero of a blackbody. When seen from a distance, the ocean surface has a low albedo, as do most forests, while desert areas have some of the highest albedos among landforms. Most land areas are in an albedo range of 0.1 to 0.4. The average albedo of the Earth is about 0.3. This is far higher than for the ocean primarily because of the contribution of clouds.
Human activities have changed the albedo (via forest clearance and farming, for example) of various areas around the globe. However, quantification of this effect on the global scale is difficult.
The classic example of albedo effect is the snow-temperature feedback. If a snow-covered area warms and the snow melts, the albedo decreases, more sunlight is absorbed, and the temperature tends to increase. The converse is true: if snow forms, a cooling cycle happens. The intensity of the albedo effect depends on the size of the change in albedo and the amount of insolation; for this reason it can be potentially very large in the tropics.
The Earth's surface albedo is regularly estimated via Earth observation satellite sensors such as NASA's MODIS instruments onboard the Terra and Aqua satellites. As the total amount of reflected radiation cannot be directly measured by satellite, a mathematical model of the BRDF is used to translate a sample set of satellite reflectance measurements into estimates of directional-hemispherical reflectance and bi-hemispherical reflectance. (e. g.,
The Earth's average surface temperature due to its albedo and the greenhouse effect is currently about 15°C. For the frozen (more reflective) planet the average temperature is below -40°C (If only all continents being completely covered by glaciers - the mean temperature is about 0°C). The simulation for (more absorptive) aquaplanet shows the average temperature close to 27°C.
White-sky and black-sky albedo.
It has been shown that for many applications involving terrestrial albedo, the albedo at a particular solar zenith angle formula_1 can reasonably be approximated by the proportionate sum of two terms: the directional-hemispherical reflectance at that solar zenith angle, formula_2, and the bi-hemispherical reflectance, formula_3 the proportion concerned being defined as the proportion of diffuse illumination formula_4.
Directional-hemispherical reflectance is sometimes referred to as black-sky albedo and bi-hemispherical reflectance as white sky albedo. These terms are important because they allow the albedo to be calculated for any given illumination conditions from a knowledge of the intrinsic properties of the surface.
Astronomical albedo.
The albedos of planets, satellites and asteroids can be used to infer much about their properties. The study of albedos, their dependence on wavelength, lighting angle ("phase angle"), and variation in time comprises a major part of the astronomical field of photometry. For small and far objects that cannot be resolved by telescopes, much of what we know comes from the study of their albedos. For example, the absolute albedo can indicate the surface ice content of outer solar system objects, the variation of albedo with phase angle gives information about regolith properties, while unusually high radar albedo is indicative of high metallic content in asteroids.
Enceladus, a moon of Saturn, has one of the highest known albedos of any body in the Solar system, with 99% of EM radiation reflected. Another notable high albedo body is Eris, with an albedo of 0.86. Many small objects in the outer solar system and asteroid belt have low albedos down to about 0.05. A typical comet nucleus has an albedo of 0.04. Such a dark surface is thought to be indicative of a primitive and heavily space weathered surface containing some organic compounds.
The overall albedo of the Moon is around 0.072, but it is strongly directional and non-Lambertian, displaying also a strong opposition effect. While such reflectance properties are different from those of any terrestrial terrains, they are typical of the regolith surfaces of airless solar system bodies.
Two common albedos that are used in astronomy are the (V-band) geometric albedo (measuring brightness when illumination comes from directly behind the observer) and the Bond albedo (measuring total proportion of electromagnetic energy reflected). Their values can differ significantly, which is a common source of confusion.
In detailed studies, the directional reflectance properties of astronomical bodies are often expressed in terms of the five Hapke parameters which semi-empirically describe the variation of albedo with phase angle, including a characterization of the opposition effect of regolith surfaces.
formula_7,
where formula_8 is the astronomical albedo, formula_9 is the diameter in kilometres, and "H" is the absolute magnitude.
Other types of albedo.
Single scattering albedo is used to define scattering of electromagnetic waves on small particles. It depends on properties of the material (refractive index); the size of the particle or particles; and the wavelength of the incoming radiation.
Albedo also refers to the white, spongy inner lining of a citrus fruit rind. According to Dr. Renee M. Goodrich, associate professor of food science and human nutrition at the University of Florida, the albedo is rich in the soluble fiber pectin and contains vitamin C.
The tropics.
Although the albedo-temperature effect is most famous in colder regions of Earth, because more snow falls there, it is actually much stronger in tropical regions because in the tropics there is consistently more sunlight. When ranchers cut down dark, tropical rainforest trees to replace them with even darker soil in order to grow crops, the average temperature of the area increases up to 3 °C (5.4 °F) year-round, although part of the effect is due to changed evaporation (latent heat flux).
Small scale effects.
Albedo works on a smaller scale, too. People who wear dark clothes in the summertime put themselves at a greater risk of heatstroke than those who wear lighter color clothes.
Trees.
Because trees tend to have a low albedo, removing forests would tend to increase albedo and thereby could produce localized climate cooling. Cloud feedbacks further complicate the issue. In seasonally snow-covered zones, winter albedos of treeless areas are 10% to 50% higher than nearby forested areas because snow does not cover the trees as readily. Deciduous trees have an albedo value of about 0.15 to 0.18 while coniferous trees have a value of about 0.09 to 0.15. The difference between deciduous and coniferous is because coniferous trees are darker in general and have cone-shaped crowns. The shape of these crowns trap radiant energy more effectively than deciduous trees.
Studies by the Hadley Centre have investigated the relative (generally warming) effect of albedo change and (cooling) effect of carbon sequestration on planting forests. They found that new forests in tropical and midlatitude areas tended to cool; new forests in high latitudes (e.g. Siberia) were neutral or perhaps warming.
Snow.
Snow albedos can be as high as 0.9; this, however, is for the ideal example: fresh deep snow over a featureless landscape. Over Antarctica they average a little more than 0.8. If a marginally snow-covered area warms, snow tends to melt, lowering the albedo, and hence leading to more snowmelt (the ice-albedo positive feedback).
Water.
Water reflects light very differently from typical terrestrial materials. The reflectivity of a water surface is calculated using the Fresnel equations (see graph).
At the scale of the wavelength of light even wavy water is always smooth so the light is reflected in a specular manner (not diffusely). The glint of light off water is a commonplace effect of this. At small angles of incident light, waviness results in reduced reflectivity because of the steepness of the reflectivity-vs.-incident-angle curve and a locally increased average incident angle.
Although the reflectivity of water is very low at low and medium angles of incident light, it increases tremendously at high angles of incident light such as occur on the illuminated side of the Earth near the terminator (early morning, late afternoon and near the poles). However, as mentioned above, waviness causes an appreciable reduction. Since the light specularly reflected from water does not usually reach the viewer, water is usually considered to have a very low albedo in spite of its high reflectivity at high angles of incident light.
Note that white caps on waves look white (and have high albedo) because the water is foamed up (not smooth at the scale of the wavelength of light) so the Fresnel equations do not apply. Fresh ‘black’ ice exhibits Fresnel reflection.
Clouds.
Clouds are another source of albedo that play into the global warming equation. Different types of clouds have different albedo values, theoretically ranging from a minimum of near 0 to a maximum approaching 0.8. "On any given day, about half of Earth is covered by clouds, which reflect more sunlight than land and water. Clouds keep Earth cool by reflecting sunlight, but they can also serve as blankets to trap warmth."
Albedo and climate in some areas are already affected by artificial clouds, such as those created by the contrails of heavy commercial airliner traffic. A study following the burning of the Kuwaiti oil fields by Saddam Hussein showed that temperatures under the burning oil fires were as much as 10oC colder than temperatures several miles away under clear skies.
Aerosol effects.
Aerosol (very fine particles/droplets in the atmosphere) has two effects, direct and indirect. The direct (albedo) effect is generally to cool the planet; the indirect effect (the particles act as CCNs and thereby change cloud properties) is less certain.
Aerosols can modify the Earth’s radiative balance through the aerosol direct and indirect
Black carbon.
Another albedo-related effect on the climate is from black carbon particles. The size of this effect is difficult to quantify: the IPCC say that their "estimate of the global mean radiative forcing for BC aerosols from fossil fuels is... +0.2 W m-2 (from +0.1 W m-2 in the SAR) with a range +0.1 to +0.4 W m...-2".
---END.OF.DOCUMENT---

A.
The letter A is the first letter in the Latin alphabet, a vowel. Its name in English () is spelled ‹a›; the plural is "aes," although this is rare.
Origins.
"A" can be traced to a pictogram of an ox head in Egyptian hieroglyph or the Proto-Sinaitic alphabet.
In 1600 B.C. the Phoenician alphabet's letter had a linear form that served as the base for some later forms. Its name must have corresponded closely to the Hebrew or Arabic aleph.
When the Ancient Greeks adopted the alphabet, they had no use for the glottal stop that the letter had denoted in Phoenician and other Semitic languages, so they used the sign to represent the vowel, and kept its name with a minor change (alpha). In the earliest Greek inscriptions after the Greek Dark Ages, dating to the 8th century BC, the letter rests upon its side, but in the Greek alphabet of later times it generally resembles the modern capital letter, although many local varieties can be distinguished by the shortening of one leg, or by the angle at which the cross line is set.
The Etruscans brought the Greek alphabet to their civilization in the Italian Peninsula and left the letter unchanged. The Romans later adopted the Etruscan alphabet to write the Latin language, and the resulting letter was preserved in the modern Latin alphabet used to write many languages, including English.
The letter has two minuscule (lower-case) forms. The form used in most current handwriting consists of a circle and vertical stoke (), called Latin alpha or "script a". Most printed material uses a form consisting of a small loop with an arc over it (). Both derive from the majuscule (capital) form. In Greek handwriting, it was common to join the left leg and horizontal stroke into a single loop, as demonstrated by the Uncial version shown. Many fonts then made the right leg vertical. In some of these, the serif that began the right leg stroke developed into an arc, resulting in the printed form, while in others it was dropped, resulting in the modern handwritten form.
Usage.
In English, "a" by itself frequently denotes the near-open front unrounded vowel () as in "pad", the open back unrounded vowel () as in "father", or, in concert with a later orthographic vowel, the diphthong as in "ace" and "major", due to effects of the great vowel shift.
In most other languages that use the Latin alphabet, "a" denotes an open central unrounded vowel (). In the International Phonetic Alphabet, variants of "a" denote various vowels. In X-SAMPA, capital "A" denotes the open back unrounded vowel and lowercase "a" denotes the open front unrounded vowel.
"A" is the third common used letter in English, and the second most common in Spanish and French. In one study, on average, about 3.68% of letters used in English tend to be ‹a›s, while the number is 6.22% in Spanish and 3.95% in French.
"A" is often used to denote something or someone of a better or more prestigious quality or status: A-, A or A+, the best grade that can be assigned by teachers for students' schoolwork; A grade for clean restaurants; A-List celebrities, etc. Such associations can have a motivating effect as exposure to the letter A has been found to improve performance, when compared with other letters.
A turned "a" () is used by the International Phonetic Alphabet for the near-open central vowel, while a turned capital "A" ("∀") is used in predicate logic to specify universal quantification.
Codes for computing.
In Unicode the capital "A" is codepoint U+0043 and the lower case "a" is U+0067.
The ASCII code for capital "A" is 65 and for lower case "a" is 97; or in binary 01000001 and 01100001, respectively.
The EBCDIC code for capital "A" is 193 and for lowercase "a" is 129.
The numeric character references in HTML and XML are "&amp;#65;" and "&amp;#97;" for upper and lower case, respectively.
---END.OF.DOCUMENT---

Alabama.
Alabama is a state located in the southeastern region of the United States of America. It is bordered by Tennessee to the north, Georgia to the east, Florida and the Gulf of Mexico to the south, and Mississippi to the west. Alabama ranks 30th in total land area and ranks second in the size of its inland waterways. The state ranks 23rd in population with almost 4.6 million residents in 2006.
From the American Civil War until World War II, Alabama, like many Southern states, suffered economic hardship, in part because of continued dependence on agriculture. White rural interests dominated the state legislature until the 1960s, while urban interests and African Americans were underrepresented. Following World War II, Alabama experienced significant recovery as the economy of the state transitioned from agriculture to diversified interests in heavy manufacturing, mineral extraction, education, and technology, as well as the establishment or expansion of multiple military installations, primarily those of the U.S. Army and U.S. Air Force. The state has heavily invested in aerospace, education, health care, and banking, and various heavy industries including automobile manufacturing, mineral extraction, steel production and fabrication.
Alabama is unofficially nicknamed the "Yellowhammer State", which is also the name of the state bird. Alabama is also known as the "Heart of Dixie". The state tree is the Longleaf Pine, the state flower is the Camellia. The capital of Alabama is Montgomery, and the largest city by population is Birmingham. The largest city by total land area is Huntsville. The oldest city is Mobile.
Etymology of state name.
The Alabama, a Muskogean tribe whose members lived just below the confluence of the Coosa and Tallapoosa Rivers on the upper reaches of the Alabama River, served as the etymological source of the names of the river and state. In the Alabama language, the word for an Alabama person is "Albaamo" (or variously "Albaama" or "Albàamo" in different dialects; the plural form "Alabama persons" is "Albaamaha"). The word "Alabama" is believed to have originated from the Choctaw language and was later adopted by the Alabama tribe as their name. The spelling of the word varies significantly between sources. The first usage appears in three accounts of the Hernando de Soto expedition of 1540 with Garcilasso de la Vega using "Alibamo" while the Knight of Elvas and Rodrigo Ranjel wrote "Alibamu" and "Limamu", respectively. As early as 1702, the tribe was known to the French as "Alibamon" with French maps identifying the river as "Rivière des Alibamons". Other spellings of the appellation have included "Alibamu", "Alabamo", "Albama", "Alebamon", "Alibama", "Alibamou", "Alabamu", and "Allibamou".
Although the origin of "Alabama" was evident, the meaning of the tribe's name was not always clear. An article without a byline appearing in the "Jacksonville Republican" on July 27, 1842, originated the idea that the meaning was "Here We Rest." This notion was popularized in the 1850s through the writings of Alexander Beaufort Meek. Experts in the Muskogean languages have been unable to find any evidence that would support this translation. It is now generally accepted that the word comes from the Choctaw words "alba" (meaning "plants" or "weeds") and "amo" (meaning "to cut", "to trim", or "to gather"). This results in translations such as "clearers of the thicket" or even "herb gatherers" which may refer to clearing of land for the purpose of planting crops or to collection of medicinal plants by medicine men.
History.
Among the Native American people once living in the area of present day Alabama were Alabama ("Alibamu"), Cherokee, Chickasaw, Choctaw, Creek, Koasati, and Mobile. Trade with the Northeast via the Ohio River began during the Burial Mound Period (1000 BC-700 AD) and continued until European contact. The agrarian Mississippian culture covered most of the state from 1000 to 1600 AD, with one of its major centers being at the Moundville Archaeological Site in Moundville, Alabama. Artifacts recovered from archaeological excavations at Moundville were a major component in the formulation of the Southeastern Ceremonial Complex. Contrary to popular belief, this development appears to have no direct links to Mesoamerica, but developed independently. This Ceremonial Complex represents a major component of the religion of the Mississippian peoples, and is one of the primary means by which their religion is understood.
The French founded the first European settlement in the state with the establishment of Mobile in 1702. Southern Alabama was French from 1702 to 1763, part of British West Florida from 1763 to 1780, and part of Spanish West Florida from 1780 to 1814. Northern and central Alabama was part of British Georgia from 1763 to 1783 and part of the American Mississippi territory thereafter. Its statehood was delayed by the lack of a coastline; rectified when Andrew Jackson captured Spanish Mobile in 1814. Alabama was the twenty-second state, admitted to the Union in 1819. Its constitution provided for universal suffrage for white men.
Alabama was part of the new frontier in the 1820s and 1830s. Settlers rapidly arrived to take advantage of its fertile soil. Planters brought slaves with them, and traders brought in more from the Upper South as the cotton plantations expanded. The economy of the central "Black Belt" was built around large cotton plantations whose owners built their wealth on slave labor. It was named for the dark, productive soil. Elsewhere poor whites were subsistence farmers. According to the 1860 census, enslaved Africans comprised 45% of the state's population of 964,201. There were only 2,690 free persons of color.
In 1861 Alabama declared its secession from the Union and joined the Confederate States of America. While few battles were fought in the state, Alabama contributed about 120,000 soldiers to the Civil War. All the slaves were freed by 1865. Following Reconstruction, Alabama was restored to the Union in 1868.
After the Civil War, the state was still chiefly rural and tied to cotton. Planters resisted working with free labor and sought to re-establish controls over African Americans. Whites used paramilitary groups, Jim Crow laws and segregation to reduce freedoms of African Americans and restore their own dominance.
In its new constitution of 1901, the legislature effectively disfranchised African Americans through voting restrictions. While the planter class had engaged poor whites in supporting these efforts, the new restrictions resulted in disfranchising poor whites as well. By 1941, a total of more whites than blacks had been disfranchised: 600,000 whites to 520,000 blacks. This was due mostly to effects of the cumulative poll tax.
The damage to the African-American community was pervasive, as nearly all its citizens lost the ability to vote. In 1900, fourteen Black Belt counties (which were primarily African American) had more than 79,000 voters on the rolls. By June 1, 1903, the number of registered voters had dropped to 1,081. In 1900, Alabama had more than 181,000 African Americans eligible to vote. By 1903, only 2,980 had managed to "qualify" to register, although at least 74,000 black voters were literate. The shut out was long-lasting. The disfranchisement was ended only by African Americans leading the Civil Rights Movement and gaining Federal legislation in the mid-1960s to protect their voting and civil rights. The Voting Rights Act of 1965 also protected the suffrage of poor whites.
The rural-dominated legislature continued to underfund schools and services for African Americans in the segregated state, but did not relieve them of paying taxes. Continued racial discrimination, agricultural depression, and the failure of the cotton crops due to boll weevil infestation led tens of thousands of African Americans to seek out opportunities in northern cities. They left Alabama in the early 20th century as part of the Great Migration to industrial jobs and better futures in northern industrial cities. The population growth rate in Alabama (see "Historical Populations" table below) dropped by nearly half from 1910–1920, reflecting the effect of outmigration.
At the same time, many rural whites and blacks migrated to the city of Birmingham for work in new industrial jobs. It experienced such rapid growth that it was nicknamed "The Magic City". By the 1920s, Birmingham was the 19th largest city in the U.S. and held more than 30% of the population of the state. Heavy industry and mining were the basis of the economy.
Despite massive population changes in the state from 1901 to 1961, the rural-dominated legislature refused to reapportion House and Senate seats based on population. They held on to old representation to maintain political and economic power in agricultural areas. In addition, the state legislature gerrymandered the few Birmingham legislative seats to ensure election by persons living outside of Birmingham.
One result was that Jefferson County, containing Birmingham's industrial and economic powerhouse, contributed more than one-third of all tax revenue to the state. Urban interests were consistently underrepresented in the legislature. A 1960 study noted that because of rural domination, "A minority of about 25 per cent of the total state population is in majority control of the Alabama legislature."
African Americans were presumed partial to Republicans for historical reasons, but they were disenfranchised. White Alabamans still felt bitter towards the Republican Party in the aftermath of the Civil War and Reconstruction. These factors created a longstanding tradition that any candidate who wanted to be viable with white voters had to run as a Democrat regardless of political beliefs. The state continued as one-party Democratic for more than a century after Reconstruction ended. It produced a number of national leaders. Industrial development related to the demands of World War II brought prosperity. Cotton faded in importance as the state developed a manufacturing and service base. In the 1960s under Governor George Wallace, many whites in the state opposed integration efforts.
During the Civil Rights Movement, African Americans achieved a protection of voting and other civil rights through the passage of the national Civil Rights Act of 1964, and the Voting Rights Act of 1965. "De jure" segregation ended in the states as Jim Crow laws were invalidated or repealed.
Under the Voting Rights Act of 1965, cases were filed in Federal courts to force Alabama to properly redistrict by population both the state legislature House and Senate. In 1972, for the first time since 1901, the legislature implemented the Alabama constitution's provision for periodic redistricting based on population. This benefited the many urban areas that had developed, and all in the population who had been underrepresented for more than 60 years.
After 1972, the state's white voters shifted much of their support to Republican candidates in presidential elections (as also occurred in neighboring southern states). Since 1990 the majority of whites in the state have also voted increasingly Republican in state elections, although Democrats are still the majority party in both houses of the legislature.
Geography.
Alabama is the thirtieth largest state in the United States with 52,423 square miles (135,775 km²) of total area: 3.19% of the area is water, making Alabama twenty-third in the amount of surface water, also giving it the second largest inland waterway system in the United States. About three-fifths of the land area is a gentle plain with a general descent towards the Mississippi River and the Gulf of Mexico. The North Alabama region is mostly mountainous, with the Tennessee River cutting a large valley creating numerous creeks, streams, rivers, mountains, and lakes.
The states bordering Alabama are Tennessee to the north; Georgia to the east; Florida to the south; and Mississippi to the west. Alabama has coastline at the Gulf of Mexico, in the extreme southern edge of the state. Alabama ranges in elevation from sea level at Mobile Bay to over 1,800 feet (550 m) in the Appalachian Mountains in the northeast. The highest point is Mount Cheaha, at a height of. Alabama's land consists of of forest or 67% of total land area. Suburban Baldwin County, along the Gulf Coast, is the largest county in the state in both land area and water area.
Areas in Alabama administered by the National Park Service include Horseshoe Bend National Military Park near Alexander City; Little River Canyon National Preserve near Fort Payne; Russell Cave National Monument in Bridgeport; Tuskegee Airmen National Historic Site in Tuskegee; and Tuskegee Institute National Historic Site near Tuskegee. Additionally, Alabama has four National Forests including Conecuh, Talladega, Tuskegee, and William B. Bankhead. Alabama also contains the Natchez Trace Parkway, the Selma To Montgomery National Historic Trail, and the Trail Of Tears National Historic Trail. A notable natural wonder in Alabama is "Natural Bridge" rock, the longest natural bridge east of the Rockies, located just south of Haleyville, in Winston County.
A -wide meteorite impact crater is located in Elmore County, just north of Montgomery. This is the Wetumpka crater, which is the site of "Alabama's greatest natural disaster". A -wide meteorite hit the area about 80 million years ago. The hills just east of downtown Wetumpka showcase the eroded remains of the impact crater that was blasted into the bedrock, with the area labeled the Wetumpka crater or astrobleme ("star-wound") because of the concentric rings of fractures and zones of shattered rock that can be found beneath the surface. In 2002, Christian Koeberl with the Institute of Geochemistry University of Vienna published evidence and established the site as an internationally recognized impact crater.
Climate.
The state is classified as humid subtropical ("Cfa") under the Koppen Climate Classification. The average annual temperature is 64 °F (18 °C). Temperatures tend to be warmer in the southern part of the state with its proximity to the Gulf of Mexico, while the northern parts of the state, especially in the Appalachian Mountains in the northeast, tend to be slightly cooler. Generally, Alabama has very hot summers and mild winters with copious precipitation throughout the year. Alabama receives an average of of rainfall annually and enjoys a lengthy growing season of up to 300 days in the southern part of the state.
Summers in Alabama are among the hottest in the United States, with high temperatures averaging over throughout the summer in some parts of the state. Alabama is also prone to tropical storms and even hurricanes. Areas of the state far away from the Gulf are not immune to the effects of the storms, which often dump tremendous amounts of rain as they move inland and weaken.
South Alabama reports more thunderstorms than any part of the U.S. The Gulf Coast, around Mobile Bay, averages between 70 and 80 days per year with thunder reported. This activity decreases somewhat further north in the state, but even the far north of the state reports thunder on about 60 days per year. Occasionally, thunderstorms are severe with frequent lightning and large hail – the central and northern parts of the state are most vulnerable to this type of storm. Alabama ranks seventh in the number of deaths from lightning and ninth in the number of deaths from lightning strikes per capita. Sometimes tornadoes occur – these are common throughout the state, although the peak season for tornadoes varies from the northern to southern parts of the state. Alabama shares the dubious distinction, with Kansas, of having reported more EF5 tornadoes than any other state – according to statistics from the National Climatic Data Center for the period January 1, 1950, to October 31, 2006. An F5 tornado is the most powerful of its kind. Several long – tracked F5 tornadoes have contributed to Alabama reporting more tornado fatalities than any other state except for Texas and Mississippi. The Super Outbreak in March 1974, badly affected Alabama. The northern part of the state – along the Tennessee Valley – is one of the areas in the US most vulnerable to violent tornadoes. The area of Alabama and Mississippi most affected by tornadoes is sometimes referred to as Dixie Alley, as distinct from the Tornado Alley of the Southern Plains. Alabama is one of the few places in the world that has a secondary tornado season (November and December) along with the spring severe weather season.
Winters are generally mild in Alabama, as they are throughout most of the southeastern United States, with average January low temperatures around in Mobile and around in Birmingham. Although snow is a rare event in much of Alabama, areas of the state north of Montgomery may receive a dusting of snow a few times every winter, with an occasional moderately heavy snowfall every few years. For example, the annual average snowfall for the Birmingham area is 2 inches per year. In the southern Gulf coast, snowfall is less frequent, sometimes going several years without any snowfall.
Demographics.
The United States Census Bureau, as of July 1, 2008, estimated Alabama's population at 4,661,900, which represents an increase of 214,545, or 4.8%, since the last census in 2000. This includes a natural increase since the last census of 121,054 people (that is 502,457 births minus 381,403 deaths) and an increase due to net migration of 104,991 people into the state. Immigration from outside the United States resulted in a net increase of 31,180 people, and migration within the country produced a net gain of 73,811 people. The state had 108,000 foreign-born (2.4% of the state population), of which an estimated 22.2% were illegal immigrants (24,000).
The center of population of Alabama is located in Chilton County, outside of the town of Jemison, an area known as Jemison Division.
Race and ancestry.
The largest reported ancestry groups in Alabama: African American (26.0%), American (17.0%), English (7.8%), Irish (7.7%), German (5.7%), and Scots-Irish (2.0%). 'American' does not include those reported as Native American.
Religion.
Alabama is located in the middle of the Bible Belt. In a 2007 survey, nearly 70% of respondents could name all four of the Christian Gospels. Of those who indicated a religious preference, 59% said they possessed a "full understanding" of their faith and needed no further learning. In a 2007 poll, 92% of Alabamians reported having at least some confidence in churches in the state. The Mobile area is notable for its large percentage of Catholics, owing to the area's unique early history under French and Spanish rule. Today, a majority of Alabamians identify themselves as Protestants.
In the 2008 American Religious Identification Survey, 80% of Alabama respondents reported their religion as "Other Christian" (survey's label), 6% as Catholic, and 11% as having no religion at all.
Economy.
According to the United States Bureau of Economic Analysis, the 2008 total gross state product was $170 billion, or $29,411 per capita. Alabama's 2008 GDP increased 0.7% from the previous year. The single largest increase came in the area of information. In 1999, per capita income for the state was $18,189.
Alabama's agricultural outputs include poultry and eggs, cattle, plant nursery items, peanuts, cotton, grains such as corn and sorghum, vegetables, milk, soybeans, and peaches. Although known as "The Cotton State", Alabama ranks between eight and ten in national cotton production, according to various reports, with Texas, Georgia and Mississippi comprising the top three.
Alabama's industrial outputs include iron and steel products (including cast-iron and steel pipe); paper, lumber, and wood products; mining (mostly coal); plastic products; cars and trucks; and apparel. Also, Alabama produces aerospace and electronic products, mostly in the Huntsville area, location of NASA George C. Marshall Space Flight Center and the US Army Aviation and Missile Command, headquartered at Redstone Arsenal.
Alabama contains the largest industrial growth corridor in the nation, including the surrounding states of Tennessee, Mississippi, Florida, and Georgia. Most of this growth is due to Alabama's rapidly expanding automotive manufacturing industry. Headquartered in the state are Honda Manufacturing of Alabama, Hyundai Motor Manufacturing Alabama, Mercedes-Benz U.S. International, and Toyota Motor Manufacturing Alabama. Since 1993, the automobile industry has generated more than 67,800 new jobs in the state. Alabama currently ranks 4th in the nation in automobile output.
In the 1970s and 1980s, Birmingham's economy was transformed by investments in bio-technology and medical research at the University of Alabama at Birmingham (UAB) and its adjacent hospital. The UAB Hospital is a Level I trauma center providing health care and breakthrough medical research. UAB is now the area's largest employer and the largest in Alabama with a workforce of about 20,000. Health care services provider HealthSouth is also headquartered in the city.
Birmingham is also a leading banking center, headquarters of the Regions Financial Corporation. Birmingham-based Compass Banchshares was acquired by Madrid-based BBVA in September 2007; the headquarters of the new BBVA Compass Bank remains in Birmingham. SouthTrust, another large bank headquartered in Birmingham, was acquired by Wachovia in 2004. The city still has major operations as one of the regional headquarters of Wachovia. In November 2006, Regions Financial merged with AmSouth Bancorporation, which was also headquartered in Birmingham. They formed the eighth largest U.S. bank based on by total assets. Nearly a dozen smaller banks are also headquartered in the Magic City, such as Superior Bank and New South Federal Savings Bank.
Telecommunications provider AT&T, formerly BellSouth, has a major presence with several large offices in the metropolitan area. Major insurance providers: Protective Life, Infinity Property & Casualty and ProAssurance among others, are headquartered in Birmingham and employ a large number of people in Greater Birmingham. The city is also a powerhouse of construction and engineering companies, including BE&K and B. L. Harbert International which routinely are included in the Engineering News-Record lists of top design and international construction firms.
Huntsville is regarded for its high-technology driven economy and is known as the "Rocket City" because of NASA's Marshall Space Flight Center and the Redstone Arsenal. Huntsville's main economic influence is derived from aerospace and military technology. Redstone Arsenal, Cummings Research Park (CRP), The University of Alabama in Huntsville and NASA's Marshall Space Flight Center comprise the main hubs for the area's technology-driven economy. CRP is the second largest research park in the United States and the fourth largest in the world, and is over 38 years old. Huntsville has commercial technology companies such as the network access company ADTRAN, computer graphics company Intergraph and design and manufacturer of IT infrastructure Avocent. Telecommunications provider Deltacom, Inc. and copper tube manufacturer and distributor Wolverine Tube are also based in Huntsville. Cinram manufactures and distributes 20th Century Fox DVDs and Blu-ray Discs out of their Huntsville plant. Sanmina-SCI also has a large presence in the area. Forty-two Fortune 500 companies have operations in Huntsville. In 2005, Forbes Magazine named the Huntsville-Decatur Combined Statistical Area as 6th best place in the nation for doing business, and number one in terms of the number of engineers per total employment.
The city of Mobile, Alabama's only saltwater port, is a busy seaport on the Gulf of Mexico with inland waterway access to the Midwest by way of the Tennessee-Tombigbee Waterway. The Port of Mobile is currently the 9th largest by tonnage in the United States. In May 2007, a site north of Mobile was selected by German steelmaker ThyssenKrupp for a $3.7 billion steel production plant, with the promise of 2,700 permanent jobs.
Taxes.
Alabama's tax structure is one the most regressive in the United States. Alabama levies a 2, 4, or 5 percent personal income tax, depending upon the amount earned and filing status, though taxpayers can deduct their federal income tax from their Alabama state tax.
The state's general sales tax rate is 4%. The collection rate could be substantially higher, depending upon additional city and county sales taxes. For example, the total sales tax rate in Mobile is 9% and there is an additional restaurant tax of 1%, which means that a diner in Mobile would pay a 10% tax on a meal. Sales and excise taxes in Alabama account for 51 percent of all state and local revenue, compared with an average of about 36 percent nationwide. Alabama is also one of the few remaining states that levies a tax on food and medicine. Alabama's income tax on poor working families is among the nation's very highest. Alabama is the only state that levies income tax on a family of four with income as low as $4,600, which is barely one-quarter of the federal poverty line. Alabama's threshold is the lowest among the 41 states and the District of Columbia with income taxes.
The corporate income tax rate is currently 6.5%. The overall federal, state, and local tax burden in Alabama ranks the state as the second least tax-burdened state in the country. Property taxes are the lowest in the United States. The current state constitution requires a voter referendum to raise property taxes.
Since Alabama's tax structure largely depends on consumer spending, it is subject to high variable budget structure. For example, in 2003 Alabama had an annual budget deficit as high as $670 million. It is one of only a few states to accomplish large surpluses, with a budget surplus of nearly $1.2 billion in 2007, and estimated at more than $2.1 billion for 2008. However, the declining national economy in 2008 has eliminated that surplus and the state is again facing shortfall, with the governor declaring "proration," which will result in an immediate education budget cut and school layoffs.
Transportation.
Alabama has five major interstate roads that cross it: I-65 runs north–south roughly through the middle of the state; I-59/I-20 travels from the central west border to Birmingham, where I-59 continues to the north-east corner of the state and I-20 continues east towards Atlanta; I-85 originates in Montgomery and runs east-northeast to the Georgia border, providing a main thoroughfare to Atlanta; and I-10 traverses the southernmost portion of the state, running from west to east through Mobile. Another interstate road, I-22, is currently under construction. When completed around 2012 it will connect Birmingham with Memphis, Tennessee. Several US Highways also pass through the state, such as US 11, US 29, US 31, US 43, US 72, US 78, US 80, US 82, US 84, US 98, US 231, and US 280.
Major airports in Alabama include Birmingham-Shuttlesworth International Airport (BHM), Huntsville International Airport (HSV), Dothan Regional Airport (DHN), Mobile Regional Airport (MOB), Montgomery Regional Airport (MGM), Muscle Shoals – Northwest Alabama Regional Airport (MSL), Tuscaloosa Regional Airport (TCL), and Pryor Field Regional Airport (DCU). For rail transport, Amtrak schedules the Crescent, a daily passenger train, running from New York to New Orleans with stops at Anniston, Birmingham, and Tuscaloosa.
State government.
The foundational document for Alabama's government is the Alabama Constitution, which was ratified in 1901. At almost 800 amendments and 310,000 words, it is the world's longest constitution and is roughly forty times the length of the U.S. Constitution. There is a significant movement to rewrite and modernize Alabama's constitution. This movement is based upon the fact that Alabama's constitution highly centralizes power in Montgomery and leaves practically no power in local hands. Any policy changes proposed around the state must be approved by the entire Alabama legislature and, frequently, by state referendum. One criticism of the current constitution claims that its complexity and length were intentional to codify segregation and racism.
The legislative branch is the Alabama Legislature, a bicameral assembly composed of the Alabama House of Representatives, with 105 members, and the Alabama Senate, with 35 members. The Legislature is responsible for writing, debating, passing, or defeating state legislation.
The executive branch is responsible for the execution and oversight of laws. It is headed by the Governor of Alabama. Other members of executive branch include the cabinet, the Attorney General of Alabama, the Alabama Secretary of State, the Alabama Commissioner of Agriculture and Industries, the Alabama State Treasurer, and the Alabama State Auditor.
The judicial branch is responsible for interpreting the Constitution and applying the law in state criminal and civil cases. The highest court is the Supreme Court of Alabama.
Local and county government.
Alabama has 67 counties. Each county has its own elected legislative branch, usually called the County Commission, which usually also has executive authority in the county. Because of the restraints placed in the Alabama Constitution, all but seven counties (Jefferson, Lee, Mobile, Madison, Montgomery, Shelby, and Tuscaloosa) in the state have little to no home rule. Instead, most counties in the state must lobby the Local Legislation Committee of the state legislature to get simple local policies such as waste disposal to land use zoning.
Alabama is an alcoholic beverage control state; the government holds a monopoly on the sale of alcohol. However, counties can declare themselves "dry"; the state does not sell alcohol in those areas.
State politics.
The current governor of the state is Republican Bob Riley. The lieutenant governor is Jim Folsom Jr. The Chief Justice of the Alabama Supreme Court is Democrat Sue Bell Cobb. The Democratic Party currently holds a large majority in both houses of the Legislature. Because of the Legislature's power to override a gubernatorial veto by a mere simple majority (most state Legislatures require a two-thirds majority to override a veto), the relationship between the executive and legislative branches can be easily strained when different parties control the branches.
During Reconstruction following the American Civil War, Alabama was occupied by federal troops of the Third Military District under General John Pope. In 1874, the political coalition known as the Redeemers took control of the state government from the Republicans, in part by suppressing the African American vote.
After 1890, a coalition of whites passed laws to segregate and disenfranchise black residents, a process completed in provisions of the 1901 constitution. Provisions which disfranchised African Americans also disfranchised poor whites, however. By 1941 more whites than blacks had been disfranchised: 600,000 to 520,000, although the impact was greater on the African-American community, as almost all of its citizens were disfranchised.
From 1901 to the 1960s, the state legislature failed to perform redistricting as population grew and shifted within the state. The result was a rural minority that dominated state politics until a series of court cases required redistricting in 1972.
With the disfranchisement of African Americans, the state became part of the "Solid South", a one-party system in which the Democratic Party became essentially the only political party in every Southern state. For nearly 100 years, local and state elections in Alabama were decided in the Democratic Party primary, with generally only token Republican challengers running in the General Election.
In the 1986 Democratic primary election, the then-incumbent Lieutenant Governor, Bill Baxley, lost the Democratic nomination for Governor in a scandal where Republicans were permitted to cast votes for his opponent, then Attorney General Charlie Graddick. The state Democratic party invalidated the election and placed the Baxley's name on the ballot as the Democratic candidate instead of the candidate chosen in the primary. The voters of the state revolted at what they perceived as disenfranchisement of their right to vote and elected the Republican challenger Guy Hunt as Governor. This was the first Republican Governor elected in Alabama since Reconstruction. Since then, Republicans have become increasingly competitive in Alabama politics. They currently control both seats in the U.S. Senate, four out of the state's seven congressional seats. Republicans hold an 8–1 majority on the Alabama Supreme Court and have a 5–2 majority among statewide elected executive branch offices.
However, Democrats currently hold all three seats on the Alabama Public Service Commission and they maintain control of both houses of the legislature, holding approximately 59.4% of seats in the Alabama Senate and 58.7% of seats in the Alabama House of Representatives. A majority of local offices in the state are still held by Democrats. Local elections in rural counties are generally decided in the Democratic primary and local elections in metropolitan counties are decided in the Republican Primary although there are exceptions to this rule. Only one Republican Lt. Governor has been elected since Reconstruction, Steve Windom. Windom served as Lt. Governor under Democratic Gov. Don Siegelman. The last time that Alabama had a governor and Lt. governor of the same party was the period between 1983 and 1987 when Wallace was serving his fourth term as governor and Bill Baxley was serving as Lt. Governor, both were Democrats.
An overwhelming majority of sheriff's offices in Alabama are in Democratic hands. However, most of the Democratic sheriffs preside over more rural and less populated counties and the majority of Republicans preside over more urban/suburban and more populated counties. Only three Alabama counties (Tuscaloosa, Montgomery and Calhoun) with a population of over 100,000 have Democratic sheriffs and only five Alabama counties with a population of under 75,000 have Republican sheriffs (Autauga, Coffee, Dale, Coosa, and Blount).
Alabama state politics gained nationwide and international attention in the 1950s and 1960s during the American Civil Rights Movement, when majority whites bureaucratically, and at times, violently resisted protests for electoral and social reform. George Wallace, the state's governor, remains a notorious and controversial figure. Only with the passage of the Civil Rights Act of 1964 and Voting Rights Act of 1965 did African Americans regain suffrage and other civil rights.
In 2007, the Alabama Legislature passed, and the Governor signed, a resolution expressing "profound regret" over slavery and its lingering impact. In a symbolic ceremony, the bill was signed in the Alabama State Capitol, which housed Congress of the Confederate States of America.
National politics.
From 1876 through 1956, Alabama supported only Democratic presidential candidates, by large margins. In 1960, the Democrats won with John F. Kennedy on the ballot, but the Democratic electors from Alabama gave 6 of their 11 electoral votes as a protest to Harry Byrd. In 1964, Republican Barry Goldwater carried the state, in part because of his opposition to the 1964 Civil Rights Act, which restored the franchise for African Americans.
In the 1968 presidential election, Alabama supported native son and American Independent Party candidate George Wallace over both Richard Nixon and Hubert Humphrey. Wallace was the official Democratic candidate in Alabama, while Humphrey was listed as the "National Democratic". In 1976, Democratic candidate Jimmy Carter from Georgia carried the state, the region, and the nation, but Democratic control of the region slipped after that.
Since 1980, conservative Alabama voters have increasingly voted for Republican candidates at the Federal level, especially in Presidential elections. By contrast, Democratic candidates have been elected to many state-level offices and comprise a longstanding majority in the Alabama Legislature; see Dixiecrat.
In 2004, George W. Bush won Alabama's nine electoral votes by a margin of 25 percentage points with 62.5% of the vote, mostly white voters. The eleven counties that voted Democratic were Black Belt counties, where African Americans are the majority racial group.
The state's two U.S. senators are Jefferson B. Sessions III and Richard C. Shelby, both Republicans.
In the U.S. House of Representatives, the state is represented by seven members, five of whom are Republicans: (Jo Bonner, Mike D. Rogers, Robert Aderholt, Parker Griffith, and Spencer Bachus) and two are Democrats: (Bobby Bright and Artur Davis).
Primary and secondary education.
Public primary and secondary education in Alabama is under the overview of the Alabama State Board of Education as well as local oversight by 67 county school boards and 60 city boards of education. Together, 1,541 individual schools provide education for 743,364 elementary and secondary students.
Public school funding is appropriated through the Alabama Legislature through the Education Trust Fund. In FY 2006–2007, Alabama appropriated $3,775,163,578 for primary and secondary education. That represented an increase of $444,736,387 over the previous fiscal year. In 2007, over 82 percent of schools made adequate yearly progress (AYP) toward student proficiency under the National No Child Left Behind law, using measures determined by the state of Alabama. In 2004, 23 percent of schools met AYP.
While Alabama's public education system has improved, it lags behind in achievement compared to other states. According to U.S. Census data, Alabama's high school graduation rate – 75% – is the second lowest in the United States (after Mississippi). The largest educational gains were among people with some college education but without degrees.
Colleges and universities.
Alabama's programs of higher education include 14 four-year public universities, two-year community colleges, and 17 private, undergraduate and graduate universities. In the state are two medical schools (University of Alabama at Birmingham and University of South Alabama), two veterinary colleges (Auburn University and Tuskegee University), a dental school (University of Alabama at Birmingham), an optometry college (University of Alabama at Birmingham), two pharmacy schools (Auburn University and Samford University), and five law schools (University of Alabama School of Law, Birmingham School of Law, Cumberland School of Law, Miles Law School, and the Thomas Goode Jones School of Law). Public, post-secondary education in Alabama is overseen by the Alabama Commission on Higher Education. Colleges and universities in Alabama offer degree programs from two-year associate degrees to 16 doctoral level programs.
Accreditation of academic programs is through the Southern Association of Schools and Colleges as well as a plethora of subject focused national and international accreditation agencies.
Professional sports teams.
Alabama has several minor league teams including four Southern League baseball teams as well as one Arena Football League team.
Notable Alabamians.
Famous people from Alabama include Hank Aaron, Tommie Agee, Tallulah Bankhead, William Brockman Bankhead, Jay Barker, Charles Barkley, Regina Benjamin, Hugo L. Black, Frank Bolling, Paul W. (Bear) Bryant, Jimmy Buffett, Bo Bice, George Washington Carver, William Christenberry, Nat King Cole, Jerricho Cotchery, Courteney Cox Arquette, Robert Gibbs, Mitch Holleman, Zelda Fitzgerald, Charles Ghigna, Winston Groom, William C. Handy, Emmylou Harris, Taylor Hicks, Joe Hilley, Bo Jackson, Kate Jackson, Jamey Johnson, Helen Keller, Coretta Scott King, William R. King, Harper Lee, Joe Louis, Heinie Manush, William March, Willie Mays, Willie McCovey, Roy Moore, John Hunt Morgan, Jim Nabors, Randy Owen, Jesse Owens, Terrell Owens, Satchel Paige, Jake Peavy, Claude Pepper, Rosa Parks, Wilson Pickett, Howell Raines, Condoleezza Rice, Lionel Richie, Rich Boy, Philip Rivers, JaMarcus Russell, Kenny Stabler, Ozzie Smith, John Sparkman, Bart Starr, Ruben Studdard, Channing Tatum, Oscar W. Underwood, Jimmy Wales, George Wallace, Booker T. Washington, Billy Williams, and Hank Williams.
---END.OF.DOCUMENT---

Achilles.
In Greek mythology, Achilles (Ancient Greek:) was a Greek hero of the Trojan War, the central character and the greatest warrior of Homer's "Iliad".
Achilles also has the attributes of being the most handsome of the heroes assembled against Troy.
Later legends (beginning with a poem by Statius in the first century AD) state that Achilles was invulnerable in all of his body except for his heel. Since he died due to an arrow shot into his heel, the "Achilles' heel" has come to mean a person's principal weakness.
Birth.
Achilles was the son of the nymph Thetis and Peleus, the king of the Myrmidons. Zeus and Poseidon had been rivals for the hand of Thetis until Prometheus, the fire-bringer, warned Zeus of a prophecy that Thetis would bear a son greater than his father. For this reason, the two gods withdrew their pursuit, and had her wed Peleus.
As with most mythology there is a tale which offers an alternative version of these events: in "Argonautica" (iv.760) Hera alludes to Thetis's chaste resistance to the advances of Zeus, that Thetis was so loyal to Hera's marriage bond that she coolly rejected him. Thetis, although a daughter of the sea-god Nereus, was also brought up by Hera, further explaining her resistance to the advances of Zeus.
According to the "Achilleid", written by Statius in the first century AD, and to no surviving previous sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx. However, he was left vulnerable at the part of the body she held him by, his heel. (See Achilles heel, Achilles' tendon.) It is not clear if this version of events was known earlier. In another version of this story, Thetis anointed the boy in ambrosia and put him on top of a fire to burn away the mortal parts of his body. She was interrupted by Peleus and abandoned both father and son in a rage.
However none of the sources before Statius makes any reference to this general invulnerability. To the contrary, in the "Iliad" Homer mentions Achilles being wounded: in Book 21 the Paeonian hero Asteropaeus, son of Pelagon, challenged Achilles by the river Scamander. He cast two spears at once, one grazed Achilles' elbow, "drawing a spurt of blood."
Also in the fragmentary poems of the Epic Cycle in which we can find description of the hero's death, Kúpria (unknown author), "Aithiopis" by Arctinus of Miletus, "Ilias Mikrá" by Lesche of Mytilene, Iliou pérsis by Arctinus of Miletus, there is no trace of any reference to his general invulnerability or his famous weakness (heel); in the later vase-paintings presenting Achilles' death, the arrow (or in many cases, arrows) hit his body.
Peleus entrusted Achilles to Chiron the Centaur, on Mt. Pelion, to be raised.
Achilles in the Trojan War.
Achilles' consuming rage is at some times wavering, but at other times he cannot be cooled. The humanization of Achilles by the events of the war is an important theme of the narrative.
Telephus.
When the Greeks left for the Trojan War, they accidentally stopped in Mysia, ruled by King Telephus. In the resulting battle, Achilles gave Telephus a wound that would not heal; Telephus consulted an oracle, who stated that "he that wounded shall heal". Guided by the oracle, he arrived at Argos, where Achilles heals him in order that he become their guide for the voyage to Troy.
According to other reports in Euripides' lost play about Telephus, he went to Aulis pretending to be a beggar and asked Achilles to heal his wound. Achilles refused, claiming to have no medical knowledge. Alternatively, Telephus held Orestes for ransom, the ransom being Achilles' aid in healing the wound. Odysseus reasoned that the spear had inflicted the wound; therefore, the spear must be able to heal it. Pieces of the spear were scraped off onto the wound and Telephus was healed.
Troilus.
According to the Cypria (the part of the Epic Cycle that tells the events of the Trojan War before Achilles' Wrath), when the Achaeans desired to return home, they were restrained by Achilles, who afterwards attacked the cattle of Aeneas, sacked neighboring cities and killed Troilus.
According to Dares Phrygius' "Account of the Destruction of Troy", the Latin summary through which the story of Achilles was transmitted to medieval Europe, Troilus was a young Trojan prince, the youngest of King Priam's (or sometimes Apollo) and Hecuba's five legitimate sons. Despite his youth, he was one of the main Trojan war leaders. Prophecies linked Troilus' fate to that of Troy and so he was ambushed in an attempt to capture him. Yet Achilles, struck by the beauty of both Troilus and his sister Polyxena, and overcome with lust directed his sexual attentions on the youth — who refusing to yield found instead himself decapitated upon an altar-omphalos of Apollo. Later versions of the story suggested Troilus was accidentally killed by Achilles in an over-ardent lovers' embrace. In this version of the myth, Achilles' death therefore came in retribution for this sacrilege. Ancient writers treated Troilus as the epitome of a dead child mourned by his parents. Had Troilus lived to adulthood, the First Vatican Mythographer claimed Troy would have been invincible.
In the "Iliad".
Homer's "Iliad" is the most famous narrative of Achilles' deeds in the Trojan War. The Homeric epic only covers a few weeks of the war, and does not narrate Achilles' death. It begins with Achilles' withdrawal from battle after he is dishonored by Agamemnon, the commander of the Achaean forces. Agamemnon had taken a woman named Chryseis as his slave. Her father Chryses, a priest of Apollo, begged Agamemnon to return her to him. Agamemnon refused and Apollo sent a plague amongst the Greeks. The prophet Calchas correctly determined the source of the troubles but would not speak unless Achilles vowed to protect him. Achilles did so and Calchas declared Chryseis must be returned to her father. Agamemnon consented, but then commanded that Achilles' battle prize Briseis be brought to replace Chryseis. Angry at the dishonor (and as he says later, because he loved Briseis) and at the urging of Thetis, Achilles refused to fight or lead his troops alongside the other Greek forces.
As the battle turned against the Greeks, Nestor declared that the Trojans were winning because Agamemnon had angered Achilles, and urged the king to appease the warrior. Agamemnon agreed and sent Odysseus and two other chieftains, Ajax and Phoenix, to Achilles with the offer of the return of Briseis and other gifts. Achilles rejected all Agamemnon offered him, and simply urged the Greeks to sail home as he was planning to do.
Eventually, however, hoping to retain glory despite his absence from the battle, Achilles prayed to his mother Thetis, asking her to plead with Zeus to allow the Trojans to push back the Greek forces.
The Trojans, led by Hector, subsequently pushed the Greek army back toward the beaches and assaulted the Greek ships. With the Greek forces on the verge of absolute destruction, Patroclus led the Myrmidons into battle, though Achilles remained at his camp. Patroclus succeeded in pushing the Trojans back from the beaches, but was killed by Hector before he could lead a proper assault on the city of Troy.
After receiving the news of the death of Patroclus from Antilochus, the son of Nestor, Achilles grieved over his close friend's death and held many funeral games in his honor. His mother Thetis came to comfort the distraught Achilles. She persuaded Hephaestus to make new armor for him, in place of the armor that Patroclus had been wearing which was taken by Hector. The new armor included the Shield of Achilles, described in great detail by the poet.
Enraged over the death of Patroclus, Achilles ended his refusal to fight and took the field killing many men in his rage but always seeking out Hector. Achilles even engaged in battle with the river god Scamander who became angry that Achilles was choking his waters with all the men he killed. The god tried to drown Achilles but was stopped by Hera and Hephaestus. Zeus himself took note of Achilles' rage and sent the gods to restrain him so that he would not go on to sack Troy itself, seeming to show that the unhindered rage of Achilles could defy fate itself as Troy was not meant to be destroyed yet. Finally Achilles found his prey. Achilles chased Hector around the wall of Troy three times before Athena, in the form of Hector's favorite and dearest brother, Deiphobus, persuaded Hector to stop running and fight Achilles face to face. After Hector realized the trick, he knew the battle was inevitable. Wanting to go down fighting, he charged at Achilles with his only weapon, his sword, but missed. Accepting his fate, Hector begged Achilles – not to spare his life, but to treat his body with respect after killing him. Achilles told Hector it was hopeless to expect that of him, declaring that "my rage, my fury would drive me now to hack your flesh away and eat you raw — such agonies you have caused me". Achilles then got his vengeance, killing Hector with a single blow to the neck and tying the Trojan's body to his chariot, dragging it around the battlefield for nine days.
With the assistance of the god Hermes, Hector's father, Priam, went to Achilles' tent to plead with Achilles to permit him to perform for Hector his funeral rites. The final passage in the "Iliad" is Hector's funeral, after which the doom of Troy was just a matter of time.
Penthesilea.
Achilles, after his temporary truce with Priam, fought and killed the Amazonian warrior queen Penthesilea, but later grieved over her death. At first, he was so distracted by her beauty, he did not fight as intensely as usual. Once he realized that his distraction was endangering his life, he refocused, and killed her. As he grieved over the death of such a rare beauty, a notorious Greek jeerer by the name of Thersites laughed and mocked the great Achilles. Annoyed by his insensitivity and disrespect, Achilles punched him in the face and killed him instantly.
Memnon, and the fall of Achilles.
Following the death of Patroclus, Achilles' closest companion was Nestor's son Antilochus. When Memnon, king of Ethiopia killed Antilochus, Achilles was once again drawn onto the battlefield to seek revenge. The fight between Achilles and Memnon over Antilochus echoes that of Achilles and Hector over Patroclus, except that Memnon (unlike Hector) was also the son of a goddess.
Many Homeric scholars argued that episode inspired many details in the "Iliads description of the death of Patroclus and Achilles' reaction to it. The episode then formed the basis of the cyclic epic "Aethiopis", which was composed after the "Iliad", possibly in the 7th century B.C. The "Aethiopis" is now lost, except for scattered fragments quoted by later authors.
As predicted by Hector with his dying breath, Achilles was thereafter killed by Paris with an arrow (to the heel according to Statius). In some versions, the god Apollo guided Paris' arrow. Some retellings also state that Achilles was scaling the gates of Troy and was hit with a poisoned arrow.
Both versions conspicuously deny the killer any sort of valor owing to the common conception that Paris was a coward and not the man his brother Hector was, and Achilles remained undefeated on the battlefield. His bones were mingled with those of Patroclus, and funeral games were held. He was represented in the lost Trojan War epic of Arctinus of Miletus as living after his death in the island of Leuke at the mouth of the river Danube (see below). Another version of Achilles' death is that he fell deeply in love with one of the Trojan princesses, Polyxena, Achilles asks Priam for Polyxena's hand in marriage. Priam is willing because it would mean the end of the war and an alliance with the world's greatest warrior. But while Priam is overseeing the private marriage of Polyxena and Achilles, Paris who would have to give up Helen if Achilles married his sister hides in the bushes and shoots Achilles with a divine arrow killing him.
Achilles was cremated and his ashes buried in the same urn as those of Patroclus.
Paris was later killed by Philoctetes using the enormous bow of Heracles.
Fate of Achilles' armor.
Achilles' armor was the object of a feud between Odysseus and Telamonian Ajax (Ajax the greater). They competed for it by giving speeches on why they were the bravest after Achilles to their Trojan prisoners, who after considering both men came to a consensus in favor of Odysseus. Furious, Ajax cursed Odysseus, which earned the ire of Athena. Athena temporarily made Ajax so mad with grief and anguish that he began killing sheep, thinking they were his comrades. After a while, when Athena lifted his madness and Ajax realized that he had actually been killing sheep, he was so embarrassed that he committed suicide. Odysseus eventually gave the armor to Neoptolemus, the son of Achilles.
A relic claimed to be Achilles' bronze-headed spear was for centuries preserved in the temple of Athena on the acropolis of Phaselis, Lycia, a port on the Pamphylian Gulf. The city was visited in 333 BC by Alexander the Great, who envisioned himself as the new Achilles and carried the "Iliad" with him, but his court biographers do not mention the spear, which he would indeed have touched with excitement. But it was being shown in the time of Pausanias in the second century AD.
Achilles and Patroclus.
Achilles' relationship with Patroclus is a key aspect of his myth. Its exact nature has been a subject of dispute in both the classical period and modern times. In the "Iliad", they appeared to be generally portrayed as a model of deep and loyal friendship. However, commentators from the classical period to today have tended to interpret the relationship through the lens of their own cultures. Thus, in 5th century BC Athens the relationship was commonly interpreted as pederastic. Contemporary readers may interpret the two heroes either as relatives or close friends, as "war buddies," as being in a teacher/student relationship, or in love with each other as an egalitarian homosexual couple. Whichever the case may be, Achilles nevertheless continued to have sexual relationships with women.
The cult of Achilles in antiquity.
There was an archaic heroic cult of Achilles on the White Island, "Leuce", in the Black Sea off the modern coasts of Romania and Ukraine, with a temple and an oracle which survived into the Roman period.
In the lost epic "Aithiopis", a continuation of the "Iliad" attributed to Arktinus of Miletos, Achilles’ mother Thetis returned to mourn him and removed his ashes from the pyre and took them to Leuce at the mouths of the Danube. There the Achaeans raised a tumulus for him and celebrated funeral games.
Pliny's Natural History (IV.27.1) mentions a tumulus that is no longer evident ("Insula Akchillis tumulo eius viri clara"), on the island consecrated to him, located at a distance of fifty Roman miles from Peuce by the Danube Delta, and the temple there. Pausanias has been told that the island is "covered with forests and full of animals, some wild, some tame. In this island there is also Achilles’ temple and his statue” (III.19.11). Ruins of a square temple 30 meters to a side, possibly that dedicated to Achilles, were discovered by Captain Kritzikly in 1823, but there has been no modern archeological work done on the island.
Pomponius Mela tells that Achilles is buried in the island named Achillea, between Boristhene and Ister ("De situ orbis", II, 7). And the Greek geographer Dionysius Periegetus of Bithynia, who lived at the time of Domitian, writes that the island was called "Leuce" "because the wild animals which live there are white. It is said that there, in Leuce island, reside the souls of Achilles and other heroes, and that they wander through the uninhabited valleys of this island; this is how Jove rewarded the men who had distinguished themselves through their virtues, because through virtue they had acquired everlasting honor” ("Orbis descriptio", v. 541, quoted in Densuşianu 1913).
The "Periplus of the Euxine Sea" gives the following details: "It is said that the goddess Thetis raised this island from the sea, for her son Achilles, who dwells there. Here is his temple and his statue, an archaic work. This island is not inhabited, and goats graze on it, not many, which the people who happen to arrive here with their ships, sacrifice to Achilles. In this temple are also deposited a great many holy gifts, craters, rings and precious stones, offered to Achilles in gratitude. One can still read inscriptions in Greek and Latin, in which Achilles is praised and celebrated. Some of these are worded in Patroclus’ honor, because those who wish to be favored by Achilles, honor Patroclus at the same time. There are also in this island countless numbers of sea birds, which look after Achilles’ temple. Every morning they fly out to sea, wet their wings with water, and return quickly to the temple and sprinkle it. And after they finish the sprinkling, they clean the hearth of the temple with their wings. Other people say still more, that some of the men who reach this island, come here intentionally. They bring animals in their ships, destined to be sacrificed. Some of these animals they slaughter, others they set free on the island, in Achilles’ honor. But there are others, who are forced to come to this island by sea storms. As they have no sacrificial animals, but wish to get them from the god of the island himself, they consult Achilles’ oracle. They ask permission to slaughter the victims chosen from among the animals that graze freely on the island, and to deposit in exchange the price which they consider fair. But in case the oracle denies them permission, because there is an oracle here, they add something to the price offered, and if the oracle refuses again, they add something more, until at last, the oracle agrees that the price is sufficient. And then the victim doesn’t run away any more, but waits willingly to be caught. So, there is a great quantity of silver there, consecrated to the hero, as price for the sacrificial victims. To some of the people who come to this island, Achilles appears in dreams, to others he would appear even during their navigation, if they were not too far away, and would instruct them as to which part of the island they would better anchor their ships”. (quoted in Densuşianu)
The heroic cult of Achilles on Leuce island was widespread in antiquity, not only along the sea lanes of the Pontic Sea but also in maritime cities whose economic interests were tightly connected to the riches of the Black Sea.
Achilles from Leuce island was venerated as "Pontarches" the lord and master of the Pontic (Black) Sea, the protector of sailors and navigation. Sailors went out of their way to offer sacrifice. To Achilles of Leuce were dedicated a number of important commercial port cities of the Greek waters: Achilleion in Messenia (Stephanus Byzantinus), Achilleios in Laconia (Pausanias, III.25,4) Nicolae Densuşianu (Densuşianu 1913) even thought he recognized Achilles in the name of Aquileia and in the north arm of the Danube delta, the arm of Chilia ("Achileii"), though his conclusion, that Leuce had sovereign rights over Pontos, evokes modern rather than archaic sea-law."
Leuce had also a reputation as a place of healing. Pausanias (III.19,13) reports that the Delphic Pythia sent a lord of Croton to be cured of a chest wound. Ammianus Marcellinus (XXII.8) attributes the healing to waters ("aquae") on the island.
The cult of Achilles in modern times: The Achilleion in Corfu.
In the region of Gastouri (Γαστούρι) to the south of the city of Corfu Greece, Empress of Austria Elisabeth of Bavaria also known as Sissi built in 1890 a summer palace with Achilles as its central theme and it is a monument to platonic romanticism. The palace, naturally, was named after Achilles: "Achilleion" (Αχίλλειον). This elegant structure abounds with paintings and statues of Achilles both in the main hall and in the lavish gardens depicting the heroic and tragic scenes of the Trojan war.
The name of Achilles.
Achilles' name can be analyzed as a combination of ("akhos") "grief" and ("Laos") "a people, tribe, nation, etc." In other words, Achilles is an embodiment of the grief of the people, grief being a theme raised numerous times in the "Iliad" (frequently by Achilles). Achilles' role as the hero of grief forms an ironic juxtaposition with the conventional view of Achilles as the hero of "kleos" (glory, usually glory in war).
"Laos" has been construed by Gregory Nagy, following Leonard Palmer, to mean "a corps of soldiers", a muster. With this derivation, the name would have a double meaning in the poem: When the hero is functioning rightly, his men bring grief to the enemy, but when wrongly, his men get the grief of war. The poem is in part about the misdirection of anger on the part of leadership.
The name Achilleus was a common and attested name among the Greeks early after 7th century BC. It was also turned into the female form of Ἀχιλλεία, "Achilleía", firstly attested in Attica,4th century BC, (IG II² 1617) and Achillia, as the name of a female gladiator fighting, 'Amazonia'. Roman gladiatorial games often referenced classical mythology and this seems to reference Achilles' fight with Penthesilea, but give it an extra twist of Achilles being 'played' by a woman.
Other stories about Achilles.
Some post-Homeric sources claim that in order to keep Achilles safe from the war, Thetis (or, in some versions, Peleus) hides the young man at the court of Lycomedes, king of Skyros. There, Achilles is disguised as a girl and lives among Lycomedes' daughters, perhaps under the name "Pyrrha" (the red-haired girl). With Lycomedes' daughter Deidamia, whom in the account of Statius he rapes, Achilles there fathers a son, Neoptolemus (also called Pyrrhus, after his father's possible alias). According to this story, Odysseus learns from the prophet Calchas that the Achaeans would be unable to capture Troy without Achilles' aid. Odysseus goes to Skyros in the guise of a peddler selling women's clothes and jewelry and places a shield and spear among his goods. When Achilles instantly takes up the spear, Odysseus sees through his disguise and convinces him to join the Greek campaign. In another version of the story, Odysseus arranges for a trumpet alarm to be sounded while he was with Lycomedes' women; while the women flee in panic, Achilles prepares to defend the court, thus giving his identity away.
In book 11 of Homer's "Odyssey," Odysseus sails to the underworld and converses with the shades. One of these is Achilles, who when greeted as "blessed in life, blessed in death", responds that he would rather be a slave to the worst of masters than be king of all the dead. But Achilles then asks Odysseus of his son's exploits in the Trojan war, and when Odysseus tells of Neoptolemus' heroic actions, Achilles is filled with satisfaction. This leaves the reader with an ambiguous understanding of how Achilles felt about the heroic life. Achilles was worshipped as a sea-god in many of the Greek colonies on the Black Sea, the location of the mythical "White Island" which he was said to inhabit after his death, together with many other heroes.
The kings of the Epirus claimed to be descended from Achilles through his son, Neoptolemus. Alexander the Great, son of the Epiran princess Olympias, could therefore also claim this descent, and in many ways strove to be like his great ancestor; he is said to have visited his tomb while passing Troy.
Achilles fought and killed the Amazon Helene. Some also said he married Medea, and that after both their deaths they were united in the Elysian Fields of Hades — as Hera promised Thetis in Apollonius' Argonautica. In some versions of the myth, Achilles has a relationship with his captive Briseis.
Achilles in Greek tragedy.
The Greek tragedian Aeschylus wrote a trilogy of plays about Achilles, given the title "Achilleis" by modern scholars. The tragedies relate the deeds of Achilles during the Trojan War, including his defeat of Hector and eventual death when an arrow shot by Paris and guided by Apollo punctures his heel. Extant fragments of the "Achilleis" and other Aeschylean fragments have been assembled to produce a workable modern play. The first part of the "Achilleis" trilogy, "The Myrmidons", focused on the relationship between Achilles and chorus, who represent the Achaean army and try to convince Achilles to give up his quarrel with Agamemnon; only a few lines survive today.
The tragedian Sophocles also wrote a play with Achilles as the main character, "The Lovers of Achilles". Only a few fragments survive.
Achilles in Greek philosophy.
The philosopher Zeno of Elea centered one of his paradoxes on an imaginary footrace between "swift-footed" Achilles and a tortoise, by which he attempted to show that Achilles could not catch up to a tortoise with a head start, and therefore that motion and change were impossible. As a student of the monist Parmenides and a member of the Eleatic school, Zeno believed time and motion to be illusions.
Music.
Achilles has frequently been mentioned in music.
Quotes.
"If Achilles was anything, he was a man who believed his own press releases."
—Roger Ebert, commenting on the classical depiction of Achilles' character and personality.
Bibliography.
Thomas Bullfinch, Myths of Greek and Rome
---END.OF.DOCUMENT---

Abraham Lincoln.
Abraham Lincoln (February 12, 1809 – April 15, 1865) served as the 16th President of the United States from March 1861 until his assassination in April 1865. He successfully led his country through its greatest internal crisis, the American Civil War, preserving the Union and ending slavery. Before his election in 1860 as the first Republican president, Lincoln had been a country lawyer, an Illinois state legislator, a member of the United States House of Representatives, and twice an unsuccessful candidate for election to the U.S. Senate. As an outspoken opponent of the expansion of slavery in the United States,
Lincoln won the Republican Party nomination in 1860 and was elected president later that year. His tenure in office was occupied primarily with the defeat of the secessionist Confederate States of America in the American Civil War. He introduced measures that resulted in the abolition of slavery, issuing his Emancipation Proclamation in 1863 and promoting the passage of the Thirteenth Amendment to the Constitution. Six days after the large-scale surrender of Confederate forces under General Robert E. Lee, Lincoln became the first American president to be assassinated.
Lincoln had closely supervised the victorious war effort, especially the selection of top generals, including Ulysses S. Grant. Historians have concluded that he handled the factions of the Republican Party well, bringing leaders of each faction into his cabinet and forcing them to cooperate. Lincoln successfully defused the "Trent" affair, a war scare with Britain late in 1861. Under his leadership, the Union took control of the border slave states at the start of the war. Additionally, he managed his own reelection in the 1864 presidential election.
Copperheads and other opponents of the war criticized Lincoln for refusing to compromise on the slavery issue. Conversely, the Radical Republicans, an abolitionist faction of the Republican Party, criticized him for moving too slowly in abolishing slavery. Even with these opponents, Lincoln successfully rallied public opinion through his rhetoric and speeches; his Gettysburg Address (1863) became an iconic symbol of the nation's duty. At the close of the war, Lincoln held a moderate view of Reconstruction, seeking to speedily reunite the nation through a policy of generous reconciliation. Lincoln has consistently been ranked by scholars as one of the greatest of all U.S. Presidents.
Childhood and education.
Abraham Lincoln was born on February 12, 1809, to Thomas Lincoln and Nancy Hanks, two farmers, in a one-room log cabin on the Sinking Spring Farm, in southeast Hardin County, Kentucky
(now part of LaRue County), making him the first president born in the west. Lincoln was not given a middle name.
His ancestor Samuel Lincoln had arrived in Hingham, Massachusetts from England in the 17th century.
His grandfather, also named Abraham Lincoln, had moved to Kentucky, where he owned over, and was ambushed and killed by an Indian raid in 1786.
Thomas Lincoln was a respected citizen of rural Kentucky. He owned several farms, including the Sinking Spring Farm, although he was not wealthy. The family belonged to a Separate Baptists church, which had high moral standards frowning on alcohol consumption and dancing, and many church members were opposed to slavery.
Abraham himself never joined their church, or any other church.
In 1816, the Lincoln family left Kentucky to avoid the expense of fighting for one of their properties in court, and made a new start in Perry County, Indiana (now in Spencer County). Lincoln later noted that this move was "partly on account of slavery", and partly because of difficulties with land deeds in Kentucky. Abraham's father disapproved of slavery on religious grounds and it was hard to compete economically with farms operated by slaves. Unlike land in the Northwest Territory, Kentucky never had a proper U.S. survey, and farmers often had difficulties proving title to their property.
When Lincoln was nine, his mother, then 34 years old, died of milk sickness. Soon afterwards, his father remarried, to Sarah Bush Johnston. Lincoln and his stepmother were close; he called her "Mother" for the rest of his life, but he became increasingly distant from his father. Abraham felt his father was not a success, and did not want to be like him. In later years, he would occasionally lend his father money.
In 1830, fearing a milk sickness outbreak, the family settled on public land in Macon County, Illinois.
The next year, when his father relocated the family to a new homestead in Coles County, Illinois, 22-year-old Lincoln struck out on his own, canoeing down the Sangamon River to the village of New Salem in Sangamon County.
Later that year, hired by New Salem businessman Denton Offutt and accompanied by friends, he took goods from New Salem to New Orleans via flatboat on the Sangamon, Illinois and Mississippi rivers.
Lincoln's formal education consisted of about 18 months of schooling; but he was an avid reader and largely self-educated. He was also skilled with an axe and a talented local wrestler, the latter of which helped give him self-confidence.
Lincoln avoided hunting and fishing because he did not like killing animals, even for food.
Marriage and family.
Lincoln's first love was Ann Rutledge. He met her when he first moved to New Salem, and by 1835 they had reached a romantic understanding. Rutledge, however, died on August 25, probably of typhoid fever.
Earlier, in either 1833 or 1834, he had met Mary Owens, the sister of his friend Elizabeth Abell, when she was visiting from her home in Kentucky. Late in 1836, Lincoln agreed to a match proposed by Elizabeth between him and her sister, if Mary ever returned to New Salem. Mary did return in November 1836 and Lincoln courted her for a time; however they both had second thoughts about their relationship. On August 16, 1837, Lincoln wrote Mary a letter from Springfield, to which he had moved that April to begin his law practice, suggesting he would not blame her if she ended the relationship. She never replied, and the courtship was over.
In 1840, Lincoln became engaged to Mary Todd, from a wealthy slaveholding family based in Lexington, Kentucky.
They met in Springfield in December 1839,
and were engaged sometime around that Christmas.
A wedding was set for January 1, 1841, but the couple split as the wedding approached. They later met at a party, and then married on November 4, 1842, in the Springfield mansion of Mary's married sister.
In 1844, the couple bought a house on Eighth and Jackson in Springfield, near Lincoln's law office.
The Lincolns soon had a budding family, with the birth of son Robert Todd Lincoln in Springfield, Illinois on August 1, 1843, and second son Edward Baker Lincoln on March 10, 1846, also in Springfield. According to a house girl, Abraham "was remarkably fond of children".
The Lincolns did not believe in strict rules and tight boundaries when it came to their children.
Robert, however, would be the only one of the Lincolns' children to survive into adulthood. Edward Lincoln died on February 1, 1850 in Springfield, likely of tuberculosis.
The Lincolns' grief over this loss was somewhat assuaged by the birth of William "Willie" Wallace Lincoln nearly eleven months later, on December 21. But Willie himself died of a fever at the age of eleven on February 20, 1862, in Washington, D.C., during President Lincoln's first term.
The Lincolns' fourth son Thomas "Tad" Lincoln was born on April 4, 1853, and, although he outlived his father, died at the age of eighteen on July 16, 1871 in Chicago.
Robert Lincoln eventually went on to attend Phillips Exeter Academy and Harvard College. His (and by extension, his father's) last known lineal descendant, Robert Todd Lincoln Beckwith, died December 24, 1985.
The death of the Lincolns' sons had profound effects on both Abraham and Mary. Later in life, Mary Todd Lincoln found herself unable to cope with the stresses of losing her husband and sons, and this (in conjunction with what some historians consider to have been pre-existing bipolar disorder
) eventually led Robert Lincoln to involuntarily commit her to a mental health asylum in 1875.
Abraham Lincoln himself was contemporaneously described as suffering from "melancholy" throughout his legal and political life, a condition which modern mental health professionals would now typically characterize as clinical depression.
Early political career and military service.
Lincoln began his political career in March 1832 at age 23 when he announced his candidacy for the Illinois General Assembly. He was esteemed by the residents of New Salem, but he didn't have an education, powerful friends, or money. The centerpiece of his platform was the undertaking of navigational improvements on the Sangamon River. Before the election he served as a captain in a company of the Illinois militia during the Black Hawk War, although he never saw combat. Lincoln returned from the militia after a few months and was able to campaign throughout the county before the August 6 election. At, he was tall and "strong enough to intimidate any rival." At his first political speech, he grabbed a man accosting a supporter by his "neck and the seat of his trousers", and threw him. When the votes were counted, Lincoln finished eighth out of thirteen candidates (only the top four were elected), but he did manage to secure 277 out of the 300 votes cast in the New Salem precinct.
In 1834, he won an election to the state legislature. He was labeled a Whig, but ran a bipartisan campaign.
He then decided to become a lawyer, and began teaching himself law by reading "Commentaries on the Laws of England".
Admitted to the bar in 1837, he moved to Springfield, Illinois, that April,
and began to practice law with John T. Stuart, Mary Todd's cousin, who let Lincoln have the run of his law library while studying to be a lawyer.
With a reputation as a formidable adversary during cross-examinations and closing arguments, Lincoln became an able and successful lawyer.
In 1841, Lincoln entered law practice with William Herndon, whom Lincoln thought "a studious young man".
He served four successive terms in the Illinois House of Representatives as a representative from Sangamon County, affiliated with the Whig party.
In 1837, he and another legislator declared that slavery was "founded on both injustice and bad policy"
the first time he had publicly opposed slavery. In the 1835–1836 legislative session he'd voted to restrict suffrage to whites only. He would later say that he had been against slavery since he was a boy, but being labelled an abolitionist was "political suicide" in Sangamon County in those years, and so he chose his words carefully when discussing the issue publicly.
National politics.
Lincoln was a Whig, and since the early 1830s had strongly admired the policies and leadership of Henry Clay.
"I have always been an old-line Henry Clay Whig" he professed to friends in 1861.
The party favored economic expansion such as improving roads and increasing trade.
In 1846, Lincoln was elected to the U.S. House of Representatives, where he served one two-year term.
As a House member, Lincoln was a dedicated Whig, showing up for most votes and giving speeches that echoed the party line.
He used his office as an opportunity to speak out against the Mexican–American War, which he attributed to President Polk's desire for "military glory — that attractive rainbow, that rises in showers of blood".
Lincoln's main stand against Polk occurred in his Spot Resolutions: The war had begun with a violent confrontation on territory disputed by Mexico and Texas,
but as Lincoln pointed out, Polk had insisted that Mexican soldiers had "invaded "our territory" and shed the blood of our fellow-citizens on our "own soil".
Lincoln demanded that Polk show Congress the exact spot on which blood had been shed, and proof that that spot was on American soil. Congress never enacted the resolution or even debated it,
and its introduction resulted in a loss of political support for Lincoln in his district;
one Illinois newspaper derisively nicknamed him "spotty Lincoln."
Despite his admiration for Henry Clay, Lincoln was a key early supporter of Zachary Taylor's candidacy for the 1848 presidential election. When Lincoln's term ended, the incoming Taylor administration offered him the governorship of the Oregon Territory. The territory leaned heavily Democratic, and Lincoln doubted they would elect him as governor or as a senator after they were admitted to the union, so he returned to Springfield.
Prairie lawyer.
Back in Springfield, Lincoln turned most of his energies to making a living practicing law, handling "every kind of business that could come before a prairie lawyer." He "rode the circuit"--that is, appeared in county seats in the mid-state region when the county courts were in session.
His reputation grew and he appeared before the Supreme Court of the United States, arguing a case involving a canal boat that sank after hitting a bridge.
Lincoln represented numerous transportation interests, such as the river barges and the railroads. As a riverboat man, Lincoln had initially favored riverboat interests, but ultimately he represented whoever hired him.
In 1849, he had received a patent for a "device to buoy vessels over shoals". Lincoln's goal had been to lessen the draft of a river craft by pushing horizontal floats into the water alongside the hull. The floats would have served as temporary ballast tanks.
The idea was never commercialized, but Lincoln is still the only person to hold a patent and serve as President of the United States.
In 1851, he represented the Alton & Sangamon Railroad in a dispute with one of its shareholders, James A. Barret, who had refused to pay the balance on his pledge to the railroad on the grounds that it had changed its originally planned route.
Lincoln argued that as a matter of law a corporation is not bound by its original charter when that charter can be amended in the public interest, that the newer proposed Alton & Sangamon route was superior and less expensive, and that accordingly the corporation had a right to sue Mr. Barret for his delinquent payment. He won this case, and the decision by the Illinois Supreme Court was eventually cited by 25 other courts throughout the United States. Lincoln appeared in front of the Illinois Supreme Court 175 times, 51 times as sole counsel, of which, 31 were decided in his favor.
Lincoln's most notable criminal trial came in 1858 when he defended William "Duff" Armstrong, who was on trial for the murder of James Preston Metzker.
The case is famous for Lincoln's use of judicial notice to show an eyewitness had lied on the stand. After the witness testified to having seen the crime in the moonlight, Lincoln produced a Farmers' Almanac to show that the moon on that date was at such a low angle it could not have produced enough illumination to see anything clearly. Based on this evidence, Armstrong was acquitted.
Republican politics 1854–1860.
Lincoln returned to politics in response to the Kansas-Nebraska Act (1854), which expressly repealed the limits on slavery's extent as established by the Missouri Compromise (1820). Illinois Democrat Stephen A. Douglas, the most powerful man in the Senate, proposed popular sovereignty as the solution to the slavery impasse, and incorporated it into the Kansas–Nebraska Act. Douglas argued that in a democracy the people should have the right to decide whether to allow slavery in their territory, rather than have such a decision imposed on them by the national Congress.
In the October 16, 1854, "Peoria Speech",
Lincoln outlined his position on slavery that he would repeat over the next six years on the route to the presidency.
According to a newspaper account of the speech, Lincoln spoke with "a thin high-pitched falsetto voice of much carrying power, that could be heard a long distance in spite of the hustle and bustle of the crowd... [with] the accent and pronunciation peculiar to his native state, Kentucky."
In late 1854, Lincoln decided to run for the United States Senate as a Whig.
Despite leading in the first six rounds of voting in the state legislature, Lincoln instructed his backers to vote for Lyman Trumbull to prevent pro-Nebraska candidate Joel Aldrich Matteson from winning. Trumbull beat Matteson in the tenth round of voting.
The Whigs had been irreparably split by the Kansas-Nebraska Act. "I think I am a Whig, but others say there are not Whigs, and I am an abolitionist, even though I do no more than oppose the expansion of slavery" he said. Drawing on remnants of the old Whig party, and on disenchanted Free Soil, Liberty, and Democratic party members, he was instrumental in forging the shape of the new Republican Party.
At the Republican convention in 1856, Lincoln placed second in the contest to become the party's candidate for Vice-President.
In 1857–58, Douglas broke with President Buchanan, leading to a fight for control of the Democratic Party. Some eastern Republicans even favored the reelection of Douglas in 1858, since he had led the opposition to the Lecompton Constitution, which would have admitted Kansas as a slave state.
Accepting the Republican nomination for Senate in 1858, Lincoln delivered his famous speech: "'A house divided against itself cannot stand.'(Mark 3:25) I believe this government cannot endure permanently half slave and half free. I do not expect the Union to be dissolved — I do not expect the house to fall — but I do expect it will cease to be divided. It will become all one thing, or all the other."
The speech created an evocative image of the danger of disunion caused by the slavery debate, and rallied Republicans across the north.
As a part of his 1860 presidential campaign strategy Lincoln acquired through banker Jacob Bunn, in May, 1859, the Illinois Staats-Anzeiger, a German-language newspaper of Springfield, Illinois, to further the cause of Republican Party politics among the German-speaking community of the region..
Lincoln–Douglas debates of 1858.
The 1858 campaign featured the Lincoln–Douglas debates, generally considered the most famous political debate in American history.
Lincoln warned that "The Slave Power" was threatening the values of republicanism, while Stephen A. Douglas emphasized the supremacy of democracy, as set forth in his Freeport Doctrine, which said that local settlers should be free to choose whether to allow slavery or not and could overrule the Supreme Courts Dred Scott v. Sandford decision.
Though the Republican legislative candidates won more popular votes, the Democrats won more seats, and the legislature reelected Douglas to the Senate. Nevertheless, Lincoln's definition of the issues gave him a national political reputation.<ref»Carwardine, p. 89-90
On February 27, 1860, New York party leaders invited Lincoln to give a speech at Cooper Union to group of powerful Republicans. In one of the most important speeches of his career, Lincoln showed that he was a contender for the Republican's presidential nomination. Journalist Noah Brooks reported, "No man ever before made such an impression on his first appeal to a New York audience."
1860 Presidential election.
On May 9–10, 1860, the Illinois Republican State Convention was held in Decatur.
At this convention, Lincoln received his first endorsement to run for the presidency.
On May 18, at the 1860 Republican National Convention in Chicago, Lincoln emerged as the Republican candidate on the third ballot, beating candidates such as William H. Seward and Salmon P. Chase.
Why Lincoln won the nomination has been subject of much debate. His expressed views on slavery were seen as more moderate than those of rivals Seward and Chase.
Some feel that Seward lost more than Lincoln won, including Seward himself. Others attribute it to luck, and the fact that the convention was held in Lincoln's home state. Historian Doris Kearns Goodwin believes the real reason was Lincoln's skill as a politician.
Most Republicans agreed with Lincoln that the North was the aggrieved party
as the Slave Power tightened its grasp on the national government with the Dred Scott decision and the presidency of James Buchanan. Throughout the 1850s Lincoln denied that there would ever be a civil war, and his supporters repeatedly rejected claims that his election would incite secession.
Meanwhile, Douglas was selected as the candidate of the northern Democrats, with Herschel Vespasian Johnson as the vice-presidential candidate. Delegates from eleven slave states walked out of the Democrat's convention, disagreeing with Douglas's position on Popular sovereignty, and ultimately selected John C. Breckinridge as their candidate.
As Douglas stumped the country, Lincoln was the only one of the four major candidates to give no speeches whatever. Instead he monitored the campaign closely but relied on the enthusiasm of the Republican Party. It did the leg work that produced majorities across the North. It produced tons of campaign posters and leaflets, and thousands of newspaper editorials. There were thousands of Republican speakers who focused first on the party platform, and second on Lincoln's life story, emphasizing his childhood poverty. The goal was to demonstrate the superior power of "free labor", whereby a common farm boy could work his way to the top by his own efforts. The Republican Party's production of campaign literature dwarfed the combined opposition. A "Chicago Tribune" writer produced a pamphlet that detailed Lincoln's life, and sold one million copies.
On November 6, 1860, Lincoln was elected as the 16th President of the United States, beating Democrat Stephen A. Douglas, John C. Breckinridge of the Southern Democrats, and John Bell of the new Constitutional Union Party. He was the first Republican president, winning entirely on the strength of his support in the North: he was not even on the ballot in ten states in the South, and won only two of 996 counties in all the Southern states. Lincoln received 1,866,452 votes, Douglas 1,376,957 votes, Breckinridge 849,781 votes, and Bell 588,789 votes. The electoral vote was decisive: Lincoln had 180 and his opponents added together had only 123. Turnout was 82.2%, with Lincoln winning the free northern states. Douglas won Missouri, and split New Jersey with Lincoln.
Bell won Virginia, Tennessee, and Kentucky, and Breckinridge won the rest of the South.
There were fusion tickets in which all of Lincoln's opponents combined to form one ticket in New York, New Jersey and Rhode Island, but even if the anti-Lincoln vote had been combined in every state, Lincoln still would have won because he would still have had a majority in the electoral college.
Presidency and the Civil War.
With the emergence of the Republicans as the nation's first major sectional party by the mid-1850s, the old Second Party System collapsed and a realignment created the Third Party System. It became the stage on which sectional tensions were played out. Although little of the West–the focal point of sectional tensions– was fit for cotton cultivation, Southern secessionists read the political fallout as a sign that their power in national politics was rapidly weakening. The slave system had been buttressed by the Democratic Party, which was increasingly seen by anti-slavery elements as representing a more pro-Southern position that unfairly permitted the Slave Power to prevail in the nation's territories and to dominate national policy before the Civil War. Yet the Democrats suffered a significant reverse in the electoral realignment of the mid-1850s; they lost the dominance they had achieved over the Whig Party and, indeed, were the minority party in most of the northern states. The 1854 election was a Realigning election or "critical election" that saw a realignment of voting patterns.
Abraham Lincoln's election was a watershed in the balance of power of competing national and parochial interests and affiliations.
Secession winter 1860–1861.
As Lincoln's election became more likely, secessionists made clear their intent to leave the Union.
On December 20, 1860, South Carolina took the lead; by February 1, 1861, Florida, Mississippi, Alabama, Georgia, Louisiana,
The seven states soon declared themselves to be a new nation, the Confederate States of America. The upper South (Delaware, Maryland, Virginia, North Carolina, Tennessee, Kentucky, Missouri, and Arkansas) listened to, but initially rejected, the secessionist appeal.
President Buchanan and President-elect Lincoln refused to recognize the Confederacy.
Attempts at compromise, such as the Crittenden Compromise which would have extended the Missouri line of 1820, were discussed.
Despite support for the Crittenden Compromise among some Republicans, Lincoln denounced it in private letters, saying "either the Missouri line extended, or... Pop. Sov. would lose us everything we gained in the election; that filibustering for all South of us, and making slave states of it, would follow in spite of us, under either plan",
while other Republicans publicly stated it "would amount to a perpetual covenant of war against every people, tribe, and state owning a foot of land between here and Tierra del Fuego."
The Confederate States of America selected Jefferson Davis on February 9, 1861, as their provisional President.
President-elect Lincoln evaded possible assassins in Baltimore, and on February 23, 1861, arrived in disguise in Washington, D.C.
At his inauguration on March 4, 1861, sharpshooters watched the inaugural platform, while soldiers on horseback patrolled the surrounding area.
In his first inaugural address, Lincoln declared, "I hold that in contemplation of universal law and of the Constitution the Union of these States is perpetual. Perpetuity is implied, if not expressed, in the fundamental law of all national governments," arguing further that the purpose of the United States Constitution was "to form a more perfect union" than the Articles of Confederation which were "explicitly" perpetual, thus the Constitution too was perpetual. He asked rhetorically that even were the Constitution a simple contract, would it not require the agreement of all parties to rescind it?
Also in his inaugural address, in a final attempt to reunite the states and prevent certain war, Lincoln supported the pending Corwin Amendment to the Constitution, which had passed Congress the previous day. This amendment, which explicitly protected slavery in those states in which it already existed, was considered by Lincoln to be a possible way to stave off secession.
A few short weeks before the war he went so far as to pen a letter to every governor asking for their support in ratifying the Corwin Amendment.
By the time Lincoln took office, the Confederacy was an established fact, and no leaders of the insurrection proposed rejoining the Union on any terms. The failure of the Peace Conference of 1861 rendered legislative compromise virtually impossible. Buchanan might have allowed the southern states to secede, and some members of his cabinet recommended that. However, conservative Democratic nationalists, such as Jeremiah S. Black, Joseph Holt, and Edwin M. Stanton had taken control of Buchanan's cabinet in early January, and refused to accept secession.
Lincoln and nearly every Republican leader adopted this position by March 1861: the Union could not be dismantled. Believing that a peaceful solution was still possible, Lincoln decided to not take any action against the South unless the Unionists themselves were attacked first. This finally happened in April 1861.
Historian Allan Nevins argues that Lincoln made three miscalculations in believing that he could preserve the Union, hold government property, and still avoid war. He "temporarily underrated the gravity of the crisis", overestimated the strength of Unionist sentiment in the South and border states, and misunderstood the conditional support of Unionists in the border states.
Fighting begins.
On April 12, 1861, Union troops at Fort Sumter were fired upon and forced to surrender. On April 15, Lincoln called on the states to send detachments totaling 75,000 troops,
to recapture forts, protect the capital, and "preserve the Union", which in his view still existed intact despite the actions of the seceding states. These events forced the states to choose sides. Virginia declared its secession, after which the Confederate capital was moved from Montgomery to Richmond. North Carolina, Tennessee, and Arkansas also voted for secession over the next two months. Missouri, Kentucky and Maryland threatened secession, but neither they nor the slave state of Delaware seceded. Lincoln urgently negotiated with state leaders there, promising not to interfere with slavery.
Troops headed south towards Washington, D.C. to protect the capital in response to Lincoln's call. On April 19, angry secessionist mobs in Baltimore, a Maryland city to the north of Washington that controlled the rail links, attacked Union troops traveling to the capital. George William Brown, the Mayor of Baltimore, and other suspect Maryland politicians were arrested and imprisoned at Fort McHenry.
Rebel leaders were also arrested in other border areas and held in military prisons without trial. Over 18,000 were arrested. One, Clement Vallandigham, was exiled, but the remainder were released, usually after two or three months ("see": Ex parte Merryman).
Conducting the war effort.
The war was a source of constant frustration for the president and occupied nearly all of his time. He had a contentious relationship with General McClellan,
who became general-in-chief of all the Union armies in the wake of the embarrassing Union defeat at the First Battle of Bull Run and after the retirement of Winfield Scott in late 1861.
Despite his inexperience in military affairs, Lincoln immediately took an active part in determining war strategy. His priorities were twofold: to ensure that Washington was well defended; and to conduct an aggressive war effort that would satisfy the demand in the North for prompt, decisive victory.
McClellan, a youthful West Point graduate and railroad executive called back to active military service,
He took several months to plan and execute his Peninsula Campaign, with the objective of capturing Richmond by moving the Army of the Potomac by boat to the peninsula and then traveling by land to Richmond. McClellan's delay concerned Lincoln, as did his insistence that no troops were needed to defend Washington, Lincoln insisted on holding some of McClellan's troops to defend the capital, a decision McClellan blamed for the ultimate failure of the Peninsula Campaign. McClellan, a conservative Democrat,
was passed over for general-in-chief (that is, chief strategist) in favor of Henry Wager Halleck, after giving Lincoln his "Harrison's Landing Letter", where he offered unsolicited political advice to Lincoln urging caution in the war effort.
McClellan's letter incensed Radical Republicans, who successfully pressured Lincoln to appoint John Pope, a Republican, as head of the new Army of Virginia. Pope complied with Lincoln's strategic desire to move toward Richmond from the north, thus protecting the capital from attack. However, Pope was soundly defeated at the Second Battle of Bull Run in the summer of 1862, forcing the Army of the Potomac to defend Washington for a second time.
In response to his failure, Pope was sent to Minnesota to fight the Sioux.
Despite his dissatisfaction with McClellan's failure to reinforce Pope, Lincoln restored him to command of all forces around Washington, to the dismay of his cabinet (all save Seward), who wished McClellan gone.
Two days after McClellan's return to command, General Lee's forces crossed the Potomac River into Maryland, leading to the Battle of Antietam (September 1862).
The ensuing Union victory, one of the bloodiest in American history, enabled Lincoln to give notice that he would issue an Emancipation Proclamation in January,
but he relieved McClellan of his command after waiting for the conclusion of the 1862 midterm elections and appointed Republican Ambrose Burnside to head the Army of the Potomac.
Burnside was politically neutral, which Lincoln desired, and for the most part supported the President's aims.
Burnside had promised to follow through on Lincoln's strategic vision for a strong offensive against Lee and Richmond. After Burnside was stunningly defeated at Fredericksburg in December,
Joseph Hooker took command, despite his history of "loose talk" and criticizing former commanders.
Hooker was routed by Lee at the Battle of Chancellorsville in May, 1863,
but continued to command his troops for roughly two months. Hooker did not agree with Lincoln's desire to divide his troops, and possibly force Lee to do the same, and tendered his resignation, which was accepted. During the Gettysburg Campaign he was replaced by George Meade.
Using black troops and former slaves was official government policy after the issuance of the Emancipation Proclamation. At first Lincoln was reluctant to fully implement this program, but by the spring of 1863 he was ready to initiate "a massive recruitment of Negro troops." In a letter to Andrew Johnson, the military governor of Tennessee, encouraging him to lead the way in raising black troops, Lincoln wrote, "The bare sight of fifty thousand armed, and drilled black soldiers on the banks of the Mississippi would end the rebellion at once."
By the end of 1863, at Lincoln's direction, General Lorenzo Thomas had recruited twenty regiments of African Americans from the Mississippi Valley.
Grant.
After the Union victory at Gettysburg, Meade's failure to pursue Lee and months of inactivity for the Army of the Potomac persuaded Lincoln that a change was needed. McClellan was seeking the Democratic nomination for President, and Lincoln worried that Grant might also have political aspirations. Lincoln convinced himself that Grant didn't have political aspirations, in the immediate at least, and made Ulysses S. Grant commander of the Union Army.
Grant already had a solid string of victories in the Western Theater, including the battles of Vicksburg and Chattanooga.
Responding to criticism of Grant, Lincoln replied, "I can't spare this man. He fights."
Grant waged his bloody Overland Campaign in 1864 with a strategy of a war of attrition, characterized by high Union losses at battles such as the Wilderness and Cold Harbor, but by proportionately higher Confederate losses. The high casualty figures alarmed the nation, and, after Grant lost a third of his army, Lincoln asked what Grant's plans were. "I propose to fight it out on this line if it takes all summer," replied Grant. Lincoln and the Republican party mobilized support throughout the North, backed Grant to the hilt, and replaced his losses.
The Confederacy was out of replacements, so Lee's army shrank with every battle, forcing it back to trenches outside Petersburg. In April 1865, Lee's army finally crumbled under Grant's pounding, and Richmond fell.
Lincoln authorized Grant to target the Confederate infrastructure – such as plantations, railroads, and bridges – hoping to destroy the South's morale and weaken its economic ability to continue fighting. This strategy allowed Generals Sherman and Sheridan to destroy plantations and towns in the Shenandoah Valley, Georgia, and South Carolina. The damage caused by Sherman's March to the Sea through Georgia totaled more than $100 million by Sherman's own estimate.
Lincoln grasped the need to control strategic points (such as the Mississippi River and the fortress city of Vicksburg) and understood the importance of defeating the enemy's army, rather than simply capturing territory. He had, however, limited success in motivating his commanders to adopt his strategies until late 1863, when he found a man who shared his vision of the war in Ulysses S. Grant. Only then could he relentlessly pursue a series of coordinated offensives in multiple theaters, and have a top commander who agreed on the use of black troops.
Two days a week, Lincoln would meet with his cabinet in the afternoon, and occasionally his wife would force him to take a carriage ride because she was concerned he was working too hard. Throughout the war, Lincoln showed an intense interest with the military campaigns. He spent hours at the War Department telegraph office, reading dispatches from the field.
He visited battle sites frequently, and seemed fascinated by scenes of war. During Jubal Anderson Early's raid on Washington, D.C. in 1864, Lincoln was watching the combat from an exposed position; captain Oliver Wendell Holmes, Jr. shouted at him, "Get down, you damn fool, before you get shot!"
Emancipation Proclamation.
Lincoln maintained that the powers of his administration to end slavery were limited by the Constitution. He expected to cause the eventual extinction of slavery by stopping its further expansion into any U.S. territory, and by persuading states to accept compensated emancipation if the state would outlaw slavery (an offer that took effect only in Washington, D.C.). Guelzo says Lincoln believed that shrinking slavery in this way would make it uneconomical, and place it back on the road to eventual extinction that the Founders had envisioned.
In July 1862, Congress passed the Second Confiscation Act, which freed the slaves of anyone convicted of aiding the rebellion. Although Lincoln believed it wasn't in Congress's remit to free any slaves, he approved the bill. He felt freeing the slaves could only be done by the Commander in Chief during wartime, and that signing the bill would help placate those in Congress who wanted to do it through legislation. In that month, Lincoln discussed a draft of the Emancipation Proclamation with his cabinet. In it, he stated that "as a fit and necessary military measure" (and according to Donald not for moral reasons) on January 1, 1863, "all persons held as a slaves" in the Confederate states will " thenceforward, and forever, be free."
The Emancipation Proclamation, announced on September 22, 1862 and put into effect on January 1, 1863, freed slaves in territories not already under Union control. As Union armies advanced south, more slaves were liberated until all of them in Confederate territory (over three million) were freed. Lincoln later said: "I never, in my life, felt more certain that I was doing right, than I do in signing this paper." The proclamation made the abolition of slavery in the rebel states an official war goal. Lincoln then threw his energies into passage of the Thirteenth Amendment to permanently abolish slavery throughout the nation.
He personally lobbied individual Congressmen for the Amendment, which was passed by the Congress in early 1865, shortly before his death.
A few days after the Emancipation was announced, thirteen Republican governors met at the War Governors' Conference; they supported the president's Proclamation, but suggested the removal of General George B. McClellan as commander of the Union's Army of the Potomac.
For some time, Lincoln continued earlier plans to set up colonies for the newly freed slaves. He commented favorably on colonization in the Emancipation Proclamation, but all attempts at such a massive undertaking failed. As Frederick Douglass observed, Lincoln was, "The first great man that I talked with in the United States freely who in no single instance reminded me of the difference between himself and myself, of the difference of color."
Gettysburg Address.
Although the Battle of Gettysburg was a Union victory, it was also the bloodiest battle of the war and dealt a blow to Lincoln's war effort. As the Union Army decreased in numbers due to casualties, more soldiers were needed to replace the ranks. Lincoln's 1863 military drafts were considered "odious" among many in the north, particularly immigrants. The New York Draft Riots of July 1863 were the most notable manifestation of this discontent.
"If the election were to occur now, the result would be extremely doubtful, and although most of our discreet friends are sanguine of the result, my impression is, the chances would be against us. The draft is very odious in the State... the Democratic leaders have succeeded in exciting prejudice and passion, and have infused their poison into the minds of the people to a very large extent, and the changes are against us."
Therefore, in the fall of 1863, Lincoln's principal aim was to sustain public support for the war effort. This goal became the focus of his address at the Gettysburg battlefield cemetery on November 19.
The "Gettysburg Address" is one of the most quoted speeches in United States history.
It was delivered at the dedication of the Soldiers' National Cemetery in Gettysburg, Pennsylvania, on the afternoon of Thursday, November 19, 1863, during the American Civil War, four and a half months after the Union armies defeated those of the Confederacy at the decisive Battle of Gettysburg.
Abraham Lincoln's carefully crafted address, secondary to other presentations that day, came to be regarded as one of the greatest speeches in American history. In just over two minutes, Lincoln invoked the principles of human equality espoused by the Declaration of Independence and redefined the Civil War as a struggle not merely for the Union, but as "a new birth of freedom" that would bring true equality to all of its citizens, and that would also create a unified nation in which states' rights were no longer dominant.
Beginning with the now-iconic phrase, "Four score and seven years ago...", Lincoln referred to the events of the Civil War and described the ceremony at Gettysburg as an opportunity not only to consecrate the grounds of a cemetery, but also to dedicate the living to the struggle to ensure that "government of the people, by the people, for the people, shall not perish from the earth".
1864 election.
After Union victories at Gettysburg, Vicksburg, and Chattanooga in 1863, overall victory seemed at hand, and Lincoln promoted Ulysses S. Grant General-in-Chief on March 12, 1864. When the spring campaigns turned into bloody stalemates, Lincoln supported Grant's strategy of wearing down Lee's Confederate army at the cost of heavy Union casualties. With an election looming, he easily defeated efforts to deny his renomination. At the Convention, the Republican Party selected Andrew Johnson, a War Democrat from the Southern state of Tennessee, as his running mate to form a broader coalition. They ran on the new Union Party ticket uniting Republicans and War Democrats.
Lincoln did not show the pledge to his cabinet, but asked them to sign the sealed envelope.
While the Democratic platform followed the Peace wing of the party and called the war a "failure," their candidate, General George B. McClellan, supported the war and repudiated the platform.
Lincoln provided Grant with new replacements and mobilized his party to support Grant and win local support for the war effort. Sherman's capture of Atlanta in September ended defeatist jitters; the Democratic Party was deeply split, with some leaders and most soldiers openly for Lincoln; the Union party was united and energized, and Lincoln was easily reelected in a landslide. He won all but three states, including 78% of the Union soldiers' vote.
Second Inaugural Address.
On March 4, 1865, Lincoln delivered his second inaugural address, his favorite of all his speeches. At this time, a victory over the rebels was at hand, slavery was dead, and Lincoln was looking to the future.
Reconstruction.
Reconstruction began during the war as Lincoln and his associates pondered questions of how to reintegrate the Southern states and what to do with Confederate leaders and the freed slaves. Lincoln led the "moderates" regarding Reconstruction policy, and was usually opposed by the Radical Republicans, under Thaddeus Stevens in the House and Charles Sumner and Benjamin Wade in the Senate (though he cooperated with these men on most other issues). Determined to find a course that would reunite the nation and not alienate the South, Lincoln urged that speedy elections under generous terms be held throughout the war in areas behind Union lines. His Amnesty Proclamation of December 8, 1863, offered pardons to those who had not held a Confederate civil office, had not mistreated Union prisoners, and would sign an oath of allegiance.
Critical decisions had to be made as state after state was reconquered. Of special importance were Tennessee, where Lincoln appointed Andrew Johnson as governor, and Louisiana, where Lincoln attempted a plan that would restore statehood when 10% of the voters agreed to it. The Radicals thought this policy too lenient, and passed their own plan, the Wade-Davis Bill, in 1864. When Lincoln pocket vetoed the bill, the Radicals retaliated by refusing to seat representatives elected from Louisiana, Arkansas, and Tennessee.
Near the end of the war, Lincoln made an extended visit to Grant's headquarters at City Point, Virginia. This allowed the president to confer in person with Grant and Sherman about ending hostilities (as Sherman managed a hasty visit to Grant from his forces in North Carolina at the same time).
Lincoln also was able to visit Richmond after it was taken by the Union forces and to make a public gesture of sitting at Jefferson Davis' own desk, symbolically saying to the nation that the President of the United States held authority over the entire land. He was greeted at the city as a conquering hero by freed slaves, whose sentiments were epitomized by one admirer's quote, "I know I am free for I have seen the face of Father Abraham and have felt him." When a general asked Lincoln how the defeated Confederates should be treated, Lincoln replied, "Let 'em up easy."
Lincoln arrived back in Washington on the evening of April 9, 1865, the day Lee surrendered at Appomattox Court House in Virginia. The war was effectively over. The other rebel armies surrendered soon after, and there was no subsequent guerrilla warfare.
Redefining Republicanism.
Lincoln's rhetoric defined the issues of the war for the nation, the world, and posterity. The Gettysburg Address defied Lincoln's own prediction that "the world will little note, nor long remember what we say here." His second inaugural address is also greatly admired and often quoted.
In recent years, historians have stressed Lincoln's use of and redefinition of republican values. As early as the 1850s, a time when most political rhetoric focused on the sanctity of the Constitution, Lincoln shifted emphasis to the Declaration of Independence as the foundation of American political values—what he called the "sheet anchor" of republicanism.
The Declaration's emphasis on freedom and equality for all, rather than the Constitution's tolerance of slavers, shifted the debate. As Diggins concludes regarding the highly influential Cooper Union speech, "Lincoln presented Americans a theory of history that offers a profound contribution to the theory and destiny of republicanism itself."
His position gained strength because he highlighted the moral basis of republicanism, rather than its legalisms.
Nevertheless, in 1861 Lincoln justified the war in terms of legalisms (the Constitution was a contract, and for one party to get out of a contract all the other parties had to agree), and then in terms of the national duty to guarantee a "republican form of government" in every state.
That duty was also the principle underlying federal intervention in Reconstruction.
In his Gettysburg Address Lincoln redefined the American nation, arguing that it was born not in 1789 but in 1776, "conceived in Liberty, and dedicated to the proposition that all men are created equal." He declared that the sacrifices of battle had rededicated the nation to the propositions of democracy and equality, "that this nation shall have a new birth of freedom — and that government of the people, by the people, for the people, shall not perish from the earth." By emphasizing the centrality of the nation, he rebuffed the claims of state sovereignty. While some critics say Lincoln moved too far and too fast, they agree that he dedicated the nation to values that marked "a new founding of the nation."
Civil liberties suspended.
During the Civil War, Lincoln appropriated powers no previous President had wielded: he used his war powers to proclaim a blockade, suspended the writ of habeas corpus, spent money before Congress appropriated it, and imprisoned between 15,000 and 18,000 suspected Confederate sympathizers without trial.
Domestic measures.
Lincoln believed in the Whig theory of the presidency, which left Congress to write the laws while he signed them; Lincoln exercised his veto power only four times, the only significant instance being his pocket veto of the Wade-Davis Bill.
Thus, he signed the Homestead Act in 1862, making millions of acres of government-held land in the West available for purchase at very low cost. The Morrill Land-Grant Colleges Act, also signed in 1862, provided government grants for state agricultural colleges in each state. The Pacific Railway Acts of 1862 and 1864 granted federal support for the construction of the United States' First Transcontinental Railroad, which was completed in 1869. The passage of the Homestead Act and the Pacific Railway Acts was made possible by the absence of Southern congressmen and senators who had opposed the measures in the 1850s.
Other important legislation involved two measures to raise revenues for the Federal government: tariffs (a policy with long precedent), and a Federal income tax (which was new). In 1861, Lincoln signed the second and third Morrill Tariff (the first had become law under James Buchanan). In 1861, Lincoln signed the Revenue Act of 1861
creating the first U.S. income tax. This created a flat tax of 3% on incomes above $800 ($ in current dollars), which was later changed by the Revenue Act of 1862
Lincoln also presided over the expansion of the federal government's economic influence in several other areas. The creation of the system of national banks by the National Banking Acts of 1863, 1864, and 1865 allowed the creation of a strong national financial system. In 1862, Congress created, with Lincoln's approval, the Department of Agriculture, although that institution would not become a Cabinet-level department until 1889. The Legal Tender Act of 1862 established the United States Note, the first paper currency in United States history since the Continentals that were issued during the Revolution. This was done to increase the money supply to pay for fighting the war.
In 1862, Lincoln sent a senior general, John Pope, to put down the "Sioux Uprising" in Minnesota. Presented with 303 death warrants for convicted Santee Dakota who were accused of killing innocent farmers, Lincoln ordered a personal review of these warrants, eventually approving 39 of these for execution (one was later reprieved).
Abraham Lincoln is largely responsible for the institution of the Thanksgiving holiday in the United States. Prior to Lincoln's presidency, Thanksgiving, while a regional holiday in New England since the 17th century, had only been proclaimed by the federal government sporadically, and on irregular dates. The last such proclamation was during James Madison's presidency fifty years before. In 1863, Lincoln declared the final Thursday in November to be a day of Thanksgiving, and the holiday has been celebrated annually then ever since.
Assassination.
Originally, John Wilkes Booth, a well-known actor and a Confederate spy from Maryland, had formulated a plan to kidnap Lincoln in exchange for the release of Confederate prisoners. After attending an April 11 speech in which Lincoln promoted voting rights for blacks, an incensed Booth changed his plans and determined to assassinate the president.
Learning that the President and First Lady would be attending Ford's Theatre, he laid his plans, assigning his co-conspirators to assassinate Vice President Andrew Johnson and Secretary of State William H. Seward.
Without his main bodyguard Ward Hill Lamon, to whom he related his famous dream regarding his own assassination, Lincoln left to attend the play "Our American Cousin" on April 14, 1865. As a lone bodyguard wandered, and Lincoln sat in his state box (Box 7) in the balcony, Booth crept up behind the President and waited for what he thought would be the funniest line of the play ("You sock-dologizing old man-trap"), hoping the laughter would muffle the noise of the gunshot. When the laughter began, Booth jumped into the box and aimed a single-shot, round-ball.44 caliber (11 mm) Deringer at his head, firing at point-blank range. Major Henry Rathbone momentarily grappled with Booth but was cut by Booth's knife. Booth then leaped to the stage and shouted "Sic semper tyrannis!" () and escaped, despite suffering a broken leg in the leap.
A twelve-day manhunt ensued, in which Booth was chased by Federal agents (under the direction of Secretary of War Edwin M. Stanton).
He was eventually cornered in a Virginia barn house and shot, dying of his wounds soon after.
An army surgeon, Doctor Charles Leale, initially assessed Lincoln's wound as mortal. The President was taken across the street from the theater to the Petersen House, where he lay in a coma for nine hours before dying. Several physicians attended Lincoln, including U.S. Army Surgeon General Joseph K. Barnes of the Army Medical Museum. Using a probe, Barnes located some fragments of Lincoln's skull and the ball lodged inside his brain. Lincoln never regained consciousness and was pronounced dead at 7:22:10 a.m. April 15, 1865. He was the first president to be assassinated or to lie in state.
Lincoln's body was carried by train in a grand funeral procession through several states on its way back to Illinois.
While much of the nation mourned him as the savior of the United States, Copperheads celebrated the death of a man they considered a tyrant. The Lincoln Tomb in Oak Ridge Cemetery in Springfield, is tall and, by 1874, was surmounted with several bronze statues of Lincoln. To prevent repeated attempts to steal Lincoln's body and hold it for ransom, Robert Todd Lincoln had it exhumed and reinterred in concrete several feet thick in 1901.
Religious and philosophical beliefs.
In March 1860 in a speech in New Haven, Connecticut, Lincoln said, regarding slavery, "Whenever this question shall be settled, it must be settled on some philosophical basis. No policy that does not rest upon some philosophical public opinion can be permanently maintained." The philosophical basis for Lincoln's beliefs regarding slavery and other issues of the day require that Lincoln be examined "seriously as a man of ideas." Lincoln was a strong supporter of the American Whig version of liberal capitalism who, more than most politicians of the time, was able to express his ideas within the context of Nineteenth Century religious beliefs.
There were few people who strongly or directly influenced Lincoln's moral and intellectual development and perspectives. There was no teacher, mentor, church leader, community leader, or peer that Lincoln would credit in later years as a strong influence on his intellectual development. Lacking a formal education, Lincoln's personal philosophy was shaped by "an amazingly retentive memory and a passion for reading and learning." It was Lincoln's reading, rather than his relationships, that were most influential in shaping his personal beliefs.
Even as a child, Lincoln largely rejected organized religion, but the Calvinistic "doctrine of necessity" would remain a factor throughout his life. In 1846 Lincoln described the effect of this doctrine as "that the human mind is impelled to action, or held in rest by some power, over which the mind itself has no control."
In April 1864, in justifying his actions regarding Emancipation, Lincoln wrote, "I claim not to have controlled events, but confess plainly that events have controlled me. Now, at the end of three years struggle the nation's condition is not what either party, or any man devised, or expected. God alone can claim it."
As Lincoln matured, and especially during his term as president, the idea of a divine will somehow interacting with human affairs increasingly influenced his public expressions. On a personal level, the death of his son Willie in February 1862 may have caused Lincoln to look towards religion for answers and solace.
Lincoln's religious skepticism was fueled by his exposure to the ideas of the Lockean Enlightenment and classical liberalism, especially economic liberalism. Consistent with the common practice of the Whig party, Lincoln would often use the Declaration of Independence as the philosophical and moral expression of these two philosophies.
In a February 22, 1861 speech at Independence Hall in Philadelphia Lincoln said,
He found in the Declaration justification for Whig economic policy and opposition to territorial expansion and the nativist platform of the Know Nothings. In claiming that all men were created free, Lincoln and the Whigs argued that this freedom required economic advancement, expanded education, territory to grow, and the ability of the nation to absorb the growing immigrant population.
It was the Declaration of Independence, rather than the Bible, that Lincoln most relied on to oppose any further territorial expansion of slavery. He saw the Declaration as more than a political document. To him, as well as to many abolitionists and other antislavery leaders, it was, foremost, a moral document that had forever determined valuable principles for the future shaping of the nation.
Legacy and memorials.
Lincoln's death made the President a national martyr,
regarded by historians in numerous polls as among the greatest presidents in U.S. history, usually in the top three, along with George Washington and Franklin D. Roosevelt.
A study published in 2004, found that scholars in the fields of history and politics ranked Lincoln number one, while law scholars placed him second after Washington.
Among contemporary admirers, Lincoln is usually seen as personifying classical values of honesty and integrity, as well as respect for individual and minority rights, and human freedom in general.
Many American organizations of all purposes and agendas continue to cite his name and image, with interests ranging from the gay rights-supporting Log Cabin Republicans to the insurance corporation Lincoln National Corporation. The Lincoln automobile brand is also named after him.
The ballistic missile submarine "Abraham Lincoln" (SSBN-602) and the aircraft carrier "Abraham Lincoln" (CVN-72) were named in his honor.
During the Spanish Civil War, the American faction of the International Brigades named themselves the Abraham Lincoln Brigade.
Lincoln has been memorialized in many town, city, and county names,
Lincoln, Illinois, is the only city to be named for Abraham Lincoln before he became President.
Lincoln's name and image appear in numerous places. These include the Lincoln Memorial in Washington, D.C., the U.S. Lincoln $5 bill and the Lincoln cent, and Lincoln's sculpture on Mount Rushmore. Abraham Lincoln Birthplace National Historical Park in Hodgenville, Kentucky,
Lincoln Boyhood National Memorial in Lincoln City, Indiana,
and Lincoln Home National Historic Site in Springfield, Illinois,
In addition, New Salem, Illinois (a reconstruction of Lincoln's early adult hometown),
Ford's Theatre, and Petersen House (where he died) are all preserved as museums.
The state nickname for Illinois is "Land of Lincoln"; the slogan has appeared continuously on nearly all Illinois license plates issued since 1954.
Abraham Lincoln's birthday, February 12, was never a national holiday, but it was observed by 30 states. In 1971, Presidents Day became a national holiday, combining Lincoln's and Washington's birthdays, and replacing most states' celebration of his birthday.
As of 2005, Lincoln's Birthday is a legal holiday in 10 states.
The Abraham Lincoln Association was formed in 1908 to commemorate the centennial of Lincoln's birth.
The Association is now the oldest group dedicated to the study of Lincoln.
To commemorate his 200th birthday in February 2009, Congress established the Abraham Lincoln Bicentennial Commission (ALBC) in 2000 to honor Lincoln.
The Abraham Lincoln Presidential Library and Museum is located in Springfield and is run by the State of Illinois.
Lincoln owned a model 1857 Waltham William Ellery watch, with serial number 67613. This watch is now in the custody of the Smithsonian Museum.
On March 11, 2009, the National Museum of American History found a message engraved inside Lincoln's watch by a watchmaker named Jonathan Dillon who was repairing it at the outbreak of the American Civil War. The engraving reads (in part): "Fort Sumpter was attacked by the rebels" and "thank God we have a government."
---END.OF.DOCUMENT---

Aristotle.
Aristotle (, "Aristotélēs") (384 BC – 322 BC) was a Greek philosopher, a student of Plato and teacher of Alexander the Great. His writings cover many subjects, including physics, metaphysics, poetry, theater, music, logic, rhetoric, politics, government, ethics, biology, and zoology.
Together with Plato and Socrates (Plato's teacher), Aristotle is one of the most important founding figures in Western philosophy. Aristotle's writings constitute a first at creating a comprehensive system of Western philosophy, encompassing morality and aesthetics, logic and science, politics and metaphysics.
Aristotle's views on the physical sciences profoundly shaped medieval scholarship, and their influence extended well into the Renaissance, although they were ultimately replaced by Newtonian physics. In the biological sciences, some of his observations were confirmed to be accurate only in the nineteenth century. His works contain the earliest known formal study of logic, which was incorporated in the late nineteenth century into modern formal logic. In metaphysics, Aristotelianism had a profound influence on philosophical and theological thinking in the Islamic and Jewish traditions in the Middle Ages, and it continues to influence Christian theology, especially Eastern Orthodox theology, and the scholastic tradition of the Catholic Church. His ethics, though always influential, gained renewed interest with the modern advent of virtue ethics. All aspects of Aristotle's philosophy continue to be the object of active academic study today. Though Aristotle wrote many elegant treatises and dialogues (Cicero described his literary style as "a river of gold"), it is thought that the majority of his writings are now lost and only about one-third of the original works have survived.
Despite the far-reaching appeal that Aristotle's works have traditionally enjoyed, today modern scholarship questions a substantial portion of the Aristotelian corpus as authentically Aristotle's own.
Life.
Aristotle was born in Stageira, Chalcidice, in 384 BC, about east of modern-day Thessaloniki. His father Nicomachus was the personal physician to King Amyntas of Macedon. Aristotle was trained and educated as a member of the aristocracy. At about the age of eighteen, he went to Athens to continue his education at Plato's Academy. Aristotle remained at the academy for nearly twenty years, not leaving until after Plato's death in 347 BC. He then traveled with Xenocrates to the court of his friend Hermias of Atarneus in Asia Minor. While in Asia, Aristotle traveled with Theophrastus to the island of Lesbos, where together they researched the botany and zoology of the island. Aristotle married Hermias's adoptive daughter (or niece) Pythias. She bore him a daughter, whom they named Pythias. Soon after Hermias' death, Aristotle was invited by Philip II of Macedon to become the tutor to his son Alexander the Great in 343 B.C.
Aristotle was appointed as the head of the royal academy of Macedon. During that time he gave lessons not only to Alexander, but also to two other future kings: Ptolemy and Cassander. In his "Politics", Aristotle states that only one thing could justify monarchy, and that was if the virtue of the king and his family were greater than the virtue of the rest of the citizens put together. Tactfully, he included the young prince and his father in that category. Aristotle encouraged Alexander toward eastern conquest, and his attitude towards Persia was unabashedly ethnocentric. In one famous example, he counsels Alexander to be 'a leader to the Greeks and a despot to the barbarians, to look after the former as after friends and relatives, and to deal with the latter as with beasts or plants'.
By 335 BC he had returned to Athens, establishing his own school there known as the Lyceum. Aristotle conducted courses at the school for the next twelve years. While in Athens, his wife Pythias died and Aristotle became involved with Herpyllis of Stageira, who bore him a son whom he named after his father, Nicomachus. According to the Suda, he also had an eromenos, Palaephatus of Abydus.
It is during this period in Athens from 335 to 323 BC when Aristotle is believed to have composed many of his works. Aristotle wrote many dialogues, only fragments of which survived. The works that have survived are in treatise form and were not, for the most part, intended for widespread publication, as they are generally thought to be lecture aids for his students. His most important treatises include "Physics", "Metaphysics", "Nicomachean Ethics", "Politics", "De Anima (On the Soul)" and "Poetics".
Aristotle not only studied almost every subject possible at the time, but made significant contributions to most of them. In physical science, Aristotle studied anatomy, astronomy, embryology, geography, geology, meteorology, physics and zoology. In philosophy, he wrote on aesthetics, ethics, government, metaphysics, politics, economics, psychology, rhetoric and theology. He also studied education, foreign customs, literature and poetry. His combined works constitute a virtual encyclopedia of Greek knowledge. It has been suggested that Aristotle was probably the last person to know everything there was to be known in his own time.
Near the end of Alexander's life, Alexander began to suspect plots against himself, and threatened Aristotle in letters. Aristotle had made no secret of his contempt for Alexander's pretense of divinity, and the king had executed Aristotle's grandnephew Callisthenes as a traitor. A widespread tradition in antiquity suspected Aristotle of playing a role in Alexander's death, but there is little evidence for this.
Upon Alexander's death, anti-Macedonian sentiment in Athens once again flared. Eurymedon the hierophant denounced Aristotle for not holding the gods in honor. Aristotle fled the city to his mother's family estate in Chalcis, explaining, "I will not allow the Athenians to sin twice against philosophy," a reference to Athens's prior trial and execution of Socrates. However, he died in Euboea of natural causes within the year (in 322 BC). Aristotle named chief executor his student Antipater and left a will in which he asked to be buried next to his wife.
Logic.
With the "Prior Analytics", Aristotle is credited with the earliest study of formal logic, and his conception of it was the dominant form of Western logic until 19th century advances in mathematical logic. Kant stated in the "Critique of Pure Reason" that Aristotle's theory of logic completely accounted for the core of deductive inference.
History.
Aristotle "says that 'on the subject of reasoning' he 'had nothing else on an earlier date to speak of'". However, Plato reports that syntax was devised before him, by Prodicus of Ceos, who was concerned by the correct use of words. Logic seems to have emerged from dialectics; the earlier philosophers made frequent use of concepts like "reductio ad absurdum" in their discussions, but never truly understood the logical implications. Even Plato had difficulties with logic; although he had a reasonable conception of a deducting system, he could never actually construct one and relied instead on his dialectic. Plato believed that deduction would simply follow from premises, hence he focused on maintaining solid premises so that the conclusion would logically follow. Consequently, Plato realized that a method for obtaining conclusions would be most beneficial. He never succeeded in devising such a method, but his best attempt was published in his book "Sophist", where he introduced his division method.
Analytics and the "Organon".
The order of the books (or the teachings from which they are composed) is not certain, but this list was derived from analysis of Aristotle's writings. It goes from the basics, the analysis of simple terms in the "Categories," the analysis of propositions and their elementary relations in "On Interpretation", to the study of more complex forms, namely, syllogisms (in the "Analytics") and dialectics (in the "Topics" and "Sophistical Refutations"). The first three treatises form the core of the logical theory "stricto sensu": the grammar of the language of logic and the correctness rules of reasoning. There is one volume of Aristotle's concerning logic not found in the "Organon", namely the fourth book of "Metaphysics.".
Aristotle's scientific method.
Like his teacher Plato, Aristotle's philosophy aims at the universal. Aristotle, however, found the universal in particular things, which he called the essence of things, while Plato finds that the universal exists apart from particular things, and is related to them as their prototype or exemplar. For Aristotle, therefore, philosophic method implies the ascent from the study of particular phenomena to the knowledge of essences, while for Plato philosophic method means the descent from a knowledge of universal Forms (or ideas) to a contemplation of particular imitations of these. For Aristotle, "form" still refers to the unconditional basis of phenomena but is "instantiated" in a particular substance (see "Universals and particulars", below). In a certain sense, Aristotle's method is both inductive and deductive, while Plato's is essentially deductive from "a priori" principles.
In Aristotle's terminology, "natural philosophy" is a branch of philosophy examining the phenomena of the natural world, and includes fields that would be regarded today as physics, biology and other natural sciences. In modern times, the scope of "philosophy" has become limited to more generic or abstract inquiries, such as ethics and metaphysics, in which logic plays a major role. Today's philosophy tends to exclude empirical study of the natural world by means of the scientific method. In contrast, Aristotle's philosophical endeavors encompassed virtually all facets of intellectual inquiry.
In the larger sense of the word, Aristotle makes philosophy coextensive with reasoning, which he also would describe as "science". Note, however, that his use of the term "science" carries a different meaning than that covered by the term "scientific method". For Aristotle, "all science ("dianoia") is either practical, poetical or theoretical" ("Metaphysics" 1025b25). By practical science, he means ethics and politics; by poetical science, he means the study of poetry and the other fine arts; by theoretical science, he means physics, mathematics and metaphysics.
If logic (or "analytics") is regarded as a study preliminary to philosophy, the divisions of Aristotelian philosophy would consist of: (1) Logic; (2) Theoretical Philosophy, including Metaphysics, Physics, Mathematics, (3) Practical Philosophy and (4) Poetical Philosophy.
In the period between his two stays in Athens, between his times at the Academy and the Lyceum, Aristotle conducted most of the scientific thinking and research for which he is renowned today. In fact, most of Aristotle's life was devoted to the study of the objects of natural science. Aristotle's metaphysics contains observations on the nature of numbers but he made no original contributions to mathematics. He did, however, perform original research in the natural sciences, e.g., botany, zoology, physics, astronomy, chemistry, meteorology, and several other sciences.
Aristotle's writings on science are largely qualitative, as opposed to quantitative. Beginning in the sixteenth century, scientists began applying mathematics to the physical sciences, and Aristotle's work in this area was deemed hopelessly inadequate. His failings were largely due to the absence of concepts like mass, velocity, force and temperature. He had a conception of speed and temperature, but no quantitative understanding of them, which was partly due to the absence of basic experimental devices, like clocks and thermometers.
His writings provide an account of many scientific observations, a mixture of precocious accuracy and curious errors. For example, in his "History of Animals" he claimed that human males have more teeth than females and in the "Generation of Animals" he said the female is as it were a deformed male.
In a similar vein, John Philoponus, and later Galileo, showed by simple experiments that Aristotle's theory that a heavier object falls faster than a lighter object is incorrect. On the other hand, Aristotle refuted Democritus's claim that the Milky Way was made up of "those stars which are shaded by the earth from the sun's rays," pointing out (correctly, even if such reasoning was bound to be dismissed for a long time) that, given "current astronomical demonstrations" that "the size of the sun is greater than that of the earth and the distance of the stars from the earth many times greater than that of the sun, then...the sun shines on all the stars and the earth screens none of them."
In places, Aristotle goes too far in deriving 'laws of the universe' from simple observation and over-stretched reason. Today's scientific method assumes that such thinking without sufficient facts is ineffective, and that discerning the validity of one's hypothesis requires far more rigorous experimentation than that which Aristotle used to support his laws.
Aristotle also had some scientific blind spots. He posited a geocentric cosmology that we may discern in selections of the "Metaphysics", which was widely accepted up until the 1500s. From the 3rd century to the 1500s, the dominant view held that the Earth was the center of the universe (geocentrism).
Since he was perhaps the philosopher most respected by European thinkers during and after the Renaissance, these thinkers often took Aristotle's erroneous positions as given, which held back science in this epoch. However, Aristotle's scientific shortcomings should not mislead one into forgetting his great advances in the many scientific fields. For instance, he founded logic as a formal science and created foundations to biology that were not superseded for two millennia. Moreover, he introduced the fundamental notion that nature is composed of things that change and that studying such changes can provide useful knowledge of underlying constants.
The five elements.
Each of the four earthly elements has its natural place; the earth at the centre of the universe, then water, then air, then fire. When they are out of their natural place they have natural motion, requiring no external cause, which is towards that place; so bodies sink in water, air bubbles rise up, rain falls, flame rises in air. The heavenly element has perpetual circular motion.
Causality, The Four Causes===.
Additionally, things can be causes of one another, causing each other reciprocally, as hard work causes fitness and vice versa, although not in the same way or function, the one is as the beginning of change, the other as the goal. (Thus Aristotle first suggested a reciprocal or circular causality as a relation of mutual dependence or influence of cause upon effect). Moreover, Aristotle indicated that the same thing can be the cause of contrary effects; its presence and absence may result in different outcomes. Simply it is the goal or purpose that brings about an event (not necessarily a mental goal). Taking our two dominos, it requires someone to intentionally knock the dominos over as they cannot fall themselves.
Aristotle marked two modes of causation: proper (prior) causation and accidental (chance) causation. All causes, proper and incidental, can be spoken as potential or as actual, particular or generic. The same language refers to the effects of causes, so that generic effects assigned to generic causes, particular effects to particular causes, operating causes to actual effects. Essentially, causality does not suggest a temporal relation between the cause and the effect.
All further investigations of causality will consist of imposing the favorite hierarchies on the order causes, such as final > efficient > material > formal (Thomas Aquinas), or of restricting all causality to the material and efficient causes or to the efficient causality (deterministic or chance) or just to regular sequences and correlations of natural phenomena (the natural sciences describing how things happen instead of explaining the whys and wherefores).
Optics.
Aristotle held more accurate theories on some optical concepts than other philosophers of his day. The earliest known written evidence of a camera obscura can be found in Aristotle's documentation of such a device in 350 BC in "Problemata". Aristotle's apparatus contained a dark chamber that had a single small hole, or aperture, to allow for sunlight to enter. Aristotle used the device to make observations of the sun and noted that no matter what shape the hole was, the sun would still be correctly displayed as a round object. In modern cameras, this is analogous to the diaphragm. Aristotle also made the observation that when the distance between the tiny hole and the surface with the image increased, the image was amplified.
Chance and spontaneity.
Spontaneity and chance are causes of effects. Chance as an incidental cause lies in the realm of accidental things. It is "from what is spontaneous" (but note that what is spontaneous does not come from chance). For a better understanding of Aristotle's conception of "chance" it might be better to think of "coincidence": Something takes place by chance if a person sets out with the intent of having one thing take place, but with the result of another thing (not intended) taking place. For example: A person seeks donations. That person may find another person willing to donate a substantial sum. However, if the person seeking the donations met the person donating, not for the purpose of collecting donations, but for some other purpose, Aristotle would call the collecting of the donation by that particular donator a result of chance. It must be unusual that something happens by chance. In other words, if something happens all or most of the time, we cannot say that it is by chance.
There is also more specific kind of chance, which Aristotle names "luck", that can only apply to human beings, since it is in the sphere of moral actions. According to Aristotle, luck must involve choice (and thus deliberation), and only humans are capable of deliberation and choice. "What is not capable of action cannot do anything by chance".
Metaphysics.
Aristotle defines metaphysics as "the knowledge of immaterial being," or of "being in the highest degree of abstraction." He refers to metaphysics as "first philosophy", as well as "the theologic science."
Substance, potentiality and actuality.
Aristotle examines the concept of substance and essence ("ousia") in his "Metaphysics", Book VII and he concludes that a particular substance is a combination of both matter and form. As he proceeds to the book VIII, he concludes that the matter of the substance is the substratum or the stuff of which it is composed, "e.g." the matter of the house are the bricks, stones, timbers etc., or whatever constitutes the "potential" house. While the form of the substance, is the "actual" house, namely 'covering for bodies and chattels' or any other differentia (see also predicables). The formula that gives the components is the account of the matter, and the formula that gives the differentia is the account of the form.
With regard to the change ("kinesis") and its causes now, as he defines in his Physics and On Generation and Corruption 319b-320a, he distinguishes the coming to be from: 1) growth and diminution, which is change in quantity; 2) locomotion, which is change in space; and 3) alteration, which is change in quality.
The coming to be is a change where nothing persists of which the resultant is a property. In that particular change he introduces the concept of potentiality ("dynamis") and actuality ("entelecheia") in association with the matter and the form.
Referring to potentiality, this is what a thing is capable of doing, or being acted upon, if it is not prevented by something else. For example, the seed of a plant in the soil is potentially ("dynamei") plant, and if is not prevented by something, it will become a plant. Potentially beings can either 'act' ("poiein") or 'be acted upon' ("paschein"), which can be either innate or learned. For example, the eyes possess the potentiality of sight (innate – being acted upon), while the capability of playing the flute can be possessed by learning (exercise – acting).
Actuality is the fulfillment of the end of the potentiality. Because the end ("telos") is the principle of every change, and for the sake of the end exists potentiality, therefore actuality is the end. Referring then to our previous example, we could say that actuality is when the seed of the plant becomes a plant.
" For that for the sake of which a thing is, is its principle, and the becoming is for the sake of the end; and the actuality is the end, and it is for the sake of this that the potentiality is acquired. For animals do not see in order that they may have sight, but they have sight that they may see."
In conclusion, the matter of the house is its potentiality and the form is its actuality. The formal cause ("aitia") then of that change from potential to actual house, is the reason ("logos") of the house builder and the final cause is the end, namely the house itself. Then Aristotle proceeds and concludes that the actuality is prior to potentiality in formula, in time and in substantiality.
With this definition of the particular substance (i.e., matter and form), Aristotle tries to solve the problem of the unity of the beings, "e.g.", what is that makes the man one? Since, according to Plato there are two Ideas: animal and biped, how then is man a unity? However, according to Aristotle, the potential being (matter) and the actual one (form) are one and the same thing.
Universals and particulars.
Aristotle's predecessor, Plato, argued that all things have a universal form, which could be either a property, or a relation to other things. When we look at an apple, for example, we see an apple, and we can also analyze a form of an apple. In this distinction, there is a particular apple and a universal form of an apple. Moreover, we can place an apple next to a book, so that we can speak of both the book and apple as being next to each other.
Plato argued that there are some universal forms that are not a part of particular things. For example, it is possible that there is no particular good in existence, but "good" is still a proper universal form. Bertrand Russell is a contemporary philosopher that agreed with Plato on the existence of "uninstantiated universals".
Aristotle disagreed with Plato on this point, arguing that all universals are instantiated. Aristotle argued that there are no universals that are unattached to existing things. According to Aristotle, if a universal exists, either as a particular or a relation, then there must have been, must be currently, or must be in the future, something on which the universal can be predicated. Consequently, according to Aristotle, if it is not the case that some universal can be predicated to an object that exists at some period of time, then it does not exist.
In addition, Aristotle disagreed with Plato about the location of universals. As Plato spoke of the world of the forms, a location where all universal forms subsist, Aristotle maintained that universals exist within each thing on which each universal is predicated. So, according to Aristotle, the form of apple exists within each apple, rather than in the world of the forms.
Biology and medicine.
In Aristotelian science, most especially in biology, things he saw himself have stood the test of time better than his retelling of the reports of others, which contain error and superstition. He dissected animals, but not humans and his ideas on how the human body works have been almost entirely superseded.
Empirical research program.
Aristotle is the earliest natural historian whose work has survived in some detail. Aristotle certainly did research on the natural history of Lesbos, and the surrounding seas and neighbouring areas. The works that reflect this research, such as "History of Animals", "Generation of Animals", and "Parts of Animals", contain some observations and interpretations, along with sundry myths and mistakes. The most striking passages are about the sea-life visible from observation on Lesbos and available from the catches of fishermen. His observations on catfish, electric fish ("Torpedo") and angler-fish are detailed, as is his writing on cephalopods, namely, "Octopus", "Sepia" (cuttlefish) and the paper nautilus ("Argonauta argo"). His description of the hectocotyl arm was about two thousand years ahead of its time, and widely disbelieved until its rediscovery in the nineteenth century. He separated the aquatic mammals from fish, and knew that sharks and rays were part of the group he called Selachē (selachians).
Another good example of his methods comes from the "Generation of Animals" in which Aristotle describes breaking open fertilized chicken eggs at intervals to observe when visible organs were generated.
He gave accurate descriptions of ruminants' four-chambered fore-stomachs, and of the ovoviviparous embryological development of the hound shark "Mustelus mustelus".
Classification of living things.
Aristotle's classification of living things contains some elements which still existed in the nineteenth century. What the modern zoologist would call vertebrates and invertebrates, Aristotle called 'animals with blood' and 'animals without blood' (he was not to know that complex invertebrates do make use of haemoglobin, but of a different kind from vertebrates). Animals with blood were divided into live-bearing (humans and mammals), and egg-bearing (birds and fish). Invertebrates ('animals without blood') are insects, crustacea (divided into non-shelled – cephalopods – and shelled) and testacea (molluscs). In some respects, this incomplete classification is better than that of Linnaeus, who crowded the invertebrata together into two groups, Insecta and Vermes (worms).
For Charles Singer, "Nothing is more remarkable than [Aristotle's] efforts to [exhibit] the relationships of living things as a "scala naturae" Aristotle's "History of Animals" classified organisms in relation to a hierarchical "Ladder of Life" ("scala naturae"), placing them according to complexity of structure and function so that higher organisms showed greater vitality and ability to move.
Aristotle believed that intellectual purposes, i.e., formal causes, guided all natural processes. Such a teleological view gave Aristotle cause to justify his observed data as an expression of formal design. Noting that "no animal has, at the same time, both tusks and horns," and "a single-hooved animal with two horns I have never seen," Aristotle suggested that Nature, giving no animal both horns and tusks, was staving off vanity, and giving creatures faculties only to such a degree as they are necessary. Noting that ruminants had a multiple stomachs and weak teeth, he supposed the first was to compensate for the latter, with Nature trying to preserve a type of balance.
In a similar fashion, Aristotle believed that creatures were arranged in a graded scale of perfection rising from plants on up to man, the "scala naturae" or Great Chain of Being. His system had eleven grades, arranged according "to the degree to which they are infected with potentiality", expressed in their form at birth. The highest animals laid warm and wet creatures alive, the lowest bore theirs cold, dry, and in thick eggs.
Aristotle also held that the level of a creature's perfection was reflected in its form, but not preordained by that form. Ideas like this, and his ideas about souls, are not regarded as science at all in modern times.
He placed emphasis on the type(s) of soul an organism possessed, asserting that plants possess a vegetative soul, responsible for reproduction and growth, animals a vegetative and a sensitive soul, responsible for mobility and sensation, and humans a vegetative, a sensitive, and a rational soul, capable of thought and reflection.
Aristotle, in contrast to earlier philosophers, but in accordance with the Egyptians, placed the rational soul in the heart, rather than the brain. Notable is Aristotle's division of sensation and thought, which generally went against previous philosophers, with the exception of Alcmaeon.
Successor: Theophrastus.
Aristotle's successor at the Lyceum, Theophrastus, wrote a series of books on botany—the "History of Plants"—which survived as the most important contribution of antiquity to botany, even into the Middle Ages. Many of Theophrastus' names survive into modern times, such as "carpos" for fruit, and "pericarpion" for seed vessel.
Rather than focus on formal causes, as Aristotle did, Theophrastus suggested a mechanistic scheme, drawing analogies between natural and artificial processes, and relying on Aristotle's concept of the efficient cause. Theophrastus also recognized the role of sex in the reproduction of some higher plants, though this last discovery was lost in later ages.
Influence on Hellenistic medicine.
After Theophrastus, the Lyceum failed to produce any original work. Though interest in Aristotle's ideas survived, they were generally taken unquestioningly. It is not until the age of Alexandria under the Ptolemies that advances in biology can be again found.
The first medical teacher at Alexandria Herophilus of Chalcedon, corrected Aristotle, placing intelligence in the brain, and connected the nervous system to motion and sensation. Herophilus also distinguished between veins and arteries, noting that the latter pulse while the former do not. Though a few ancient atomists such as Lucretius challenged the teleological viewpoint of Aristotelian ideas about life, teleology (and after the rise of Christianity, natural theology) would remain central to biological thought essentially until the 18th and 19th centuries. Ernst Mayr claimed that there was "nothing of any real consequence in biology after Lucretius and Galen until the Renaissance." Aristotle's ideas of natural history and medicine survived, but they were generally taken unquestioningly.
Ethics.
Aristotle considered ethics to be a practical rather than theoretical study, i.e., one aimed at doing good rather than knowing for its own sake. He wrote several treatises on ethics, including most notably, the "Nichomachean Ethics".
Aristotle taught that virtue has to do with the proper function ("ergon") of a thing. An eye is only a good eye in so much as it can see, because the proper function of an eye is sight. Aristotle reasoned that humans must have a function specific to humans, and that this function must be an activity of the "psuchē" (normally translated as "soul") in accordance with reason ("logos"). Aristotle identified such an optimum activity of the soul as the aim of all human deliberate action, "eudaimonia", generally translated as "happiness" or sometimes "well being". To have the potential of ever being happy in this way necessarily requires a good character ("ēthikē" "aretē"), often translated as moral (or ethical) virtue (or excellence).
Aristotle taught that to achieve a virtuous and potentially happy character requires a first stage of having the fortune to be habituated not deliberately, but by teachers, and experience, leading to a later stage in which one consciously chooses to do the best things. When the best people come to live life this way their practical wisdom ("phronēsis") and their intellect ("nous") can develop with each other towards the highest possible ethical virtue, that of wisdom.
Politics.
In addition to his works on ethics, which address the individual, Aristotle addressed the city in his work titled "Politics". Aristotle's conception of the city is organic, and he is considered one of the first to conceive of the city in this manner. Aristotle considered the city to be a natural community. Moreover, he considered the city to be prior to the family which in turn is prior to the individual, i.e., last in the order of becoming, but first in the order of being. He is also famous for his statement that "man is by nature a political animal." Aristotle conceived of politics as being like an organism rather than like a machine, and as a collection of parts none of which can exist without the others.
It should be noted that the modern understanding of a political community is that of the state. However, the state was foreign to Aristotle. He referred to political communities as cities. Aristotle understood a city as a political "partnership". Subsequently, a city is created not to avoid injustice or for economic stability, but rather to live a good life: "The political partnership must be regarded, therefore, as being for the sake of noble actions, not for the sake of living together". This can be distinguished from the social contract theory which individuals leave the state of nature because of "fear of violent death" or its "inconveniences."
Rhetoric and poetics.
Aristotle considered epic poetry, tragedy, comedy, dithyrambic poetry and music to be imitative, each varying in imitation by medium, object, and manner. For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation – through narrative or character, through change or no change, and through drama or no drama. Aristotle believed that imitation is natural to mankind and constitutes one of mankind's advantages over animals.
While it is believed that Aristotle's "Poetics" comprised two books – one on comedy and one on tragedy – only the portion that focuses on tragedy has survived. Aristotle taught that tragedy is composed of six elements: plot-structure, character, style, spectacle, and lyric poetry. The characters in a tragedy are merely a means of driving the story; and the plot, not the characters, is the chief focus of tragedy. Tragedy is the imitation of action arousing pity and fear, and is meant to effect the catharsis of those same emotions. Aristotle concludes "Poetics" with a discussion on which, if either, is superior: epic or tragic mimesis. He suggests that because tragedy possesses all the attributes of an epic, possibly possesses additional attributes such as spectacle and music, is more unified, and achieves the aim of its mimesis in shorter scope, it can be considered superior to epic.
Aristotle was a keen systematic collector of riddles, folklore, and proverbs; he and his school had a special interest in the riddles of the Delphic Oracle and studied the fables of Aesop.
Modern scholarship.
Modern scholarship reveals that Aristotle's "lost" works stray considerably in characterization from the surviving Aristotelian corpus. Whereas the lost works appear to have been originally written with an intent for subsequent publication, the surviving works do not appear to have been so. Rather the surviving works mostly resemble lectures unintended for publication. The authenticity of a portion of the surviving works as originally Aristotelian is also today held suspect, with some books duplicating or summarizing each other, the authorship of one book questioned and another book considered to be unlikely Aristotle's at all.
Some of the individual works within the corpus, including the "Constitution of Athens," are regarded by most scholars as products of Aristotle's "school," perhaps compiled under his direction or supervision. Others, such as "On Colors," may have been produced by Aristotle's successors at the Lyceum, e.g., Theophrastus and Straton. Still others acquired Aristotle's name through similarities in doctrine or content, such as the "De Plantis," possibly by Nicolaus of Damascus. Other works in the corpus include medieval palmistries and astrological and magical texts whose connections to Aristotle are purely fanciful and self-promotional.
Loss of his works.
According to a distinction that originates with Aristotle himself, his writings are divisible into two groups: the "exoteric" and the "esoteric". Most scholars have understood this as a distinction between works Aristotle intended for the public (exoteric), and the more technical works (esoteric) intended for the narrower audience of Aristotle's students and other philosophers who were familiar with the jargon and issues typical of the Platonic and Aristotelian schools. Another common assumption is that none of the exoteric works is extant – that all of Aristotle's extant writings are of the esoteric kind. Current knowledge of what exactly the exoteric writings were like is scant and dubious, though many of them may have been in dialogue form. ("Fragments" of some of Aristotle's dialogues have survived.) Perhaps it is to these that Cicero refers when he characterized Aristotle's writing style as "a river of gold"; it is hard for many modern readers to accept that one could seriously so admire the style of those works currently available to us. However, some modern scholars have warned that we cannot know for certain that Cicero's praise was reserved specifically for the exoteric works; a few modern scholars have actually admired the concise writing style found in Aristotle's extant works.
One major question in the history of Aristotle's works, then, is how were the exoteric writings all lost, and how did the ones we now possess come to us? The story of the original manuscripts of the esoteric treatises is described by Strabo in his "Geography" and Plutarch in his "Parallel Lives". The manuscripts were left from Aristotle to his successor Theophrastus, who in turn willed them to Neleus of Scepsis. Neleus supposedly took the writings from Athens to Scepsis, where his heirs let them languish in a cellar until the first century BC, when Apellicon of Teos discovered and purchased the manuscripts, bringing them back to Athens. According to the story, Apellicon tried to repair some of the damage that was done during the manuscripts' stay in the basement, introducing a number of errors into the text. When Lucius Cornelius Sulla occupied Athens in 86 BC, he carried off the library of Apellicon to Rome, where they were first published in 60 BC by the grammarian Tyrannion of Amisus and then by philosopher Andronicus of Rhodes.
Carnes Lord attributes the popular belief in this story to the fact that it provides "the most plausible explanation for the rapid eclipse of the Peripatetic school after the middle of the third century, and for the absence of widespread knowledge of the specialized treatises of Aristotle throughout the Hellenistic period, as well as for the sudden reappearance of a flourishing Aristotelianism during the first century B.C." Lord voices a number of reservations concerning this story, however. First, the condition of the texts is far too good for them to have suffered considerable damage followed by Apellicon's inexpert attempt at repair. Second, there is "incontrovertible evidence," Lord says, that the treatises were in circulation during the time in which Strabo and Plutarch suggest they were confined within the cellar in Scepsis. Third, the definitive edition of Aristotle's texts seems to have been made in Athens some fifty years before Andronicus supposedly compiled his. And fourth, ancient library catalogues predating Andronicus' intervention list an Aristotelian corpus quite similar to the one we currently possess. Lord sees a number of post-Aristotelian interpolations in the "Politics", for example, but is generally confident that the work has come down to us relatively intact.
As the influence of the "falsafa" grew in the West, in part due to Gerard of Cremona's translations and the spread of Averroism, the demand for Aristotle's works grew. William of Moerbeke translated a number of them into Latin. When Thomas Aquinas wrote his theology, working from Moerbeke's translations, the demand for Aristotle's writings grew and the Greek manuscripts returned to the West, stimulating a revival of Aristotelianism in Europe, and ultimately revitalizing European thought through Muslim influence in Spain to fan the embers of the Renaissance.
Development of logic.
Twenty-three hundred years after his death, Aristotle remains one of the most influential people who ever lived. He was the founder of formal logic, pioneered the study of zoology, and left every future scientist and philosopher in his debt through his contributions to the scientific method. Despite these accolades, many of Aristotle's errors held back science considerably. Bertrand Russell notes that "almost every serious intellectual advance has had to begin with an attack on some Aristotelian doctrine". Russell also refers to Aristotle's ethics as "repulsive", and calls his logic "as definitely antiquated as Ptolemaic astronomy". Russell notes that these errors make it difficult to do historical justice to Aristotle, until one remembers how large of an advance he made upon all of his predecessors. Of course, the problem of excessive devotion to Aristotle is more a problem of those later centuries and not of Aristotle himself.
Later Greek philosophers.
The immediate influence of Aristotle's work was felt as the Lyceum grew into the Peripatetic school. Aristotle's notable students included Aristoxenus, Dicaearchus, Demetrius of Phalerum, Eudemos of Rhodes, Harpalus, Hephaestion, Meno, Mnason of Phocis, Nicomachus, and Theophrastus. Aristotle's influence over Alexander the Great is seen in the latter's bringing with him on his expedition a host of zoologists, botanists, and researchers. He had also learned a great deal about Persian customs and traditions from his teacher. Although his respect for Aristotle was diminished as his travels made it clear that much of Aristotle's geography was clearly wrong, when the old philosopher released his works to the public, Alexander complained "Thou hast not done well to publish thy acroamatic doctrines; for in what shall I surpass other men if those doctrines wherein I have been trained are to be all men's common property?"
Influence on Christian theologians.
Aristotle is referred to as "The Philosopher" by Scholastic thinkers such as Thomas Aquinas. See "Summa Theologica", Part I, Question 3, etc. These thinkers blended Aristotelian philosophy with Christianity, bringing the thought of Ancient Greece into the Middle Ages. It required a repudiation of some Aristotelian principles for the sciences and the arts to free themselves for the discovery of modern scientific laws and empirical methods. The medieval English poet Chaucer describes his student as being happy by having
The Italian poet Dante says of Aristotle in the first circles of hell,
Views on women.
Aristotle believed that women are colder than men and thus a lower form of life. His assumption carried forward unexamined to Galen and others for almost two thousand years until the sixteenth century. He also believed that females could not be fully human. His analysis of procreation is frequently criticized on the grounds that it presupposes an active, ensouling masculine element bringing life to an inert, passive, lumpen female element; it is on these grounds that Aristotle is considered by some feminist critics to have been a misogynist.
On the other hand, Aristotle gave equal weight to women's happiness as he did to men's, and commented in his Rhetoric that a society cannot be happy unless women are happy too. In places like Sparta where the lot of women is bad, there can only be half-happiness in society.(see Rhetoric 1.5.6)
Post-Enlightenment thinkers.
The German philosopher Friedrich Nietzsche has been said to have taken nearly all of his political philosophy from Aristotle. However implausible this is, it is certainly the case that Aristotle's rigid separation of action from production, and his justification of the subservience of slaves and others to the virtue – or "arete" – of a few justified the ideal of aristocracy. It is Martin Heidegger, not Nietzsche, who elaborated a new interpretation of Aristotle, intended to warrant his deconstruction of scholastic and philosophical tradition. More recently, Alasdair MacIntyre has attempted to reform what he calls the Aristotelian tradition in a way that is anti-elitist and capable of disputing the claims of both liberals and Nietzscheans.
List of works.
The works of Aristotle that have survived from antiquity through Mediæval manuscript transmission are collected in the Corpus Aristotelicum. These texts, as opposed to Aristotle's lost works, are technical philosophical treatises from within Aristotle's school. Reference to them is made according to the organization of Immanuel Bekker's Royal Prussian Academy edition ("Aristotelis Opera edidit Academia Regia Borussica", Berlin, 1831-1870), which in turn is based on ancient classifications of these works.
Further reading.
The secondary literature on Aristotle is vast. The following references are only a small selection.
---END.OF.DOCUMENT---

An American in Paris.
"An American in Paris" is a symphonic composition by American composer George Gershwin, composed in 1928. Inspired by time Gershwin had spent in Paris, it is in the form of an extended tone poem evoking the sights and energy of the French capital in the 1920s. It is one of Gershwin's best-known compositions.
Gershwin composed the piece on commission from the New York Philharmonic. He also did the orchestration. (He did not orchestrate his musicals.) Gershwin scored "An American in Paris" for the standard instruments of the symphony orchestra plus celesta, saxophone, and automobile horns. Gershwin brought back some Parisian taxi horns for the New York premiere of the composition which took place on December 13, 1928 in Carnegie Hall with Walter Damrosch conducting the New York Philharmonic.
Gershwin collaborated on the original program notes with the critic and composer Deems Taylor, noting that: "My purpose here is to portray the impression of an American visitor in Paris as he strolls about the city and listens to various street noises and absorbs the French atmosphere." When the tone poem moves into the blues, "our American friend... has succumbed to a spasm of homesickness." But, "nostalgia is not a fatal disease." The American visitor "once again is an alert spectator of Parisian life" and "the street noises and French atmosphere are triumphant."
Instrumentation.
"An American in Paris" is scored for 3 flutes (3rd doubling on piccolo), 2 oboes, English horn, 2 clarinets in B flat, bass clarinet in B flat, 2 bassoons, 4 horns in F, 3 trumpets in B flat, 3 trombones, tuba, timpani, snare drum, bass drum, cymbals, low and high tom-toms, xylophone, glockenspiel, celesta, 4 taxi horns, alto saxophone/soprano saxophone, tenor saxophone/soprano saxophone/alto saxophone, baritone saxophone/soprano saxophone/alto saxophone, and strings.
The revised edition by F Campbell-Watson calls for three saxophones, alto, tenor and baritone. In this arrangement the soprano and alto doublings have been rewritten to avoid changing instruments.
Recordings.
"An American in Paris" has been frequently recorded over the years. The very first recording was made for RCA Victor in 1929 with Nathaniel Shilkret conducting the Victor Symphony Orchestra, drawn from members of the Philadelphia Orchestra. Gershwin was on hand to "supervise" the recording; however, Shilkret was reported to be in charge and eventually asked the composer to leave the recording studio. Then, a little later, Shilkret discovered there was no one to play the brief celesta solo during the slow section, so he hastily asked Gershwin if he might play the solo; Gershwin said he could and so he briefly participated in the actual recording. The radio broadcast of the September 8, 1937 Hollywood Bowl George Gershwin Memorial Concert, in which "An American in Paris," also conducted by Shilkret, was second on the program, was recorded and was released in 1998 in a two-CD set. Arthur Fiedler and the Boston Pops Orchestra recorded the work for RCA Victor, including one of the first stereo recordings of the music. In 1945, Arturo Toscanini and the NBC Symphony Orchestra recorded the music in Carnegie Hall, one of the few commercial recordings Toscanini made of music by an American composer. The Seattle Symphony also recorded a version in the 1980's of Gershwin's original score, before he committed to numerous edits resulting in the score as we hear it today.
In 1951, MGM released a musical comedy, "An American in Paris", featuring Gene Kelly and Leslie Caron. Winner of numerous awards, including the 1951 Best Picture Oscar, the film was directed by Vincente Minnelli, featured many tunes of Gershwin, and concluded with an extensive, elaborate dance sequence built around Gershwin's symphonic poem (arranged for the film by Johnny Green).
A part of the symphonic composition is also featured in "As Good as It Gets", released in 1997.
---END.OF.DOCUMENT---

Academy Award for Best Art Direction.
The Academy Awards are the oldest awards ceremony for achievements in motion pictures. The Academy Award for Best Art Direction recognizes achievement in art direction on a film. The films below are listed with their production year, so the Oscar 2000 for best art direction went to a film from 1999. In the lists below, the winner of the award for each year is shown first, followed by the other nominees.
1920s.
This award was originally for Interior Decoration
1930s.
With the awards for 1940 the award was divided into separate awards for black-and-white and color movies.
1940s.
Beginning with 1947 movies the name of the award was changed to Art Direction - Set Decoration.
1950s.
For 1957 films this award became a single award.
With the 1959 films this category was again divided in two
1960s.
For 1967 the two awards in this category were recombined into a single award.
---END.OF.DOCUMENT---

Academy Award.
The Academy Award (frequently known as the Oscars) are accolades presented annually by the Academy of Motion Picture Arts and Sciences (AMPAS) to recognize excellence of professionals in the film industry, including directors, actors, and writers. The formal ceremony at which the awards are presented is one of the most prominent award ceremonies in the world. It is also the oldest award ceremony in the media, and many other award ceremonies such as the Grammy Awards (for music), Golden Globe Awards (all forms of visual media), and Emmy Awards (for television) are often modeled from the Academy. The Academy of Motion Picture Arts and Sciences itself was conceived by Metro-Goldwyn-Mayer studio boss Louis B. Mayer.
The 1st Academy Awards ceremony was held on Thursday, May 16, 1929, at the Hotel Roosevelt in Hollywood to honor outstanding film achievements of 1927 and 1928. It was hosted by actor Douglas Fairbanks and director William C. deMille. The 82nd Academy Awards, honoring the best in film for 2009, was held on Sunday, March 7, 2010, at the Kodak Theatre in Hollywood, with actors Steve Martin and Alec Baldwin hosting the ceremony.
History.
The first awards were presented on May 16, 1929, at a private brunch at the Hollywood Roosevelt Hotel with an audience of about 270 people..
The cost of guest tickets for that night's ceremony was $5. Fifteen statuettes were awarded, honoring artists, directors and other personalities of the filmmaking industry of the time for their works during the 1927-1928 period.
Winners had been announced three months earlier of their triumphs; however that was changed in the second ceremony of the Academy Awards in 1930. Since then and during the first decade, the results were given to newspapers for publication at 11pm on the night of the awards. This method was used until the "Los Angeles Times" announced the winners before the ceremony began; as a result, the Academy has used a sealed envelope to reveal the name of the winners since 1941. Since 2002, the awards have been broadcast from the Kodak Theatre.
The first Best Actor awarded was Emil Jannings, for his performance in The Last Command and The Way of All Flesh. He had to return to Europe before the ceremony, so the Academy agreed to give him the prize earlier; this made him the first Academy Award winner in history. The honored professionals were awarded for all the work done in a certain category for the qualifying period; for example, Emil Jannings, received the award for two movies he starred during that period. Since the fourth ceremony, the system changed, and the professionals were honored for a specific performance in a single film.
In the 29th ceremony, held on March 27th, 1957 the Best Foreign Language Film category was introduced; until then, foreign language films were honored with the Special Achievement Award.
Design.
Although there are seven other types of awards presented by the Academy (the Irving G. Thalberg Memorial Award, the Jean Hersholt Humanitarian Award, the Gordon E. Sawyer Award, the Scientific and Engineering Award, the Technical Achievement Award, the John A. Bonner Medal of Commendation, and the Student Academy Award), the best known one is the "Academy Award of Merit" more popularly known as the Oscar statuette. Made of gold-plated britannium on a black metal base, it is 13.5 in (34 cm) tall, weighs 8.5 lb (3.85 kg) and depicts a knight rendered in Art Deco style holding a crusader's sword standing on a reel of film with five spokes. The five spokes each represent the original branches of the Academy: Actors, Writers, Directors, Producers, and Technicians.
MGM's art director Cedric Gibbons, one of the original Academy members, supervised the design of the award trophy by printing the design on a scroll.
In need of a model for his statuette Gibbons was introduced by his then wife Dolores del Río to Mexican film director and actor Emilio "El Indio" Fernández. Reluctant at first, Fernández was finally convinced to pose nude to create what today is known as the "Oscar". Then, sculptor George Stanley (who also did the Muse Fountain at the Hollywood Bowl) sculpted Gibbons's design in clay and Sachin Smith cast the statuette in 92.5 percent tin and 7.5 percent copper and then gold-plated it. The only addition to the Oscar since it was created is a minor streamlining of the base. The original Oscar mold was cast in 1928 at the C.W. Shumway & Sons Foundry in Batavia, Illinois, which also contributed to casting the molds for the Vince Lombardi Trophy and Emmy Awards statuettes. Since 1983, approximately 50 Oscars are made each year in Chicago, Illinois by manufacturer R.S. Owens & Company.
In support of the American effort in World War II, the statuettes were made of plaster and were traded in for gold ones after the war had ended.
Naming.
The root of the name "Oscar" is contested. One biography of Bette Davis claims that she named the Oscar after her first husband, band leader Harmon Oscar Nelson; one of the earliest mentions in print of the term "Oscar" dates back to a "Time" magazine article about the 1934 6th Academy Awards and to Bette Davis's receipt of the award in 1936. Walt Disney is also quoted as thanking the Academy for his Oscar as early as 1932. Another claimed origin is that the Academy's Executive Secretary, Margaret Herrick, first saw the award in 1931 and made reference to the statuette's reminding her of her "Uncle Oscar" (a nickname for her cousin Oscar Pierce). Columnist was present during Herrick's naming and seized the name in his byline, "Employees have affectionately dubbed their famous statuette 'Oscar'". The trophy was officially dubbed the "Oscar" in 1939 by the Academy of Motion Pictures Arts and Sciences. Another legend reports that the Norwegian-American Eleanor Lilleberg, executive secretary to Louis B. Mayer, saw the first statuette and exclaimed, "It looks like King Oscar II!". At the end of the day she asked, "What should we do with Oscar, put him in the vault?" and the name stuck.
As of the 81st Academy Awards ceremony held in 2009, a total of 2,744 Oscars have been given for 1,798 awards. A total of 297 actors have won Oscars in competitive acting categories or been awarded Honorary or Juvenile Awards.
Ownership of Oscar statuettes.
Since 1950, the statuettes have been legally encumbered by the requirement that neither winners nor their heirs may sell the statuettes without first offering to sell them back to the Academy for US$1. If a winner refuses to agree to this stipulation, then the Academy keeps the statuette. Academy Awards not protected by this agreement have been sold in public auctions and private deals for six-figure sums.
This rule is highly controversial, since while the Oscar is under the ownership of the recipient, it is essentially not on the open market. The case of Michael Todd's grandson trying to sell Todd's Oscar statuette illustrates that there are many who do not agree with this idea. When Todd's grandson attempted to sell Todd's Oscar statuette to a movie prop collector, the Academy won the legal battle by getting a permanent injunction. Although some Oscar sales transactions have been successful, the buyers have subsequently returned the statuettes to the Academy, which keeps them in its treasury.
Nomination.
Since 2004, Academy Award nomination results have been announced to the public in late January. Prior to 2004, nomination results were announced publicly in early February.
Voters.
The Academy of Motion Picture Arts and Sciences (AMPAS), a professional honorary organization, maintains a voting membership of 5,835 as of 2007.
Actors constitute the largest voting bloc, numbering 1,311 members (22 percent) of the Academy's composition. Votes have been certified by the auditing firm PricewaterhouseCoopers (and its predecessor Price Waterhouse) for the past 73 annual awards ceremonies.
All AMPAS members must be invited to join by the Board of Governors, on behalf of Academy Branch Executive Committees. Membership eligibility may be achieved by a competitive nomination or a member may submit a name based on other significant contribution to the field of motion pictures.
New membership proposals are considered annually. The Academy does not publicly disclose its membership, although as recently as 2007 press releases have announced the names of those who have been invited to join. The 2007 release also stated that it has just under 6,000 voting members. While the membership had been growing, stricter policies have kept its size steady since then.
Rules.
Today, according to Rules 2 and 3 of the official Academy Awards Rules, a film must open in the previous calendar year, from midnight at the start of January 1 to midnight at the end of December 31, in Los Angeles County, California, to qualify. For example, the 2010 Best Picture winner, "The Hurt Locker", was actually first released in 2008, but did not qualify for the 2009 awards as it did not play its Oscar-qualifying run in Los Angeles until mid-2009, thus qualifying for the 2010 awards.
Rule 2 states that a film must be feature-length, defined as a minimum of 40 minutes, except for short subject awards, and it must exist either on a 35 mm or 70 mm film print or in 24 frame/s or 48 frame/s progressive scan digital cinema format with native resolution not less than 1280x720.
Producers must submit an Official Screen Credits online form before the deadline; in case it is not submitted by the defined deadline, the film will be ineligible for Academy Awards in any year. The form includes the production credits for all related categories. Then, each form is checked and put in a Reminder List of Eligible Releases.
In late December ballots and copies of the Reminder List of Eligible Releases are mailed to around 6000 active members. For most categories, members from each of the branches vote to determine the nominees only in their respective categories (i.e. only directors vote for directors, writers for writers, actors for actors, etc.); there are some exceptions though in the case of certain categories, like Foreign Film, Documentary and Animated Feature Film in which movies are selected by special screening committees made up of member from all branches. In the special case of Best Picture, all voting members are eligible to select the nominees for that category. Foreign films must include English subtitles, and each country can only submit one film per year.
The members of the various branches nominate those in their respective fields while all members may submit nominees for Best Picture. The winners are then determined by a second round of voting in which all members are then allowed to vote in most categories, including Best Picture.
Telecast.
The major awards are presented at a live televised ceremony, most commonly in February or March following the relevant calendar year, and six weeks after the announcement of the nominees. It is the culmination of the film awards season, which usually begins during November or December of the previous year. This is an elaborate extravaganza, with the invited guests walking up the red carpet in the creations of the most prominent fashion designers of the day. Black tie dress is the most common outfit for men, although fashion may dictate not wearing a bow-tie, and musical performers sometimes do not adhere to this. (The artists who recorded the nominees for Best Original Song quite often perform those songs live at the awards ceremony, and the fact that they are performing is often used to promote the television broadcast.)
The Academy Awards is televised live across the United States (excluding Alaska and Hawaii), Canada, the United Kingdom, and gathers millions of viewers elsewhere throughout the world. The 2007 ceremony was watched by more than 40 million Americans. Other awards ceremonies (such as the Emmys, Golden Globes, and Grammys) are broadcast live in the East Coast but are on tape delay in the West Coast and might not air on the same day outside North America (if the awards are even televised). The Academy has for several years claimed that the award show has up to a billion viewers internationally, but this has so far not been confirmed by any independent sources. The usual extension of this claim is that only the Super Bowl, Olympics Opening Ceremonies, and FIFA World Cup Final draw higher viewership.
The Awards show was first televised on NBC in 1953. NBC continued to broadcast the event until 1960 when the ABC Network took over, televising the festivities through 1970, after which NBC resumed the broadcasts. ABC once again took over broadcast duties in 1976; it is under contract to do so through the year 2014.
After more than sixty years of being held in late March or early April, the ceremonies were moved up to late February or early March starting in 2004 to help disrupt and shorten the intense lobbying and ad campaigns associated with Oscar season in the film industry. Another reason was because of the growing TV ratings success of the NCAA Men's Division I Basketball Championship, which would cut into the Academy Awards audience. The earlier date is also to the advantage of ABC, as it now usually occurs during the highly profitable and important February sweeps period. (Some years, the ceremony is moved into early March in deference to the Winter Olympics.) Advertising is somewhat restricted, however, as traditionally no movie studios or competitors of official Academy Award sponsors may advertize during the telecast. The Awards show holds the distinction of having won the most Emmys in history, with 38 wins and 167 nominations.
After many years of being held on Mondays at 9:00 p.m. Eastern/6:00 p.m Pacific, in 1999 the ceremonies were moved to Sundays at 8:30 p.m. Eastern/5:30 p.m. Pacific. The reasons given for the move were that more viewers would tune in on Sundays, that Los Angeles rush-hour traffic jams could be avoided, and that an earlier start time would allow viewers on the East Coast to go to bed earlier. For many years the film industry had opposed a Sunday broadcast because it would cut into the weekend box office.
On March 30, 1981, the awards ceremony was postponed for one day after the shooting of President Ronald Reagan and others in Washington DC.
In 1993 an "In Memoriam" section was introduced, honoring those who had made a significant contribution to cinema who had died in the preceding 12 months. This section has led to some criticism for omission of notable persons such as Leonard Schrader and Malcolm Arnold in 2007 and Gene Barry, Farrah Fawcett, Henry Gibson, and Bea Arthur in 2010.
Since 2002, celebrities have been seen arriving at the Academy Awards in hybrid vehicles; during the telecast of the 79th Academy Awards in 2007, Leonardo DiCaprio and former vice president Al Gore announced that ecologically intelligent practices had been integrated into the planning and execution of the Oscar presentation and several related events.
In 2010, the organizers of the Academy Awards announced that winners' acceptance speeches must not run past 45 seconds. This, according to organizer Bill Mechanic, was to ensure the elimination of what he termed "the single most hated thing on the show" - overly long and embarrassing displays of emotion.
Ratings.
Historically, the "Oscarcast" has pulled in a bigger haul when box-office hits are favored to win the Best Picture trophy. More than 57.25 million viewers tuned to the telecast in 1998, the year of "Titanic", which generated close to US$600 million at the North American box office pre-Oscars. The 76th Academy Awards ceremony in which ' (pre-telecast box office earnings of US$368 million) received 11 Awards including Best Picture drew 43.56 million viewers. The most watched ceremony based on Nielsen ratings to date, however, was the 42nd Academy Awards (Best Picture "Midnight Cowboy") which drew a 43.4% household rating on April 7, 1970.
By contrast, ceremonies honoring films that have not performed well at the box office tend to show weaker ratings. The 78th Academy Awards which awarded low-budgeted, independent film "Crash" (with a pre-Oscar gross of US$53.4 million) generated an audience of 38.64 million with a household rating of 22.91%. In 2008, the 80th Academy Awards telecast was watched by 31.76 million viewers on average with an 18.66% household rating, the lowest rated and least watched ceremony to date, in spite of celebrating 80 years of the Academy Awards. The Best Picture winner of that particular ceremony was another low-budget, independently financed film ("No Country for Old Men").
Venues.
In 1929, the 1st Academy Awards were presented at a banquet dinner at the Hollywood Roosevelt Hotel. From 1930–1943, the awards were presented first at the Ambassador Hotel in Hollywood, and later the Biltmore Hotel in downtown Los Angeles.
Grauman's Chinese Theater in Hollywood then hosted the awards from 1944 to 1946, followed by the Shrine Auditorium in Los Angeles from 1947 to 1948. The 21st Academy Awards in 1949 were held at the Academy Award Theater at what was the Academy's headquarters on Melrose Avenue in Hollywood.
From 1950 to 1960, the awards were presented at Hollywood's Pantages Theatre. With the advent of television, the 1953–1957 awards took place simultaneously in Hollywood and New York first at the NBC International Theatre (1953) and then at the NBC Century Theatre (1954–1957), after which the ceremony took place solely in Los Angeles. The Oscars moved to the Santa Monica Civic Auditorium in Santa Monica, California in 1961. By 1969, the Academy decided to move the ceremonies back to Los Angeles, this time to the Dorothy Chandler Pavilion at the Los Angeles County Music Center.
In 2002, Hollywood's Kodak Theatre became the permanent home of the awards.
Current awards.
In the first year of the awards, the Best Director award was split into two separate categories (Drama and Comedy). At times, the Best Original Score award has also been split into separate categories (Drama and Comedy/Musical). From the 1930s through the 1960s, the Art Direction, Cinematography, and Costume Design awards were likewise split into two separate categories (black-and-white films and color films).
Special Academy Awards.
These awards are voted on by special committees, rather than by the Academy membership as a whole, but the individual selected to receive the special award may decline the offer. They are not always presented on a consistent annual basis.
Criticism.
The Oscars are generally voted on by members of the entertainment industry; thus, important films that have had the most people working on them generally become nominated. Director William Friedkin, an Oscar winner and producer of the Academy Awards, spoke critically of the awards at a conference in New York in 2009. He characterized the Academy Awards as "the greatest promotion scheme that any industry ever devised for itself".
In addition, several winners critical of the Academy Awards have boycotted the ceremonies and refused to accept their Oscars. The first to do so was Dudley Nichols (Best Writing in 1935 for "The Informer"). Nichols boycotted the Eighth Academy Awards ceremony because of conflicts between the Academy and the Writer's Guild. George C. Scott became the second person to refuse his award (Best Actor in 1970 for "Patton"), at the 43rd Academy Awards ceremony. Scott explained, "The whole thing is a goddamn meat parade. I don't want any part of it." The third winner, Marlon Brando, refused his award (Best Actor in 1972 for "The Godfather"), citing the film industry's discrimination and mistreatment of Native Americans. At the 45th Academy Awards ceremony, Brando sent Sacheen Littlefeather to read a 15-page speech detailing Brando's criticisms.
It has been observed that several of the Academy Award winners – particularly Best Picture – have not stood the test of time or had defeated worthier efforts. On "They Shoot Pictures, Don't They's" comprehensive database of the 1,000 most acclaimed films of all time, only eight of the first hundred ranked films have won the Best Picture award. Tim Dirks, editor of AMC's filmsite.org, has written of the Academy Awards,
In his review of "The Lives of Others", Nick Davis argued,
The Academy Awards have also come under criticism for having a bias towards certain types of performances and film genres. The Best Picture prize has never been given to a film noir, science fiction or an animated film; and rarely are horror, fantasy, comedy and westerns recognized by AMPAS.
Acting prizes in certain years have been criticized for not recognizing superior performances so much as being awarded for sentimental reasons, personal popularity, atonement for past mistakes, or presented as a "career honor" to recognize a distinguished nominee's entire body of work.
---END.OF.DOCUMENT---

Actrius.
"Actrius" (Catalan: "Actresses") is a 1996 film directed by Ventura Pons. In the film, there are no male actors and the four leading actresses dubbed themselves in the Castilian version.
Synopsis.
In order to prepare the role of an important old actress, a theatre student interviews three actresses who were her pupils: an international diva (Glòria Marc, played by Núria Espert), a television star (Assumpta Roca, played by Rosa Maria Sardà) and a dubbing director (Maria Caminal, played by Anna Lizaran).
---END.OF.DOCUMENT---

Animalia (book).
"Animalia" (ISBN 0810918684) is an illustrated children's book by Graeme Base. It was published in 1986.
"Animalia" is an alliterative alphabet book and contains twenty-six illustrations, one for each letter of the alphabet. Each illustration features an animal from the animal kingdom (A is for alligator, B is for butterfly, etc.) along with a short poem utilizing the letter of the page for many of the words. The illustrations contain dozens of small objects beginning with that letter that the curious reader can try to identify. As an additional challenge, the author has hidden a picture of himself as a child in every picture. In 1987, "Animalia" won the title of Honour Book in the Children's Book Council of Australia Picture Book of the Year Awards. In 1996, a tenth anniversary edition was released.
Base also published a colouring book version for children to do their own colouring.
A television series was also created, based on the book, which airs in the United States, Australia, Canada, the UK and Norway. It also airs on Minimax for the Czech and Slovak Republics.
---END.OF.DOCUMENT---

International Atomic Time.
International Atomic Time (TAI, from the French name Temps Atomique International) is a high-precision atomic coordinate time standard based on the notional passage of proper time on Earth's geoid. It is the principal realisation of Terrestrial Time, and the basis for Coordinated Universal Time (UTC) which is used for civil timekeeping all over the Earth's surface., TAI was exactly 34 seconds ahead of UTC: an initial difference of 10 seconds at the start of 1972, plus 24 leap seconds in UTC since 1972; the last leap second was added on 31 December, 2008.
Time coordinates on the TAI scales are conventionally specified using traditional means of specifying days, carried over from non-uniform time standards based on the rotation of the Earth. Specifically, both Julian Dates and the Gregorian calendar are used. TAI in this form was synchronised with Universal Time at the beginning of 1958, and the two have drifted apart ever since, due to the changing motion of the Earth.
Operation.
TAI as a time scale is a weighted average of the time kept by over 200 atomic clocks in about 70 national laboratories worldwide. The clocks are compared using satellites. Due to the averaging it is far more stable than any clock would be alone. The majority of the clocks are caesium clocks; the definition of the SI second is written in terms of caesium.
The participating institutions each broadcast, in real time (in the present), a frequency signal with time codes, which is their estimate of TAI. Time codes are usually published in the form of UTC. These time scales are denoted in the form "TAI(NPL)" ("UTC(NPL)" for the UTC form), where "NPL" in this case identifies the National Physical Laboratory, UK.
The clocks at different institutions are regularly compared against each other. The International Bureau of Weights and Measures (BIPM) combines these measurements to retrospectively calculate the weighted average that forms the most stable time scale possible. This combined time scale is published monthly in [ftp://ftp2.bipm.fr/pub/tai/publication/cirt/ Circular T], and is the canonical TAI. This time scale is expressed in the form of tables of differences UTC-UTC("x") and TAI-TA("x"), for each participating institution "x".
Errors in publication may be corrected by issuing a revision of the faulty Circular T or by errata in a subsequent Circular T. Aside from this, once published in Circular T the TAI scale is not revised. In hindsight it is possible to discover errors in TAI, and to make better estimates of the true proper time scale. Doing so does not create another version of TAI; it is instead considered to be creating a better realisation of Terrestrial Time (TT).
History.
Atomic timekeeping services started experimentally in 1955, using the first caesium atomic clock at the National Physical Laboratory, UK (NPL). Early atomic time scales consisted of quartz clocks with frequencies calibrated by a single atomic clock; the atomic clocks were not operated continuously. The "Greenwich Atomic" (GA) scale began in 1955 at the Royal Greenwich Observatory. The United States Naval Observatory began the A.1 scale 13 September 1956, using an Atomichron© commercial atomic clock, followed by the NBS-A scale at the National Bureau of Standards, Boulder, Colorado. The International Time Bureau (BIH) began a time scale, Tm or AM, in July 1955, using both local caesium clocks and comparisons to distant clocks using the phase of VLF radio signals. Both the BIH scale and A.1 was defined by an epoch at the beginning of 1958: it was set to read Julian Date 2436204.5 (1 January 1958 00:00:00) at the corresponding UT2 instant. The procedures used by the BIH evolved, and the name for the time scale changed: "A3" in 1963 and "TA(BIH)" in 1969. This synchronisation was inevitably imperfect, depending as it did on the astronomical realisation of UT2. At the time, UT2 as published by various observatories differed by several centiseconds.
The SI second was defined in terms of the caesium atom in 1967, and in 1971 it was renamed International Atomic Time (TAI).
Also in 1961, UTC began. UTC is a discontinuous time scale composed from segments that are linear transformations of atomic time, the discontinuities being arranged so that UTC approximated UT2 until the end of 1971, and UT1 thereafter. This was a compromise arrangement for a broadcast time scale: a linear transformation of the BIH's atomic time meant that the time scale was stable and internationally synchronised, while approximating UT1 means that tasks such as navigation which require a source of Universal Time continue to be well served by public time broadcasts.
In the 1970s, it became clear that the clocks participating in TAI were ticking at different rates due to gravitational time dilation, and the combined TAI scale therefore corresponded to an average of the altitudes of the various clocks. Starting from Julian Date 2443144.5 (1 January 1977T00:00:00), corrections were applied to the output of all participating clocks, so that TAI would correspond to proper time at mean sea level (the geoid). Because the clocks had been on average well above sea level, this meant that TAI slowed down, by about 10−12. The former uncorrected time scale continues to be published, under the name "EAL" ("Echelle Atomique Libre", meaning "Free Atomic Scale").
The instant that the gravitational correction started to be applied serves as the epoch for Barycentric Coordinate Time (TCB), Geocentric Coordinate Time (TCG), and Terrestrial Time (TT). All three of these time scales were defined to read JD 2443144.5003725 (1 January 1977 00:00:32.184) exactly at that instant. (The offset is to provide continuity with the older Ephemeris Time.) TAI was henceforth a realisation of TT, with the equation TT(TAI) = TAI + 32.184 s.
---END.OF.DOCUMENT---

Altruism.
Altruism (pronounced:) is selfless concern for the welfare of others. It is a traditional virtue in many cultures, and a core aspect of various religious traditions such as Judaism, Christianity, Islam, Hinduism, Jainism, Buddhism, Confucianism, Sikhism, and many others. Altruism is the opposite of selfishness.
Altruism can be distinguished from feelings of loyalty and duty. Altruism focuses on a motivation to help others or a want to do good without reward, while duty focuses on a moral obligation towards a specific individual (for example, God, a king), a specific organization (for example, a government), or an abstract concept (for example, patriotism etc). Some individuals may feel both altruism and duty, while others may not. Pure altruism is giving without regard to reward or the benefits of recognition and need.
The term "altruism" may also refer to an ethical doctrine that claims that individuals are morally obliged to benefit others.
The notion of altruism.
The concept has a long history in philosophical and ethical thought. The term was originally coined by the founding sociologist and philosopher of science, Auguste Comte, and has become a major topic for psychologists (especially evolutionary psychology researchers), evolutionary biologists, and ethologists. While ideas about altruism from one field can have an impact on the other fields, the different methods and focuses of these fields lead to different perspectives on altruism.
Behavioural theories.
In the science of ethology (the study of animal behaviour), and more generally in the study of social evolution, altruism refers to behaviour by an individual that increases the fitness of another individual while decreasing the fitness of the actor. Researchers on alleged altruist behaviours among animals have been ideologically opposed to the sociological social Darwinist concept of the "survival of the fittest", under the name of "survival of the nicest"—not to be confused with the biological concept of Darwin's theory of evolution. Insistence on such cooperative behaviors between animals was first exposed by the Russian zoologist and anarchist Peter Kropotkin in his 1902 book, '.
Theories of apparently-altruistic behavior were accelerated by the need to produce theories compatible with evolutionary origins. Two related strands of research on altruism have emerged out of traditional evolutionary analyses, and from game theory respectively.
The study of altruism was the initial impetus behind George R. Price's development of the Price equation which is a mathematical equation used to study genetic evolution. An interesting example of altruism is found in the cellular slime moulds, such as "Dictyostelium mucoroides". These protists live as individual amoebae until starved, at which point they aggregate and form a multicellular fruiting body in which some cells sacrifice themselves to promote the survival of other cells in the fruiting body. Social behavior and altruism share many similarities to the interactions between the many parts (cells, genes) of an organism, but are distinguished by the ability of each individual to reproduce indefinitely without an absolute requirement for its neighbors.
Neurobiology.
Jorge Moll and Jordan Grafman, neuroscientists at the National Institutes of Health and LABS-D'Or Hospital Network (J.M.) provided the first evidence for the neural bases of altruistic giving in normal healthy volunteers, using functional magnetic resonance imaging. In their research, published in the Proceedings of the National Academy of Sciences USA in October, 2006, they showed that both pure monetary rewards and charitable donations activated the mesolimbic reward pathway, a primitive part of the brain that usually lights up in response to food and sex. However, when volunteers generously placed the interests of others before their own by making charitable donations, another brain circuit was selectively activated: the subgenual cortex/septal region. These structures are intimately related to social attachment and bonding in other species. Altruism, the experiment suggested, was not a superior moral faculty that suppresses basic selfish urges but rather was basic to the brain, hard-wired and pleasurable.
Another experiment funded by the National Institutes of Health and conducted in 2007 at the Duke University in Durham, North Carolina suggests a different view, "that altruistic behavior may originate from how people view the world rather than how they act in it". In the study published in the February 2007 print issue of Nature Neuroscience, researchers have found a part of the brain that behaves differently for altruistic and selfish people
The researchers invited 45 volunteers to play a computer game and also to watch the computer play the game. In some instances successful completion of the game resulted in them winning money for themselves, and in other instances it resulted in money being donated to a charity each person had chosen at the beginning of the experiment. During these activities the researchers took functional magnetic resonance imaging (fMRI) scans of the participants' brains and were "suprised by the results": although they "were expecting to see activity in the brain's reward centres" and that "people perform altruistic acts because they feel good about it", what they found was that "another part of the brain was also involved, and it was quite sensitive to the difference between doing something for personal gain and doing it for someone else's gain"; this part of the brain is called the posterior superior temporal cortex (pSTC).
In the next stage the scientists asked the participants questions about type and frequency of their altruistic or helping behaviours. They then analysed the responses to generate an estimate of a person's tendency to act altruistically and compared each person's level against their fMRI brain scan. The results showed that pSTC activity rose in proportion to a person's estimated level of altruism. According to the researchers, the results suggest that altruistic behavior may originate from how people view the world rather than how they act in it. "We believe that the ability to perceive other people's actions as meaningful is critical for altruism", said lead study investigator Dharol Tankersley.
Genetics.
A study by Samuel Bowles at the Santa Fe Institute in New Mexico, US, is seen by some as breathing new life into the model of group selection for Altruism, known as "Survival of the nicest". Bowles conducted a genetic analysis of contemporary foraging groups, including Australian aboriginals, native Siberian Inuit populations and indigenous tribal groups in Africa. It was found that hunter-gatherer bands of up to 30 individuals were considerably more closely related than was previously thought. Under these conditions, thought to be similar to those of the middle and upper Paleolithic, altruism towards other group-members would improve the overall fitness of the group. This is however simply a form of inclusive fitness - one vehicle helping other vehicles likely to contain the same genes.
If an individual defends the group, risking death or simply reducing his reproductive fitness, genes that this individual shares with those he successfully defends (group members) would increase in frequency (thanks to his defence supporting their reproduction). If such helpful acts are rewarded with food sharing, sexual access, monogamy or other benefits, there is not average “cost” of altruistic behaviour to be repaid. Bowles assembled genetic, climactic, archaeological, ethnographic and experimental data to examine the cost-benefit relationship of human cooperation in ancient populations. In his model, altruism is selected for when members of a group bearing genes for altruistic behaviour pay a cost - limiting their reproductive opportunities - but receive a benefit from sharing food and information. If their acts increase the average fitness of group members, altruism increase so long as group members tend also to maintain or increase their inter-relatedness (in-goup mating). Bands of such altruistic humans could then act together not only defensively, but aggressively, to gain resources from other groups.
Altruist theories in evolutionary biology were contested by Amotz Zahavi, the inventor of the signal theory and its correlative, the handicap principle, based mainly on his observations of the Arabian Babbler, a bird commonly known for its surprising (alleged) altruistic behaviours.
Religious viewpoints.
Most, if not all, of the world's religions promote altruism as a very important moral value. Judaism, Hinduism, Islam, Christianity, Buddhism, and Sikhism, etc, place particular emphasis on altruistic morality.
Buddhism.
Altruism figures prominently in Buddhism. Love and compassion are components of all forms of Buddhism, and both are focused on all beings equally: the wish that all beings be happy (love) and the wish that all beings be free from suffering (compassion). "Many illnesses can be cured by the one medicine of love and compassion. These qualities are the ultimate source of human happiness, and the need for them lies at the very core of our being" (Dalai Lama).
Since "all beings" includes the individual, love and compassion in Buddhism are outside the opposition between self and other. It is even said that the very distinction between self and other is part of the root cause of our suffering. In practical terms, however, because of the spontaneous self-centeredness of most of us, Buddhism encourages us to focus love and compassion on others, and thus can be characterized as "altruistic." Many would agree with the Dalai Lama that Buddhism as a religion is kindness toward others.
Still, the very notion of altruism is modified in such a world-view, since the belief is that such a practice promotes our own happiness: "The more we care for the happiness of others, the greater our own sense of well-being becomes" (Dalai Lama).
In the context of larger ethical discussions on moral action and judgment, Buddhism is characterized by the belief that negative (unhappy) consequences of our actions derive not from punishment or correction based on moral judgment, but on the law of karma, which functions like a natural law of cause and effect. One simple illustration of such cause and effect would be the case of experiencing the effects of what I myself cause: if I cause suffering, I will as a natural consequence experience suffering; if I cause happiness, I will as a natural consequence experience happiness.
In Buddhism, "karma" (Pāli "kamma") is strictly distinguished from "vipāka", meaning "fruit" or "result". Karma is categorized within the group or groups of cause (Pāli "hetu") in the chain of cause and effect, where it comprises the elements of "volitional activities" (Pali "sankhara") and "action" (Pali "bhava"). Any action is understood to create "seeds" in the mind that will sprout into the appropriate result (Pāli "vipaka") when they meet with the right conditions. Most types of karmas, with good or bad results, will keep one within the wheel of samsāra; others will liberate one to nirvāna.
Buddhism relates karma directly to motives behind an action. Motivation usually makes the difference between "good" and "bad", but included in the motivation is also the aspect of ignorance; so a well-intended action from an ignorant mind can easily be "bad" in the sense that it creates unpleasant results for the "actor".
Christianity.
Altruism was central to the teachings of Jesus found in the Gospel especially in the Sermon on the Mount and the Sermon on the Plain. From biblical to medieval Christian traditions, tensions between self-affirmation and other-regard were sometimes discussed under the heading of "disinterested love," as in the Pauline phrase "love seeks not its own interests." In his book "Indoctrination and Self-deception", Roderick Hindery tries to shed light on these tensions by contrasting them with impostors of authentic self-affirmation and altruism, by analysis of other-regard within creative individuation of the self, and by contrasting love for the few with love for the many. If love, which confirms others in their freedom, shuns propagandas and masks, assurance of its presence is ultimately confirmed not by mere declarations from others, but by each person's experience and practice from within. As in practical arts, the presence and meaning of love become validated and grasped not by words and reflections alone, but in the doing.
Though it might seem obvious that altruism is central to the teachings of Jesus, one important and influential strand of Christianity would qualify this. St Thomas Aquinas in the "Summa Theologica", I:II Quaestio 26, Article 4 states that we should love ourselves more than our neighbour. His interpretation of the Pauline phrase is that we should seek the common good more than the private good but this is because the common good is a more desirable good for the individual. 'You should love your neighbour as yourself' from Leviticus 19 and Matthew 22 is interpreted by St Thomas as meaning that love for ourselves is the exemplar of love for others. He does think though, that we should love God more than ourselves and our neighbour, taken as an entirety, more than our bodily life, since the ultimate purpose of love of our neighbour is to share in eternal beatitude, a more desirable thing than bodily well being. Comte was probably opposing this Thomistic doctrine, now part of mainstream Catholicism, in coining the word Altruism, as stated above.
Thomas Jay Oord has argued in several books that altruism is but one possible form of love. And altruistic action is not always loving action. Oord defines altruism as acting for the good of the other, and he agrees with feminists who note that sometimes love requires acting for one's own good when the demands of the other undermine overall well-being.
Islam and Sufism.
In Sufism, the concept of i'thar (altruism) is the notion of 'preferring others to oneself'. For Sufis, this means devotion to others through complete forgetfulness of one's own concerns. The importance lies in sacrifice for the sake of the greater good; Islam considers those practicing i'thar as abiding by the highest degree of nobility.
This is similar to the notion of chivalry, but unlike the European concept there is a focus on attention to everything in existence. A constant concern for Allah results in a careful attitude towards people, animals, and other things in this world.
This concept was emphasized by Sufi mystics like Rabia al-Adawiyya who paid attention to the difference in dedication to Allah and dedication to people.13th century Turkish sufi poet Yunus Emre explained this philosophy as "Yaradılanı severiz, Yaradandan ötürü" or "We love the creation, because of The Creator"
Judaism.
Judaism defines altruism as the desired goal of creation. The famous Rabbi Abraham Isaac Kook stated that love is the most important attribute in humanity. This is defined as bestowal, or giving, which is the intention of altruism. This can be altruism towards humanity that leads to altruism towards the creator or God. Kabbalah defines God as the force of giving in existence. Rabbi Moshe Chaim Luzzatto in particular focused on the ‘purpose of creation’ and how the will of God was to bring creation into perfection and adhesion with this upper force.
Modern Kabbalah developed by Rabbi Yehuda Ashlag, in his writings about the future generation, focuses on how society could achieve an altruistic social framework. Ashlag proposed that such a framework is the purpose of creation, and everything that happens is to raise humanity to the level of altruism, love for one another. Ashlag focused on society and its relation to divinity.
Sikhism.
Altruism is essential to the Sikh religion. In the late 1600s, Guru Gobind Singh Ji (the tenth guru in Sikhism), was in war with the Moghul rulers to protect the people of different faiths, when a fellow Sikh, Bhai Kanhaiya, attended the troops of the enemy. He gave water to both friends and foes who were wounded on the battlefield. Some of the enemy began to fight again and some Sikh warriors were annoyed by Bhai Kanhaiya as he was helping their enemy. Sikh soldiers brought Bhai Kanhaiya before Guru Gobind Singh Ji, and complained of his action that they considered counterproductive to their struggle on the battlefield.
"What were you doing, and why?" asked the Guru. "I was giving water to the wounded because I saw your face in all of them," replied Bhai Kanhaiya.
The Guru responded, "Then you should also give them ointment to heal their wounds. You were practicing what you were coached in the house of the Guru."
It was under the tutelage of the Guru that Bhai Kanhaiya subsequently founded a volunteer corps for altruism. This volunteer corps still to date is engaged in doing good to others and trains new volunteering recruits for doing the same.
Vedanta.
Vedanta differs from the view that karma is a law of cause and effect but instead additionally hold that karma is mediated by the will of a personal supreme God. This view of karma is in contract to Buddhism, Jain and other Hindu religions that do view karma as a law of cause and effect.
Swami Sivananda, an Advaita scholar, reiterates the same views in his commentary synthesising Vedanta views on the Brahma Sutras, a Vedantic text. In his commentary on Chapter 3 of the Brahma Sutras, Sivananda notes that karma is insentient and short-lived, and ceases to exist as soon as a deed is executed. Hence, karma cannot bestow the fruits of actions at a future date according to one's merit. Furthermore, one cannot argue that karma generates apurva or punya, which gives fruit. Since apurva is non-sentient, it cannot act unless moved by an intelligent being such as God. It cannot independently bestow reward or punishment.
---END.OF.DOCUMENT---

Ayn Rand.
Ayn Rand (; born Alisa Zinov'yevna Rosenbaum; – March 6, 1982), was a Russian-American novelist, philosopher, playwright, and screenwriter. She is known for her two best-selling novels and for developing a philosophical system she called Objectivism.
Born and educated in Russia, Rand immigrated to the United States in 1926. She worked as a screenwriter in Hollywood and had a play produced on Broadway in 1935–1936. She first achieved fame in 1943 with her novel "The Fountainhead", which in 1957 was followed by her best-known work, the philosophical novel "Atlas Shrugged".
Rand's political views, reflected in both her fiction and her theoretical work, emphasize individual rights (including property rights) and laissez-faire capitalism, enforced by a constitutionally-limited government. She was a fierce opponent of all forms of collectivism and statism, including fascism, communism, socialism, and the welfare state, and promoted ethical egoism while rejecting the ethic of altruism. She considered reason to be the only means of acquiring knowledge and the most important aspect of her philosophy, stating, "I am not "primarily" an advocate of capitalism, but of egoism; and I am not "primarily" an advocate of egoism, but of reason. If one recognizes the supremacy of reason and applies it consistently, all the rest follows."
Early life.
Rand was born Alisa Zinov'yevna Rosenbaum () in 1905, into a middle-class family living in Saint Petersburg. She was the eldest of the three daughters (Alisa, Natasha, and Nora) of Zinovy Zakharovich Rosenbaum and Anna Borisovna Rosenbaum, largely non-observant Jews. Her father was educated as a chemist and became a successful pharmacist, eventually owning his own pharmacy and the building in which it was located.
Rand was twelve at the time of the Russian revolution of 1917. Opposed to the Tsar, Rand's sympathies were with Alexander Kerensky. Rand's family life was disrupted by the rise of the Bolshevik party. Her father's pharmacy was confiscated by the Soviets, and the family fled to the Crimea which was initially under the control of the White Army. She later recalled that while in high school she determined that she was an atheist and that she valued reason and intellect. She graduated from high school in the Crimea and briefly held a job teaching Red Army soldiers to read. She found she enjoyed that work very much, the illiterate soldiers being eager to learn and respectful of her. At sixteen, Rand returned with her family to Saint Petersburg.
She enrolled at the University of Petrograd, where she studied in the department of social pedagogy, majoring in history. At university she was introduced to the writings of Aristotle and Plato, who would form two of the greatest influences and counter-influences respectively on her thought. A third figure whose philosophical works she studied heavily was Friedrich Nietzsche. Her formal study of philosophy amounted to only a few courses, and outside of these three philosophers, her study of key figures was limited to excerpts and summaries. Of the writers she read at this time, Victor Hugo, Edmond Rostand, Friedrich Schiller, and Fyodor Dostoevsky became her perennial favorites. Along with a number of other non-Communist students, Rand was purged from the university shortly before completing. However, after complaints from a group of visiting foreign scientists, the Communists relented and allowed many of the expelled students to complete their work and graduate, which Rand did in October 1924. She subsequently studied for a year at the State Technicum for Screen Arts.
In the fall of 1925, she was granted a visa to visit American relatives. She left Russia on January 17, 1926, and arrived in the United States on February 19, entering by ship through New York City. After a brief stay with her relatives in Chicago, she resolved never to return to the Soviet Union, and set out for Hollywood to become a screenwriter. While still in Russia she had decided her professional surname for writing would be "Rand", possibly as a Cyrillic contraction of her birth surname, and she adopted the first name "Ayn", either from a Finnish name or from the Hebrew word עין ("ayin", meaning "eye"). Initially, she struggled in Hollywood and took odd jobs to pay her basic living expenses. A chance meeting with famed director Cecil B. DeMille led to a job as an extra in his film, "The King of Kings", and to subsequent work as a junior screenwriter. While working on "The King of Kings", she intentionally bumped into an aspiring young actor, Frank O'Connor, who caught her eye. The two married on April 15, 1929. Rand became an American citizen in 1931. Taking various jobs during the 1930s to support her writing, Rand worked for a time as the head of the costume department at RKO Studios. She made attempts to bring her parents and sisters to the United States, but they were unable to get permission to emigrate.
Early fiction.
Rand's first literary success came with the sale of her screenplay "Red Pawn" to Universal Studios in 1932. Josef Von Sternberg considered it for Marlene Dietrich, but anti-Soviet themes were unpopular at the time, and the project came to nothing. This was followed by the courtroom drama "Night of January 16th", first produced in Hollywood in 1934, and then successfully reopened on Broadway in 1935. Each night the "jury" was selected from members of the audience, and one of the two different endings, depending on the jury's "verdict," would then be performed. In 1941, Paramount Pictures produced a movie version of the play. Rand did not participate in the production and was highly critical of the result.
Her first novel, the semi-autobiographical "We the Living", was published in 1936 by Macmillan. Set in Communist Russia, it focused on the struggle between the individual and the state. In the foreword to the novel, Rand stated that "We the Living" "is as near to an autobiography as I will ever write. It is not an autobiography in the literal, but only in the intellectual sense. The plot is invented, the background is not..." Without Rand's knowledge or permission, "We the Living" was made into a pair of Italian films, "Noi vivi" and "Addio, Kira", in 1942. Rediscovered in the 1960s, these films were re-edited into a new version which was approved by Rand and re-released as "We the Living" in 1986.
Her novella "Anthem" was published in England in 1938 and in America seven years later. It presents a vision of a dystopian future world in which collectivism has triumphed to such an extent that even the word "I" has vanished from the language and from humanity's memory.
"The Fountainhead" and political activism.
During the 1940s, Rand became involved in political activism. Both she and her husband worked full time in volunteer positions for the 1940 Presidential campaign of Republican Wendell Willkie. This work led to Rand's first public speaking experiences, including fielding the sometimes hostile questions from New York City audiences who had just viewed pro-Willkie newsreels, an experience she greatly enjoyed. This activity also brought her into contact with other intellectuals sympathetic to free-market capitalism. She became friends with journalist Henry Hazlitt and his wife, and Hazlitt introduced her to the Austrian School economist Ludwig von Mises. Both men expressed an admiration for Rand, and despite her philosophical differences with them, Rand strongly endorsed the writings of both men throughout her career.
Rand's first major success as a writer came with "The Fountainhead" in 1943, a romantic and philosophical novel that she wrote over a period of seven years. The novel centers on an uncompromising young architect named Howard Roark, and his struggle against what Rand described as "second-handers" — those who attempt to live through others, placing others above self. It was rejected by twelve publishers before finally being accepted by the Bobbs-Merrill Company on the insistence of editor Archibald Ogden, who threatened to quit if his employer did not publish it. "The Fountainhead" eventually became a worldwide success, bringing Rand fame and financial security. According to the Ayn Rand Institute, by April 2008 the novel had sold over 6.5 million copies.
In 1943, Rand returned to Hollywood to write the screenplay for a film version of "The Fountainhead" for Warner Brothers, and the following year she and her husband purchased a home designed by modernist Richard Neutra and an adjoining ranch. There, Rand entertained figures such as Hazlitt, Morrie Ryskind, Janet Gaynor, Gilbert Adrian and Leonard Read. Finishing her work on that screenplay, she was hired by producer Hal Wallis as a screenwriter and script-doctor, and her work for Wallis included the Oscar-nominated "Love Letters" and "You Came Along", along with research for a screenplay based on the development of the atomic bomb. This role gave Rand time to work on other projects, including the publication of her first work of non-fiction, an essay titled "The Only Path to Tomorrow", in the January 1944 edition of "Reader's Digest" magazine. Rand also outlined and took extensive notes for a non-fiction treatment of her philosophy, although the planned book was never completed.
During this period Rand developed a relationship with libertarian writer Isabel Paterson. The two women became friends and philosophical sparring-partners, and Rand is reported to have questioned the well-informed Paterson about American history and politics long into the night during their numerous meetings. Later, the two women had a falling out after what Rand saw as Paterson's bitter and insensitive comments during one of her Hollywood parties. Paterson's influence on Rand's later political theories has been a matter of ongoing debate, but Paterson biographer Stephen D. Cox credits Rand's public advocacy with keeping her old friend's political work "The God of the Machine" in print for many years, despite their previous break.
In 1947, during the Second Red Scare, Rand testified as a "friendly witness" before the United States House Un-American Activities Committee. Her testimony regarded the disparity between her personal experiences in the Soviet Union and the portrayal of it in the 1944 film "Song of Russia". Rand argued that the film grossly misrepresented the socioeconomic conditions in the Soviet Union and portrayed life in the USSR as being much better and happier than it actually was. When asked about her feelings on the effectiveness of the investigations after the hearings, Rand described the process as "futile".
The movie version of "The Fountainhead" was released in 1949. Although it used Rand's screenplay with minimal alterations, she "disliked the movie from beginning to end," complaining about its editing, acting and other elements.
"Atlas Shrugged" and later years.
After the publication of "The Fountainhead", Rand received numerous letters from readers, some of whom it had profoundly influenced. In 1951 Rand moved from Los Angeles to New York City, where she gathered a group of these admirers around her. This group (jokingly designated "The Collective") included future Federal Reserve chairman Alan Greenspan, a young psychology student named Nathan Blumenthal (later Nathaniel Branden) and his wife Barbara, and Barbara's cousin Leonard Peikoff. At first the group was an informal gathering of friends who met with Rand on weekends at her apartment to discuss philosophy. Later she began allowing them to read the drafts of her new novel, "Atlas Shrugged", as the manuscript pages were written. In 1954 Rand's close relationship with the much younger Nathaniel Branden turned into a romantic affair, with the consent of their spouses.
"Atlas Shrugged", published in 1957, was Rand's "magnum opus". The theme of the novel is "the role of the mind in man's existence—and, as a corollary, the demonstration of her moral philosophy: the morality of rational self-interest." It advocates the core tenets of Rand's philosophy of Objectivism and expresses her concept of human achievement. The plot involves a dystopian United States in which the most creative industrialists, scientists and artists go on strike and retreat to a mountainous hideaway where they build an independent free economy. The novel's hero and leader of the strike, John Galt, describes the strike as "stopping the motor of the world" by withdrawing the minds of the individuals most contributing to the nation's wealth and achievement. With this fictional strike, Rand intended to illustrate that without the efforts of the rational and productive, the economy would collapse and society would fall apart. The novel includes elements of mystery and science fiction, and contains Rand's most extensive statement of Objectivism in any of her works of fiction, a lengthy monologue delivered by Galt. "Atlas Shrugged" became an international bestseller. Rand's last work of fiction, it marked a turning point in her life, ending her career as novelist and beginning her tenure as a popular philosopher.
In 1958 Nathaniel Branden established Nathaniel Branden Lectures, later incorporated as the Nathaniel Branden Institute (NBI), to promote Rand's philosophy. Collective members gave lectures for NBI and wrote articles for Objectivist periodicals that she edited. Rand later published some of these articles in book form. Throughout the 1960s and 1970s, Rand developed and promoted her Objectivist philosophy through her non-fiction works and by giving talks, for example at Yale University, Princeton University, Columbia University, Harvard University and MIT. She received an honorary doctorate from Lewis & Clark College in 1963. For many years, she gave also an annual lecture at the Ford Hall Forum, responding afterwards in her famously spirited form to questions from the audience. In 1964 Nathaniel Branden began an affair with the young actress Patrecia Scott, whom he later married. Nathaniel and Barbara Branden hid the affair from Rand. Though her romantic relationship with Branden had already ended, Rand terminated her relationship with both Brandens in 1968 when she discovered Nathaniel Branden's affair with Patrecia Scott and his and Barbara Branden's role in concealing it, and as a result, NBI closed. She published an article in "The Objectivist" repudiating Nathaniel Branden for dishonesty and other "irrational behavior in his private life."
Rand underwent surgery for lung cancer in 1974. Several more of her closest associates parted company with her, and during the late 1970s her activities within the Objectivist movement declined, especially after the death of her husband on November 9, 1979. One of her final projects was work on a television adaptation of "Atlas Shrugged". She had also planned to write another novel, but did not get far in her notes. Rand died of heart failure on March 6, 1982 at her home in New York City, and was interred in the Kensico Cemetery, Valhalla, New York. Rand's funeral was attended by some of her prominent followers, including Alan Greenspan. A six-foot floral arrangement in the shape of a dollar sign was placed near her casket. In her will, Rand named Leonard Peikoff the heir to her estate. With her endorsement of his 1976 lecture series, she had recognized his work as being the best exposition of her philosophy.
Philosophy.
Rand saw her views as constituting an integrated philosophical system, which she called "Objectivism." Its essence is "the concept of man as a heroic being, with his own happiness as the moral purpose of his life, with productive achievement as his noblest activity, and reason as his only absolute." Objectivism has been described pejoratively as "Pseudophilosophy".
Rejecting faith as antithetical to reason, Rand embraced philosophical realism and opposed all forms of mysticism or supernaturalism, including organized religion. Rand also argued for rational egoism (rational self-interest), as the only proper guiding moral principle. The individual "must exist for his own sake," she wrote in 1962, "neither sacrificing himself to others nor sacrificing others to himself."
Rand held that the only moral social system is "laissez-faire" capitalism. Her political views were strongly individualist and hence anti-statist and anti-Communist. Rand detested many liberal and conservative politicians of her time, including prominent anti-Communists. She rejected the libertarian movement, although Jim Powell, a senior fellow at the Cato Institute, considers Rand one of the three most important women (along with Rose Wilder Lane and Isabel Paterson) of modern American libertarianism. Rand rejected anarcho-capitalism as "a contradiction in terms", a point on which she has been criticized by self-avowed anarchist Objectivists such as Roy Childs. Philosopher Chandran Kukathas said her "unremitting hostility towards the state and taxation sits inconsistently with a rejection of anarchism, and her attempts to resolve the difficulty are ill-thought out and unsystematic."
She acknowledged Aristotle as a great influence, and found early inspiration in Friedrich Nietzsche, although she rejected what she considered his anti-reason stance. Philosophers Ronald E. Merrill and David Steele point out a difference between her early and later views on the subject of sacrificing others. For example, the first edition of "We the Living" contained language which has been interpreted as advocating ruthless elitism: "What are your masses but mud to be ground underfoot, fuel to be burned for those who deserve it?"
She remarked that in the history of philosophy she could only recommend "three A's"—Aristotle, Aquinas, and Ayn Rand. Among the philosophers Rand held in particular disdain was Immanuel Kant, whom she referred to as a "monster" and "the most evil man in history". Rand was strongly opposed to the view that reason is unable to know reality "as it is in itself", which she ascribed to Kant. She considered her philosophy to be the "exact opposite" of Kant's on "every fundamental issue". Objectivist philosophers George Walsh and Fred Seddon both argue that Rand misinterpreted Kant. In particular, Walsh argues that both philosophers adhere to many of the same basic positions, and that Rand exaggerated her differences with Kant. Walsh says that for many critics, Rand's writing on Kant is "ignorant and unworthy of discussion".
Rand scholars Douglas Den Uyl and Douglas Rasmussen, while stressing the importance and originality of her thought, describe her style as "literary, hyperbolic and emotional." Similarly, philosopher Jack Wheeler says that despite "the incessant bombast and continuous venting of Randian rage," Rand's ethics is "a most immense achievement, the study of which is vastly more fruitful than any other in contemporary thought." In 1976, she said that her most important contributions to philosophy were her "theory of concepts, [her] ethics, and [her] discovery in politics that evil—the violation of rights—consists of the initiation of force."
Literary reception.
Rand's novels, when they were first published, were derided by some critics as long and melodramatic, and became bestsellers largely due to word of mouth. The first reviews Rand received were for her play "Night of January 16". Reviews of the Broadway production were mixed, and Rand considered even the positive reviews to be embarrassing because of significant changes made to her script by the producer. Rand herself described her first novel, "We the Living", as not being widely reviewed, but Michael S. Berliner says "it was the most reviewed of any of her works," with approximately 125 different reviews being published in more than 200 publications. Many of these reviews were more positive than the reviews she received for her later work. Her 1938 novella "Anthem" received little attention from reviewers, both for its first publication in England and for several subsequent re-issues.
Rand's first bestseller, "The Fountainhead", received far fewer reviews than "We the Living", and reviewers' opinions were mixed. There was a positive review in "The New York Times" that Rand greatly appreciated. The "Times" reviewer called Rand "a writer of great power" who writes "brilliantly, beautifully and bitterly," and it stated that she had "written a hymn in praise of the individual... you will not be able to read this masterful book without thinking through some of the basic concepts of our time." There were other positive reviews, but Rand dismissed many of them as either not understanding her message or as being from unimportant publications. A number of negative reviews focused on the length of the novel, such as one that called it "a whale of a book" and another that said "anyone who is taken in by it deserves a stern lecture on paper-rationing." Other negative reviews called the characters unsympathetic and Rand's style "offensively pedestrian."
Rand's 1957 novel "Atlas Shrugged" was widely reviewed, and many of the reviews were strongly negative. In the "National Review", conservative author Whittaker Chambers called the book "sophomoric" and "remarkably silly". He described the tone of the book as "shrillness without reprieve" and accused Rand of supporting the same godless system as the Soviets, claiming "From almost any page of "Atlas Shrugged", a voice can be heard, from painful necessity, commanding: 'To a gas chamber—go!'" "Atlas Shrugged" received positive reviews from a few publications, but as Rand scholar Mimi Reisel Gladstein later described them, many reviewers "seemed to vie with each other in a contest to devise the cleverest put-downs," calling it "execrable claptrap" and "a nightmare;" they said it was "written out of hate" and showed "remorseless hectoring and prolixity."
During Rand's lifetime her work received little attention from academic scholars. When "With Charity Toward None: An Analysis of Ayn Rand's Philosophy", the first academic book about Rand's philosophy, appeared in 1971, its author William F. O'Neill declared writing about Rand "a treacherous undertaking" that could lead to "guilt by association" for taking her seriously. A few articles about Rand's ideas appeared in academic journals prior to her death in 1982, many of them in "The Personalist". Academic consideration of Rand as a literary figure during her life was even more limited. Gladstein was unable to find any scholarly articles about Rand's novels when she began researching her in 1973, and only three such articles appeared during the rest of the 1970s.
Legacy.
Rand's books continue to be widely sold and read, with 25 million copies sold as of 2007, and 800,000 more being sold each year according to the Ayn Rand Institute. She has also influenced notable people in different fields. Examples include philosophers John Hospers, George H. Smith, Allan Gotthelf, Robert Mayhew and Tara Smith, economists Alan Greenspan, George Reisman and Murray Rothbard, psychologist Edwin A. Locke, historian Robert Hessen, and political writer Charles Murray. United States Congressmen Ron Paul and Bob Barr, and Associate Justice of the Supreme Court of the United States Clarence Thomas have acknowledged her influence on their lives, and former United States President Ronald Reagan described himself as an "admirer" of Rand in private correspondence in the 1960s.
Popular interest and influence.
When a 1991 survey by the Library of Congress and the Book-of-the-Month Club asked what the most influential book in the respondent's life was, Rand's "Atlas Shrugged" was the second most popular choice, after the Bible. Readers polled in 1998 and 1999 by Modern Library placed four of her books on the 100 Best Novels list, with "Atlas Shrugged" taking the top position, while another, "The Virtue of Selfishness", topped the 100 Best Nonfiction list. Books by other authors about Rand and her philosophy also appeared on the non-fiction list. The validity of such lists has been disputed. Freestar Media/Zogby polls conducted in 2007 found that around 8 percent of American adults have read "Atlas Shrugged".
Rand has been cited by numerous writers, artists and commentators as an influence on their lives and thought. Rand or characters based on her figure prominently in novels by such authors as William F. Buckley, Mary Gaitskill, Matt Ruff, J. Neil Schulman, and Kay Nolte Smith. Other authors and artists, such as Steve Ditko, Terry Goodkind, and Neil Peart, have also cited her as an influence.
Rand and her works have been referred to in a variety of media. Radio personality Rush Limbaugh makes frequent positive reference to Rand's work on his program. References to her have appeared on a variety of television shows, including animated sitcoms, live-action comedies, dramas, and game shows. "The Philosophical Lexicon", a satirical web site maintained by philosophers Daniel Dennett and Asbjørn Steglich-Petersen, defines a 'rand' as: "An angry tirade occasioned by mistaking philosophical disagreement for a personal attack and/or evidence of unspeakable moral corruption." Her image appears on a U.S. postage stamp designed by artist Nick Gaetano. The "BioShock" video game series includes elements inspired by Rand's ideas.
Two movies have been made about Rand's life. A 1997 documentary film, ', was nominated for the Academy Award for Best Documentary Feature. "The Passion of Ayn Rand", an independent film about her life, was made in 1999, starring Helen Mirren as Rand and Peter Fonda as her husband. The film was based on the book of the same name by Barbara Branden, and won several awards. Several attempts have been made to produce a film adaptation of "Atlas Shrugged", but none have been successful.
Although Rand's influence has been greatest in the United States, there has been international interest in her work. Her books were international best sellers, and continue to sell in large numbers in the 21st century.
Academia.
Since Rand's death in 1982, interest in her work has gradually increased. Historian Jennifer Burns has identified "three overlapping waves" of scholarly interest in Rand, the most recent of which is "an explosion of scholarship" in the 2000s. However, few universities currently include Rand or Objectivism as a philosophical specialty or research area, with many literature and philosophy departments dismissing her as a pop culture phenomenon rather than a subject for serious study.
Some academic philosophers have criticized Rand for what they consider her lack of rigor and limited understanding of philosophical subject matter. Many in the Continental tradition think her celebration of self-interest relies on sophistic logic, and as a result have not thought her work worth any serious consideration. Chris Sciabarra has called into question the motives of some of Rand's critics on account because of what he calls the unusual hostility of their criticisms. Sciabarra says, "The left was infuriated by her anti-communist, procapitalist politics, whereas the right was disgusted with her atheism and civil libertarianism."
Writers on Rand such as Sciabarra, Allan Gotthelf, and Tara Smith have made attempts to teach her work in academic institutions. Sciabarra co-edits the "Journal of Ayn Rand Studies", a nonpartisan peer-reviewed journal dedicated to the study of Rand's philosophical and literary work. In 1987 Gotthelf helped found the Ayn Rand Society, which is affiliated with the American Philosophical Association and has been active in sponsoring seminars and distributing videotaped lecture courses on Ayn Rand. Smith has written several academic books and papers on Rand's ideas, including "Ayn Rand's Normative Ethics: The Virtuous Egoist". Rand's ideas have also been made subjects of study at Clemson and Duke universities. Scholars of English and American literature have largely ignored her work, although attention to her literary work has increased since the 1990s. In the "Literary Encyclopedia" entry for Rand written in 2001, John Lewis declared that "Rand wrote the most intellectually challenging fiction of her generation". In a 1999 interview in the "Chronicle of Higher Education," Rand scholar Chris Matthew Sciabarra commented, "I know they laugh at Rand," while forecasting a growth of interest in her work in the academic community.
Institutes.
In 1985 Leonard Peikoff established the Ayn Rand Institute, which "works to introduce young people to Ayn Rand's novels, to support scholarship and research based on her ideas, and to promote the principles of reason, rational self-interest, individual rights and laissez-faire capitalism to the widest possible audience." In 1990 David Kelley founded the Institute for Objectivist Studies, now known as The Atlas Society. Its focus is on attracting readers of Rand's fiction; the associated Objectivist Center deals with more academic ventures. In 2001 historian John McCaskey organized the Anthem Foundation for Objectivist Scholarship, which provides grants for scholarly work on Objectivism in academia. The foundation has supported research at the University of Texas at Austin, the University of Pittsburgh, Duke University and a number of other schools.
---END.OF.DOCUMENT---

Alain Connes.
Alain Connes (born 1 April 1947) is a French mathematician, currently Professor at the Collège de France, IHÉS and Vanderbilt University.
Work.
Alain Connes is one of the leading specialists on operator algebras. In his early work on von Neumann algebras in the 1970s, he succeeded in obtaining the almost complete classification of injective factors. Following this he made contributions in operator K-theory and index theory, which culminated in the
Baum-Connes conjecture. He also introduced cyclic cohomology in the early 1980s as a first step in the study of noncommutative differential geometry.
Connes has applied his work in areas of mathematics and theoretical physics, including number theory, differential geometry and particle physics.
Awards and honours.
Connes was awarded the Fields Medal in 1982, the Crafoord Prize in 2001 and the gold medal of the CNRS in 2004. He is a member of the French Academy of Sciences and several foreign academies and societies, including the Danish Academy of Sciences, Norwegian Academy of Sciences, Russian Academy of Sciences, and US National Academy of Sciences.
---END.OF.DOCUMENT---

Allan Dwan.
Allan Dwan (April 3, 1885 – December 28, 1981) was a pioneering Canadian-born American motion picture director, producer and screenwriter.
Early life.
Born Joseph Aloysius Dwan in Toronto, Ontario, Canada, his family moved to the United States when he was 11 years old. At the University of Notre Dame, he trained as an engineer and began working for a lighting company in Chicago. However, he had a strong interest in the fledgling motion picture industry and when Essanay Studios offered him the opportunity to become a scriptwriter, he took the job. At that time, some of the East Coast movie makers began to spend winters in California where the climate allowed them to continue productions requiring warm weather. Soon, a number of movie companies worked there year-round and, in 1911, Dwan began working part time in Hollywood. While still in New York, in 1917 he was the founding president of the East Coast chapter of the Motion Picture Directors Association.
Career.
After making a series of westerns and comedies, Dwan directed fellow Canadian Mary Pickford in several very successful movies as well as her husband, Douglas Fairbanks, notably in the acclaimed 1922 "Robin Hood".
Following the introduction of the talkies, in 1937 he directed child-star Shirley Temple in "Heidi" and "Rebecca of Sunnybrook Farm" the following year.
Over his long and successful career spanning over 50 years, he directed over 400 motion pictures, many of them highly acclaimed, such as the 1949 box office smash, "Sands of Iwo Jima". He directed his last movie in 1961.
He died in Los Angeles at the age of ninety-six, and is interred in the San Fernando Mission Cemetery, Mission Hills, California.
Allan Dwan has a star on the Hollywood Walk of Fame at 6263 Hollywood Boulevard in Hollywood.
Selected films.
See also: Canadian pioneers in early Hollywood
---END.OF.DOCUMENT---

Algeria.
Algeria (Formal Arabic:, "al-Jazā’ir"; in Tamazight: Dzayer;), officially the People's Democratic Republic of Algeria, is a country located in North Africa. In terms of land area, it is the largest country on the Mediterranean Sea, the second largest on the African continent after Sudan, and the eleventh-largest country in the world.
Algeria is bordered by Tunisia in the northeast, Libya in the east, Niger in the southeast, Mali and Mauritania in the southwest, a few kilometers of the Moroccan-controlled Western Sahara in the southwest, Morocco in the west and northwest, and the Mediterranean Sea in the north. Its size is almost 2,400,000 km2, and it has an estimated population of about 35,700,000 as of January 2010. The capital of Algeria is Algiers.
Algeria is a member of the United Nations, African Union, and OPEC. It also contributed towards the creation of the Maghreb Union.
